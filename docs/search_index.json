[["index.html", "LECTURE NOTES OF STAT 3202 Welcome", " LECTURE NOTES OF STAT 3202 Dr. Pratheesh P. Gopinath 2022-01-30 Welcome Welcome to the book LECTURE NOTES ON STATISTICAL METHODS AND APPLICATIONS. "],["preface.html", "Preface", " Preface Note: This book is published in MeLoN (Module for e-Learning &amp; Online Notes) . The online version of this book is free to read here. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. If you have any feedback, please feel free to contact Dr.Pratheesh P. Gopinath. E-mail: pratheesh.pg@kau.in Thank you! This book is a collection of all lecture notes covering the syllabus of statistics course in B.Sc.(Hons.) Agriculture under Kerala Agricultural University "],["introduction.html", "Chapter 1 Introduction 1.1 Origin of the word Statistics 1.2 Statistics and Mathematics 1.3 Definition of Statistics 1.4 Data 1.5 Use and limitations of statistics 1.6 Population and Sample 1.7 Variables and constants 1.8 Types of variables 1.9 Measurement scales 1.10 Collection of Data 1.11 Methods of Collecting Primary Data 1.12 Methods of Collecting Secondary Data 1.13 Difference Between Primary and Secondary Data 1.14 Frequency distribution 1.15 Grouped frequency distribution 1.16 Terms used in grouped frequency tables. 1.17 Construction of frequency distribution table 1.18 Cumulative frequency 1.19 Relative frequency", " Chapter 1 Introduction In this lecture we will have the introduction, which includes, definition of statistics, collection and classification of data, formation of frequency distribution.(Goon and Dasgupta 1983) (Gupta and Kapoor 1997) 1.1 Origin of the word Statistics The term statistics was derived from the Neo-Latin word statisticum collegium meaning council of state and the Italian word statista meaning statesman or politician. A German word Statistik, got the meaning collection and classification of data generally in the early 19th century. This word was first introduced by Gottfried Achenwall (1749). Statistik was originally designated as a term for analysis of data about the state (data used by government or other administrative bodies). The term Statistik was introduced into English in 1791 by Sir John Sinclair when he published the first of 21 volumes titled Statistical Account of Scotland (Ball 2004). The first book to have Statistics in its title was Contributions to Vital Statistics (1845) by Francis GP Neison, actuary1 to the Medical Invalid and General Life Office. Figure 1.1: Statistical Account of Scotland by Sir John Sinclair (1791) 1.2 Statistics and Mathematics Mathematics follows a rigid theorem and proof. Mathematical theories involve well-defined and proven facts which has the minimal scope of change. However, Statistics is a discipline where real-life data is handled. This factor makes this field of study more abstract, where individuals have to develop newer solutions to problems that was new and not observed before. Statistics is an applied science; in mathematics the goal is to prove theorems. In statistics, the main goal is to develop good methods for understanding data and making decisions. Statisticians often use mathematical theorems to justify their methods, but theorems are not the main focus. Statistics is now considered as an independent field which uses mathematics to solve real life problems. 1.3 Definition of Statistics Statistics is the science which deals with the Collection of data Organization of data or Classification of data Presentation of data Analysis of data Interpretation of data Two main branches of statistics are: Descriptive statistics, which deals with summarizing data from a sample using indexes such as the mean or standard deviation etc. Inferential statistics, use a random sample of data taken from a population to describe and make inferences about the population parameters. 1.4 Data Data can be defined as individual pieces of factual information recorded and used for the purpose of analysis. It is the raw information from which inferences are drawn using the science STATISTICS. Example for data No. of farmers in a block. The rainfall over a period of time. Area under paddy crop in a state. 1.5 Use and limitations of statistics Functions of statistics: Statistics simplifies complexity, presents facts in a definite form, helps in formulation of suitable policies, facilitates comparison and helps in forecasting. Valid results and conclusion are obtained in research experiments using proper statistical tools. Uses of statistics: Statistics has pervaded almost all spheres of human activities. Statistics is useful in the administration, Industry, business, economics, research workers, banking,insurance companies etc. Limitations of Statistics Statistical theories can be applied only when there is variability in the experimental material. Statistics deals with only aggregates or groups and not with individual objects. Statistical results are not exact. Statistics are often misused. 1.6 Population and Sample Consider the following example.Suppose we wish to study the body masses of all students of College of Agriculture, Vellayani. It will take us a long time to measure the body masses of all students of the college and so we may select 20 of the students and measure their body masses (in kg). Suppose we obtain the measurements like this 49 56 48 61 59 43 58 52 64 71 57 52 63 58 51 47 57 46 53 59 In this study, we are interested in the body masses of all students of College of Agriculture, Vellayani. The set of body masses of all students of College of Agriculture, Vellayani is called the population of this study. The set of 20 body masses, W = {49, 56,48, , 53, 59}, is a sample from this population. 1.6.1 Population A population is the set of all objects we wish to study 1.6.2 Sample A sample is part of the population we study to learn about the population. 1.7 Variables and constants 1.7.1 Variables Any type of observation which can take different values for different people, or different values at different times, or places, is called a variable. The following are examples of variables: family size, number of hospital beds, number of schools in a country, etc. height, mass, blood pressure, temperature, blood glucose level, etc. Broadly speaking, there are two types of variables  quantitative and qualitative (or categorical) variables 1.7.2 Constants Constants are characteristics that have values that do not change. Examples of constants are: pi () = the ratio of the circumference of a circle to its diameter ( = 3.14159...) and e, the base of the natural or (Napierian) logarithms (e=2.71828). 1.8 Types of variables 1.8.1 Quantitative variables A quantitative variable is one that can take numerical values. The variables like family size, number of hospital beds, number of schools in a country, height, mass, blood pressure, temperature, blood glucose level, etc. are examples of quantitative variables. Quantitative variables may be characterized further as to whether they are discrete or continuous 1.8.2 Discrete variables The variables like family size, number of hospital beds, number of schools in a country, etc. can be counted. These are examples of discrete variables. Variables that can only take on a finite number of values are called \"discrete variables.\" Any variable phrased as the number of , is discrete, because it is possible to list its possible values {0,1, }. Any variable with a finite number of possible values is discrete. The following example illustrates the point. The number of daily admissions to a hospital is a discrete variable since it can be represented by a whole number, such as 0, 1, 2 or 3. The number of daily admissions on a given day cannot be a number such as 1.8, 3.96 or 5.33. 1.8.3 Continuous variables The variables like height, mass, blood pressure, temperature, blood glucose level, etc. can be measured. These are examples of continuous variables. A continuous variable does not possess the gaps or interruptions characteristic of a discrete variable. A continuous variable can assume any value within a specific relevant interval of values assumed by the variable. Notice that age is continuous since an individual does not age in discrete jumps. Weight can be measured as 35.5, 35.8 kg etc so, it is a continuous variable. 1.8.4 Categorical variables A variable is called categorical when the measurement scale is a set of categories. For example, marital status, with categories (single,married, widowed), is categorical. Whether employed (yes, no), religious affiliation (Protestant, Catholic, Jewish, Muslim, others, none), colours etc. Categorical variables are often called qualitative. It can be seen that categorical variables can neither be measured nor counted. 1.9 Measurement scales Variables can further be classified according to the following four levels of measurement: nominal, ordinal, interval and ratio. 1.9.1 Nominal scale This scale of measure applies to qualitative variables only. On the nominal scale, no order is required. For example,gender is nominal, blood group is nominal, and marital status is also nominal. We cannot perform arithmetic operations on data measured on the nominal scale. 1.9.2 Ordinal scale This scale also applies to qualitative data. On the ordinal scale, order is necessary. This means that one category is lower than the next one or vice versa. For example, Grades are ordinal, as excellent is higher than very good, which in turn is higher than good, and so on. It should be noted that, in the ordinal scale, differences between category values have no meaning. 1.9.3 Interval scale This scale of measurement applies to quantitative data only. In this scale, the zero point does not indicate a total absence of the quantity being measured. An example of such a scale is temperature on the Celsius or Fahrenheit scale. Suppose the minimum temperatures of 3 cities, A, B and C, on a particular day were 00C, 200C and 100C, respectively. It is clear that we can find the differences between these temperatures. For example, city B is 200C hotter than city A. However, we cannot say that city A has no temperature. Moreover, we cannot say that city B is twice as hot as city C, just because city B is 200C and city C is 100C. The reason is that, in the interval scale, the ratio between two numbers is not meaningful. 1.9.4 Ratio scale This scale of measurement also applies to quantitative data only and has all the properties of the interval scale. In addition to these properties, the ratio scale has a meaningful zero starting point and a meaningful ratio between 2 numbers. An example of variables measured on the ratio scale, is weight. A weighing scale that reads 0 kg gives an indication that there is absolutely no weight on it. So the zero starting point is meaningful. If Ram weighs 40 kg and Laxman weighs 20 kg, then Ram weighs twice as Laxman. Another example of a variable measured on the ratio scale is temperature measured on the Kelvin scale. This has a true zero point. Figure 1.2: Classification of variables 1.10 Collection of Data The first step in any enquiry (investigation) is the collection of data. The data may be collected for the whole population or for a sample only. It is mostly collected on a sample basis. Collecting data is very difficult job. The enumerator or investigator is the well trained individual who collects the statistical data. The respondents are the persons from whom the information is collected. 1.10.1 Types of Data There are two types (sources) for the collection of data: * Primary Data * Secondary Data 1.10.1.1 Primary Data Primary data are the first hand information which is collected, compiled and published by organizations for some purpose. They are the most original data in character and have not undergone any sort of statistical treatment. Example: Population census reports are primary data because these are collected, complied and published by the population census organization. 1.10.1.2 Secondary Data The secondary data are the second hand information which is already collected by an organization for some purpose and are available for the present study. Secondary data are not pure in character and have undergone some treatment at least once. Example: An economic survey of England is secondary data because the data are collected by more than one organization like the Bureau of Statistics, Board of Revenue, banks, etc. 1.11 Methods of Collecting Primary Data Primary data are collected using the following methods: 1.11.1 Personal Investigation The researcher conducts the survey him/herself and collects data from it. The data collected in this way are usually accurate and reliable. This method of collecting data is only applicable in case of small research projects. 1.11.2 Through Investigation Trained investigators are employed to collect the data. These investigators contact the individuals and fill in questionnaires after asking for the required information. Most organizations utilize this method. 1.11.3 Collection through Questionnaire Researchers get the data from local representations or agents that are based upon their own experience. This method is quick but gives only a rough estimate. 1.11.4 Through the Telephone Researchers get information from individuals through the telephone. This method is quick and gives accurate information. 1.12 Methods of Collecting Secondary Data Secondary data are collected by the following methods: 1.12.1 Official Publications from the Statistical Division, Ministry of Finance, the Federal Bureaus of Statistics, Ministries of Food, Agriculture, Industry, Labor, etc. 1.12.2 Semi-Official Publications from State Bank, Railway Board, Central Cotton Committee, Boards of Economic Enquiry etc. Publication of Trade Associations, Chambers of Commerce, etc. Technical and Trade Journals and Newspapers. Research Organizations such as universities and other institutions. 1.13 Difference Between Primary and Secondary Data The difference between primary and secondary data is only a change of hand. Primary data are the first hand information which is directly collected form one source. They are the most original in character and have not undergone any sort of statistical treatment, while secondary data are obtained from other sources or agencies. They are not pure in character and have undergone some treatment at least once. 1.14 Frequency distribution Table shows the number of children per family for 54 families selected from a town in India. The data, presented in this form in which it was collected, is called raw data. Figure 1.3: raw data set of No. of children in 54 families It can be seen that, the minimum and the maximum numbers of children per family are 0 and 4, respectively. Apart from these numbers, it is impossible, without further careful study, to extract any exact information from the data. But by breaking down the data into the form below Figure 1.4: Frequency distribution table Now certain features of the data become apparent. For instance, it can easily be seen that, most of the 54 families selected have two children because number of houses having 2 children is 18. This information cannot easily be obtained from the raw data. The above table is called a frequency table or a frequency distribution. It is so called because it gives the frequency or number of times each observation occurs. Thus, by finding the frequency of each observation, a more intelligible picture is obtained. 1.14.1 Construction of frequency distribution List all values of the variable in ascending order of magnitude. Form a tally column, that is, for each value in the data, record a stroke in the tally column next to that value. In the tally, each fifth stroke is made across the first four. This makes it easy to count the entries and enter the frequency of each observation. Check that the frequencies sum to the total number of observations 1.15 Grouped frequency distribution Data below gives the body masses of 22 patients, measured to the nearest kilogram. Figure 1.5: Body masses of 22 patients It can be seen that the minimum and the maximum body masses are 42 kg and 83 kg, respectively. A frequency distribution giving every body mass between 42 kg and 83 kg would be very long and would not be very informative. The problem is to overcome by grouping the data into classes. If we choose the classes 41  49 50  58 59  67 68  76 and 77  85, we obtain the frequency distribution given below: Figure 1.6: Grouped Frequency distribution table Above table gives the frequency of each group or class; it is therefore called a grouped frequency table or a grouped frequency distribution. Using this grouped frequency distribution, it is easier to obtain information about the data than using the raw data. For instance, it can be seen that 17 of the 22 patients have body masses between 50 kg and 76 kg (both inclusive). This information cannot easily be obtained from the raw data. It should be noted that, even though above table is concise, some information is lost. For example, the grouped frequency distribution does not give us the exact body masses of the patients. Thus the individual body masses of the patients are lost in our effort to obtain an overall picture. 1.16 Terms used in grouped frequency tables. Class limits The intervals into which the observations are put are called class intervals. The end points of the class intervals are called class limits. For example, the class interval 41  49, has lower class limit 41 and upper class limit 49. Class boundaries The raw data in the above example were recorded to the nearest kilogram. Thus, a body mass of 49.5kg would have been recorded as 50 kg, a body mass of 58.4 kg would have been recorded as 58 kg, while a body mass of 58.5 kg would have been recorded as 59 kg. It can therefore be seen that, the class interval 50  58, consists of measurements greater than or equal to 49.5 kg and less than 58.5 kg. The numbers 49.5 and 58.5 are called the lower and upper boundaries of the class interval 50  58. The class boundaries of the other class intervals are given below: Figure 1.7: Class boundary and class limits Note: Notice that the lower class boundary of the ith class interval is the mean of the lower class limit of the class interval and the upper class limit of the (i-1)th class interval (i = 2, 3, 4, ). For example, in the table above the lower class boundaries of the second and the fourth class intervals are (50 + 49) /2 = 49.5 and (68 + 67)/2 = 67.5 respectively. It can also be seen that the upper class boundary of the ith class interval is the mean of the upper class limit of the class interval and the lower class limit of the (i+1)th class interval (i = 1, 2, 3, ). Thus, in the above table the upper class boundary of the fourth class interval is (76 + 77)/2 = 76.5. Class mark The mid-point of a class interval is called the class mark or class mid-point of the class interval. It is the average of the upper and lower class limits of the class interval. It is also the average of the upper and lower class boundaries of the class interval. For example, in the table, the class mark of the third class interval was found as follows: class mark =(59+67) /2 = (58.5 + 67.5)/2= 63. Class width The difference between the upper and lower class boundaries of a class interval is called the class width of the class interval. Class widths of class intervals can also be found by subtracting two consecutive lower class limits, or by subtracting two consecutive upper class limits. Note: The width of the ith class interval is the numerical difference between the upper class limits of the ith and the ( i-1)th class intervals (i = 2, 3, ). It is also the numerical difference between the lower class limits of the ith and the (i+1) th class intervals (i = 1, 2, ). In grouped frequency table above the width of the first class interval is |41-50| = 9. This is the numerical difference between the lower class limits of the first and the second class intervals. The width of the second class interval is |50-59|= 9. This is the numerical difference between the lower class limits of the second and the third class intervals. It is also equal to |58-49| the numerical, difference between the upper class limits of the first and the second class intervals. 1.17 Construction of frequency distribution table Step 1. Decide how many classes you wish to use. Step 2. Determine the class width Step 3. Set up the individual class limits Step 4. Tally the items into the classes Step 5. Count the number of items in each class Consider the example An agricultural student measured the lengths of leaves on an oak tree (to the nearest cm). Measurements on 38 leaves are as follows 9,16,13,7,8,4,18,10,17,18,9,12,5,9,9,16,1,8,17,1,10,5,9,11,15,6,14,9,1,12,5,16,4,16,8,15,14,17 Step 1. Decide how many classes you wish to use. H.A. Sturges provides a formula for determining the approximation number of classes. \\(\\mathbf{k = 1 + 3.322}\\mathbf{\\log}\\mathbf{N}\\). Number of classes should be greater than calculated k In our example N=38, so k=1+3.322×log(38) = 1+3.322×1.5797 = 6.24 = approx 7 So the approximated number of classes should be not less than 6.24 i.e.\\(\\ k^{&#39;}\\) =7 Step 2. Determine the class width Generally, the class width should be the same size for all classes. C= | max  min|/ k. Class width \\(C^{&#39;}\\)should be greater than calculated C. For this example, C = | 18 1|/6.24 = 2.72, so approximately class width\\(C^{&#39;} =\\) 3 (Note that k used here is the calculated value using Struges formula not the approximated). Step 3. To set up the individual class limits, We need to find the lower limit only \\[L = min - \\frac{C^{&#39;} \\times k^{&#39;} - (max - min)}{2}\\] where C and k here are final approximated class width and number of classes respectively in our example \\(L = 1 - \\frac{3 \\times 7 - (18 - 1)}{2}\\)=1-2=-1; since there is no negative values in data = 0. Class Frequency 0-3 3 3-6 5 6-9 5 9-12 9 12-15 5 15-18 9 18-21 2 Even though the student only measured in whole numbers, the data is continuous, so \"4 cm\" means the actual value could have been anywhere from 3.5 cm to 4.5 cm. 1.18 Cumulative frequency In many situations, we are not interested in the number of observations in a given class interval, but in the number of observations which are less than (or greater than) a specified value. For example, in the above table, it can be seen that 3 leaves have length less than 3.5 cm and 9 leaves (i.e. 3 + 6) have length less than 6.5 cm. These frequencies are called cumulative frequencies. A table of such cumulative frequencies is called a cumulative frequency table or cumulative frequency distribution. Cumulative frequency is defined as a running total of frequencies. Cumulative frequency can also defined as the sum of all previous frequencies up to the current point. Notice that the last cumulative frequency is equal to the sum of all the frequencies. Two types of cumulative frequencies are Less than cumulative frequency and Greater than cumulative frequency. Less than cumulative frequency (LCF) is the number of values less than a specified value. Greater than cumulative frequency (GCF) is the number of observations greater than a specified value. The specified value for LCF in the case of grouped frequency distribution will be upper limits and for GCF will be the lower limits of the classes. LCFs are obtained by adding frequencies in the successive classes and GCF are obtained by subtracting the successive class frequencies from the total frequency. 1.19 Relative frequency It is sometimes useful to know the proportion, rather than the number, of values falling within a particular class interval. We obtain this information by dividing the frequency of the particular class interval by the total number of observations. Relative frequency of a class is the frequency of class / total observation. Relative frequencies all add up to 1. Class Frequency A B C 0.5  3.5 3 3 38 0.078947 3.5  6.5 6 9 35 0.157895 6.5  9.5 10 19 29 0.263158 9.5  12.5 5 24 19 0.131579 12.5  15.5 5 29 14 0.131579 15.5  18.5 9 38 9 0.236842 [1] Note: A= Less than cumulative frequency; B= Greater than cumulative frequency, C = Relative frequency Data is the sword of the 21st century, those who wield it well, the Samurai. - Jonathan Rosenberg, former Google SVP! References "],["graphical-representation-of-data.html", "Chapter 2 Graphical representation of data 2.1 Histogram 2.2 Cumulative frequency curve (Ogive) 2.3 Stem-and-leaf plot 2.4 Bar chart 2.5 Histogram and Bar chart 2.6 Pie Charts", " Chapter 2 Graphical representation of data We found that information given in a frequency distribution is easier to interpret than raw data. Information given in a frequency distribution in a tabular form is easier to grasp if presented graphically. Many types of diagrams are used in statistics, depending on the nature of the data and the purpose for which the diagram is intended. 2.1 Histogram A histogram consists of rectangles with: Bases on a horizontal axis, centres at the class marks, and lengths equal to the class widths. Areas proportional to class frequencies. Note: If the class intervals are of equal size, then the heights of the rectangles are proportional to the class frequencies and it is then customary to take the heights of the rectangles numerically equal to the class frequencies. If the class intervals are of different widths, then the heights of the rectangles are proportional to \\(\\frac{\\text{Class Frequency}}{\\text{Class Width}}\\). This ratio is called frequency density. Table below shows the frequency distribution of the body masses of 50 AIDS patients. Draw a Histogram. Mass 30  39 40  49 50  59 60  69 70  79 80  89 Frequency 3 6 17 13 8 3 Figure 2.1: Histogram 2.2 Cumulative frequency curve (Ogive) A graph obtained by plotting a cumulative frequency against the class boundary and joining the points by a smooth curve, is called a cumulative frequency curve. It is also called as Ogive. Two types of ogive are there, Less Than Type Cumulative Frequency Curve (Less than Ogive) and Greater Than Type Cumulative Frequency Curve (Greater than Ogive). 2.2.1 Less than Ogive Also known as less than type cumulative frequency curve. Here we use the upper limit of the classes and the less than cumulative frequency to plot the curve. Let us see for the example of the body masses of 50 AIDS patients. Upper limit 39 49 59 69 79 89 Less than Cumulative frequency 3 9 26 39 47 50 Figure 2.2: Less than ogive 2.2.2 Greater than Ogive Also known as greater than type cumulative frequency curve Here we use the lower limit of the classes and the greater than cumulative frequency to plot the curve. Lower Limit 30 40 50 60 70 80 Greater than Cumulative frequency 50 47 41 24 11 3 Figure 2.3: greater than ogive Note: Intersection of both ogives gives the median 2.2.3 Frequency polygon A grouped frequency table can also be represented by a frequency polygon, which is a special kind of line graph. To construct a frequency polygon, we plot a graph of class frequencies against the corresponding class mid-points and join successive points with straight lines. Frequency polygon is also obtained by joining the midpoints of a histogram as shown in Fig 2.5. Class Midpoints 34.5 44.5 54.5 64.5 74.5 84.5 Frequencies 3.0 6.0 17.0 13.0 8.0 3.0 Figure 2.4: Frequency polygon Figure 2.5: Frequency polygon and histogram 2.3 Stem-and-leaf plot A stem-and-leaf plot is a graphical device that is useful for representing a relatively small set of data which takes numerical values. To construct a stem-and-leaf plot, we partition each measurement into two parts. The first part is called the stem, and the second part is called the leaf. Here each numerical value is divided into two parts: The leading digits become the stem the trailing digits become the leaf. One advantage of the stem-and-leaf display over a frequency distribution is that we retain the value of each observation. Another is the distribution of the data within each groups is clear. A stem-and-leaf plot conveys similar information as a histogram. Turned on its side, it has the same shape as the histogram. In fact, since the stem-and-leaf plot shows each observation,it displays information that is lost in a histogram. A properly constructed stem-and-leaf plot, like a histogram, provides information regarding the range of the data set, shows the location of the highest concentration of measurements, and reveals the presence or absence of symmetry. Consider the example 10,15,22,25,28,23,29,31,36,45,48 stem and leaf plot can be drawn as shown below. Stem Leaf 1 0 5 2 2 3 5 8 9 3 1 6 4 5 8 Figure 2.6: Stem and Leaf plot 2.4 Bar chart A bar chart or bar graph is a diagram consisting of a series of horizontal or vertical bars of equal width. The bars represent various categories of the data. There are three types of bar charts, and these are simple bar charts, component bar charts and grouped bar charts. 2.4.1 Simple bar chart In a simple bar chart, the height (or length) of each bar is equal to the value of category in the y-axis it represents. For example data below shows the production of timber in five districts of Kerala in a certain year. District Production Alappuzha 600 Kannur 900 Trissur 1800 Ernakulam 1500 Wayanad 2400 Figure 2.7: Barchart 2.4.2 Component bar chart In a component bar chart, the bar for each category is subdivided into component parts; hence its name. Component bar charts are therefore used to show the division of items into components. This is illustrated in the following example. Example shows the distribution of sales of agricultural produce from a Farm in 1995, 1996 and 1997. Figure 2.8: Sales data of agricultural produce Figure 2.9: Component bar chart The component bar chart shows the changes of each component over the years as well as the comparison of the total sales between different years. 2.4.3 Grouped bar chart For a grouped bar chart, the components are grouped together and drawn side by side. We illustrate this with the above example. Figure 2.10: Grouped bar chart 2.5 Histogram and Bar chart Items HISTOGRAM BAR GRAPH Meaning Histogram refers to a graphical representation, that displays data by way of bars to show the frequency of numerical data. Bar graph is a pictorial representation of data that uses bars to compare different categories of data. Indicates Distribution of non-discrete variables Comparison of discrete variables Presents Quantitative data Categorical data Spaces Bars touch each other, hence there are no spaces between bars Bars do not touch each other, hence there are spaces between bars. Elements Elements are grouped together, so that they are considered as ranges. Elements are taken as individual entities. Can bars be reordered? No Yes Width of bars Need not to be same Same 2.6 Pie Charts A pie chart is a circular graph divided into sectors, each sector representing a different value or category. The angle of each sector of a pie chart is proportional to the value of the part of the data it represents. The bar chart is more precise than the pie chart for visual comparison of categories with similar relative frequencies. 2.6.1 Steps for constructing a pie chart Find the sum of the category values. Calculate the angle of the sector for each category, using the following formula.Angle of the sector for category A = \\(\\frac{\\text{value of category A}}{\\text{sum of category values}} \\times 360\\) Construct a circle and mark the centre. Use a protractor to divide the circle into sectors, using the angles obtained in step 2. Label each sector clearly. See the example: A lady spent the following sums of money on buying ingredients for a family Christmas cake. Ingredients Price Angle Flour 24 (24/240)×360= 36 Margarine 96 144 Sugar 18 27 Eggs 60 90 Baking powder 12 18 Miscellaneous 30 45 Total 240 360 Figure 2.11: Pie chart Statistics is the grammar of science.\" - Karl Pearson! "],["measures-of-central-tendency---i.html", "Chapter 3 Measures of central tendency - I 3.1 Arithmetic Mean 3.2 Merits and demerits of Arithmetic mean Merits 3.3 The median 3.4 Merits and Demerits of Median 3.5 The mode 3.6 Merits and Demerits of Mode", " Chapter 3 Measures of central tendency - I In the previous lecture, you have learnt how data can be summarised in the form of tables and presented in the form of graphs so that important features can be illustrated easily and more effectively. In this Lecture, we consider statistical measures which can be used to describe the characteristics of a set of data. We are interested in a single value that serves as a representative value of the overall data. A measure of central tendency is a summary statistic that represents the centre point or typical value of a dataset. There are five averages. Among them mean, median and mode are called simple averages and the other two averages geometric mean and harmonic mean are called special averages. These measures reflect numerical values in the centre of a set of data and are therefore called measures of central tendency. Requisites of a Good Measure of Central Tendency: It should be rigidly defined. It should be simple to understand &amp; easy to calculate It should be based upon all values of given data It should be capable of further mathematical treatment. It should have sampling stability. It should be not be unduly affected by extreme values The main objectives of Measure of Central Tendency To condense data in a single value. To facilitate comparisons between data. 3.1 Arithmetic Mean This is what people usually intend when they say \"average\". Arithmetic mean or simply the mean of a variable is defined as the sum of the observations divided by the number of observations. Mean of set of numbers \\(x_{1\\ },x_{2},\\ldots,x_{n}\\) is denoted as \\(\\overline{x}\\). It is given by the formula \\[\\overline{x} = \\frac{x_{1} + x_{2} + \\ldots + x_{n}}{n}\\] \\(= \\frac{1}{n}\\sum_{i = 1}^{n}x_{i}\\) Example 3.1 Find the mean of the numbers 2, 4, 7, 8, 11, 12 \\[\\overline{x} = \\frac{2 + 4 + 7 + 8 + 11 + 12}{6} = \\frac{44}{6} = 7.33\\] 3.1.1 The mean of a frequency distribution 3.1.1.1 Direct method If the numbers \\(x_{1\\ },x_{2},\\ldots,x_{n}\\) occur with frequencies \\(f_{1\\ },f_{2},\\ldots,f_{n}\\) respectively then \\[\\overline{x} = \\frac{x_{1}f_{1} + x_{2}f_{2\\ \\ } + \\ldots + x_{n}f_{n}}{f_{1} + f_{2} + \\ldots f_{n}}\\] \\[= \\frac{\\sum_{i = 1}^{n}{f_{i}x_{i}}}{\\sum_{i = 1}^{n}f_{i}}\\] Example 3.2 Table below shows the body masses of 50 men. Find the mean body mass. Table 3.1: Body masses of 50 men. Mass(kg) 59 60 61 62 63 Frequency 3 9 23 11 4 Solution 3.2 The calculation can be arranged as shown Mass(x) Frequency(f) fx 59 3 177 60 9 540 61 23 1403 62 11 682 63 4 252 \\(\\sum_{i = 1}^{n}f_{i}\\)= 50 \\(\\sum_{i = 1}^{n}{f_{i}x_{i}}\\)= 3054 \\(\\overline{x} = \\frac{\\sum_{i = 1}^{n}{f_{i}x_{i}}}{\\sum_{i = 1}^{n}f_{i}} = \\frac{3054}{50}\\)= 61.08 kg 3.1.1.2 Assumed mean method (Indirect method) The amount of computation involved above can be reduced by using the following formula: \\[\\overline{x} = A + \\frac{\\sum_{i = 1}^{n}{f_{i}d_{i}}}{\\sum_{i = 1}^{n}f_{i}}\\] Where \\(A\\) is the assumed mean, which can be any value in x. \\(d_{i} = x_{i} - A\\), \\(f_{i}\\) is the frequency of \\(x_{i}\\) Consider the Example 2.2 see Table: 3.1 let \\(A\\) = 61; it can be any number in x Mass(x) Frequency(f) \\[\\mathbf{d}_{\\mathbf{i}}\\mathbf{=}\\mathbf{x}_{\\mathbf{i}}\\mathbf{-}\\mathbf{61}\\] \\[\\mathbf{f}_{\\mathbf{i}}\\mathbf{d}_{\\mathbf{i}}\\] 59 3 -2 -6 60 9 -1 -9 61 23 0 0 62 11 1 11 63 4 2 8 \\(\\sum_{i = 1}^{n}f_{i}\\)= 50 \\(\\sum_{i = 1}^{n}{f_{i}d_{i}}\\)= 4 \\(\\overline{x} = 61 + \\frac{4}{50}\\) = 61.08 kg The mean mass is 61.08 kg 3.1.2 Mean of Grouped Data 3.1.2.1 Direct method The mean for grouped data is obtained from the following formula: \\[\\overline{x} = \\frac{\\sum_{i = 1}^{k}{f_{i}x_{i}}}{n}\\] Where \\(x_{i}\\) = the mid-point of ith class (ith class mark); \\(f_{i}\\)= the frequency of ith class; \\(n\\) = the sum of the frequencies or total frequencies in a sample. Note that i =1,2..., k, i.e. there are k classes. Example 3.3 Shows the distribution of the marks scored by 60 students in a Physics examination. Find the mean mark. Table 3.2: Distribution of the marks scored by 60 students Mark (%) 60-65 65-70 70-75 75-80 80-85 Number of students 2 15 25 14 4 Solution 3.3 The solution can be arranged as shown Marks Class mark(\\(\\mathbf{x}_{\\mathbf{i}}\\)) Frequency(\\(\\mathbf{f}_{\\mathbf{i}}\\)) \\[\\mathbf{f}_{\\mathbf{i}}\\mathbf{x}_{\\mathbf{i}}\\] 60-65 62.5 2 125 65-70 67.5 15 1012.5 70-75 72.5 25 1812.5 75-80 77.5 14 1085 80-85 82.5 4 330 \\(\\sum_{i = 1}^{n}f_{i}\\)= 60 \\(\\sum_{i = 1}^{n}{f_{i}x_{i}}\\)= 4365 \\(\\overline{x} = \\frac{\\sum_{i = 1}^{n}{f_{i}x_{i}}}{\\sum_{i = 1}^{n}f_{i}} = \\frac{4365}{60}\\)= 72.75 The mean mark is 72.75% 3.1.2.2 Coding method (Indirect method) If all the class intervals of a grouped frequency distribution have equal size \\(C\\) (class width); then the following formula can be used instead of direct method above. This formula makes calculations easier. \\[\\overline{x} = A + C\\frac{\\sum_{i = 1}^{n}{f_{i}u_{i}}}{\\sum_{i = 1}^{n}f_{i}}\\] Where \\(A\\) is the he class mark with the highest frequency, \\(u_{i} = \\frac{x_{i} - A}{C}\\), \\(f_{i}\\) is the frequency of \\(x_{i}\\), C is the class width This is called the coding method for computing the mean. It is a very short method and should always be used for finding the mean of a grouped frequency distribution with equal class widths. Consider the Example 3.3 see Table:3.2 \\(A\\)=72.5, class mark with highest frequency; \\(C\\) =5 Marks Class mark(\\(\\mathbf{x}_{\\mathbf{i}}\\)) Frequency(\\(\\mathbf{f}_{\\mathbf{i}}\\)) \\[\\mathbf{u}_{\\mathbf{i}}\\mathbf{=}\\frac{\\mathbf{x}_{\\mathbf{i}}\\mathbf{- 72.5}}{\\mathbf{5}}\\] \\[\\mathbf{f}_{\\mathbf{i}}\\mathbf{u}_{\\mathbf{i}}\\] 60-65 62.5 2 -2 -4 65-70 67.5 15 -1 -15 70-75 72.5 25 0 0 75-80 77.5 14 1 14 80-85 82.5 4 2 8 \\(\\sum_{i = 1}^{k}f_{i}\\)= 60 \\(\\sum_{i = 1}^{k}{f_{i}u_{i}}\\)=3 \\(\\overline{x} = 72.5 + 5 \\times \\left( \\frac{3}{60} \\right)\\)= 72.75 The mean mark is 72.75% 3.2 Merits and demerits of Arithmetic mean Merits Merits It is rigidly defined. It is easy to understand and easy to calculate. If the number of items is sufficiently large, it is more accurate and more reliable. It is a calculated value and is not based on its position in the series. It is possible to calculate even if some of the details of the data are lacking. Of all averages, it is affected least by fluctuations of sampling. It provides a good basis for comparison. Demerits It cannot be obtained by inspection nor located through a frequency graph. It cannot be in the study of qualitative phenomena not capable of numerical measurement i.e. Intelligence, beauty, honesty etc. It can ignore any single item only at the risk of losing its accuracy. It is affected very much by extreme values. It cannot be calculated for open-end classes. It may lead to fallacious conclusions, if the details of the data from which it is computed are not given. 3.3 The median The median of a set of data is defined as the middle value when the data is arranged in order of magnitude. If there are no ties, half of the observations will be smaller than the median, and half of the observations will be larger than the median. The median can be the middle most item that divides the group into two equal parts, one part comprising all values greater, and the other, all values less than that item. It is a positional measure. 3.3.1 Median of ungrouped or raw data Arrange the given n observations \\(x_{1\\ },x_{2},\\ldots,x_{n}\\) in ascending order. If the number of values is odd, median is the middle value. If the number of values is even, median is the mean of middle two values. Arrange data in ascending then use the following formula When n is odd, Median = Md =\\(\\left( \\frac{n + 1}{2} \\right)^{\\text{th}}\\)value When n is even, Median = Md =\\({\\text{Average\\ of\\ }\\left( \\frac{n}{2} \\right)^{th}\\text{and\\ }\\left( \\frac{n}{2} + 1 \\right)}^{\\text{th}}\\)value Example 3.4 Find the median of each of the following sets of numbers. (a) 12, 15, 22, 17, 20, 26, 22, 26, 12 (b) 4, 7, 9, 10, 5, 1, 3, 4, 12, 10 Solution 3.4 (a) Arranging the data in an increasing order of magnitude, we obtain 12, 12, 15, 17, 20, 22, 22, 26, 26. Here, N (= 9) is odd, and so, median =\\(\\left( \\frac{9 + 1}{2} \\right)^{\\text{th}}\\)= 5th ordered observation = 20. Note: If a number is repeated, we still count it the number of times it appears when we calculate the median. (b) Arranging the data in an increasing order of magnitude, we obtain 1, 3, 4, 4, 5, 7, 9, 10, 10, 12. Here, N(=10) is an even number and so median = \\(\\frac{1}{2}\\){5th ordered observation + 6th ordered observation} = \\(\\frac{1}{2}\\left( 5 + 7 \\right) = 6\\). Note: You can see in each case, the median divides the distribution into two equal parts, with 50% of the observations greater than it and the other 50% less than it. 3.3.2 Median of ungrouped frequency distribution The median is the middle number is an ordered set of data. In a frequency table, the observations are already arranged in an ascending order. We can obtain the median by looking for the value in the middle position. 3.3.2.1 Median of a frequency table when the number of observations is odd When the number of observations (n) is odd, then the median is the value at the \\(\\left( \\frac{n + 1}{2} \\right)^{\\text{th}}\\) positional value. For that we use less than cumulative frequency. Example 3.5: The following is a frequency table of the score obtained in a mathematics quiz. Find the median score. Table 3.3: Score obtained in a mathematics quiz. Score 0 1 2 3 4 Frequency 3 4 7 6 3 Solution 3.5: Total frequency = 3 + 4 + 7 + 6 + 3 = 23 (odd number). Since the number of scores is odd, the median is at \\(\\left( \\frac{23 + 1}{2} \\right)^{\\text{th}} =\\) 12th position. To find out the 12th position, we use less than cumulative frequencies as shown: Score 0 1 2 3 4 Frequency 3 4 7 6 3 less than cumulative frequency 3 7 14 20 23 The 12th position is after the 7th position but before the 14th position. So, the median is 2. 3.3.2.2 Median of a frequency table when the number of observations is even When the number of observations is even, then the median is the average of \\({\\left( \\frac{n}{2} \\right)^{th}\\text{and\\ }\\left( \\frac{n}{2} + 1 \\right)}^{\\text{th}}\\) position values. Example 3.6: The table is a frequency table of the marks obtained in a competition. Find the median score. Table 3.4: Distribution of marks obtained in a competition. Mark 0 1 2 3 4 Frequency 11 9 5 10 15 Solution 3.6: Total frequency = 11 + 9 + 5 + 10 + 15 = 50 (even number). Since the number of scores is even, the median is at the average of the values in \\({\\left( \\frac{n}{2} \\right)^{th} = 25\\ and\\ \\left( \\frac{n}{2} + 1 \\right)}^{\\text{th}} = 26\\) positions. To find out the 25th position and 26th position, we add up the frequencies as shown: Mark 0 1 2 3 4 Frequency 11 9 5 10 15 less than cumulative frequency 11 20 25 35 50 The mark at the 25th position is 2 and the mark at the 26th position is 3. The median is the average of the scores at 25th and 26th positions = \\(\\frac{2 + 3}{2} = 2.5\\) 3.3.3 Median of grouped frequency distribution The exact value of the median of a grouped data cannot be obtained because the actual values of a grouped data are not known. For a grouped frequency distribution, the median is in the class interval which contains the \\(\\left( \\frac{N}{2} \\right)^{\\text{th}}\\)ordered observation, where \\(N\\) is the total number of observations. This class interval is called the median class. The median of a grouped frequency distribution can be estimated by either of the following two methods: 3.3.3.1 Linear interpolation method for estimating the median The median of a grouped frequency distribution can be estimated by linear interpolation. We assume that the observations are evenly spread through the median class. The median can then be computed by using the following formula: \\[median = L + \\left( \\frac{\\frac{1}{2}N - F}{f_{m}} \\right)C\\] where \\(N\\) = total number of observations, \\(L\\) = lower limit of the median class, \\(F\\) = sum of all frequencies below L(cumulative frequency), \\(f_{m}\\) = frequency of the median class, \\(C\\) = class width of the median class. 3.3.3.2 Estimation of the median from a cumulative frequency curve The median of a grouped frequency distribution can be estimated from a cumulative frequency curve. A horizontal line is drawn from the point \\(\\frac{\\text{N\\ }}{2}\\) on the vertical axis to meet the cumulative frequency curve. From the point of intersection, a vertical line is dropped to the horizontal axis. The value on the horizontal axis is equal to the median. Figure 3.1: median from a cumulative frequency curve Example 3.7 Table below gives the distribution of the heights of 60 students in a Senior High school. Find the median height of the students Table 3.5: Distribution of heights of 60 students Height(cm) 145-150 150-155 155-160 160-165 165-170 170-175 Number of students 3 9 16 18 10 4 Solution 3.7 (i) Linear interpolation method for estimating the median \\(N\\) = 60 Median class= class interval which contains the \\(\\left( \\frac{N}{2} \\right)^{\\text{th}}\\)ordered observation; here \\(\\left( \\frac{60}{2} \\right)^{\\text{th}} =\\) 30th observation. Before the class 160-165 there are 3+9+16=28 observations so 30th observation will be in the class 160-165, therefore it is the median class. \\(L\\) = lower limit of the median class =160 \\(F\\) = sum of all frequencies below 160(cumulative frequency) = 16+9+3= 28 \\(f_{m}\\) = frequency of the median class=18 \\(C\\) = class width of the median class=5 \\(median = 160 + \\left( \\frac{\\frac{1}{2}60 - 28}{18} \\right)5\\) = 160.56 (ii) Estimation of the median from a cumulative frequency curve Figure 3.2: Median from a cumulative frequency curve Example 3.7 3.4 Merits and Demerits of Median Merits Median is not influenced by extreme values because it is a positional average. Median can be calculated in case of distribution with open-end intervals Median can be located even if the data are incomplete. Demerits A slight change in the series may bring drastic change in median value. In case of even number of items or continuous series, median is an estimated value other than any value in the series. It is not suitable for further mathematical treatment except its use in calculating mean deviation. It does not take into account all the observations 3.5 The mode The mode of a set of data is the value which occurs with the greatest frequency. The mode is therefore the most common value. The mode is an important measure in case of qualitative data. The mode can be used to describe both quantitative and qualitative data. 3.5.1 Mode of ungrouped or raw data For ungrouped data or a series of individual observations, mode is often found by mere inspection. Example 3.8 (a) The mode of 1, 2, 2, 2, 3 is 2. (b) The modes of 2, 3, 4, 4, 5, 5 are 4 and 5. (c) The mode does not exist when every observation has the same frequency. For example, the following sets of data have no modes: (i) 3, 6, 8, 9; (ii) 4, 4, 4, 7, 7, 7, 9, 9, 9. Note: It can be seen that the mode of a distribution may not exist, and even if it exists, it may not be unique. Distributions with a single mode are referred to as unimodal. Distributions with two modes are referred to as bimodal. Distributions may have several modes, in which case they are referred to as multimodal. Example 3.9 20 patients selected at random had their blood groups determined. The results are given in the table below Table 3.6: Blood groups of 20 patients Blood group A AB B O No. of patients 2 4 6 8 The blood group with the highest frequency is O. The mode of the data is therefore blood group O. We can say that most of the patients selected have blood group O. Notice that the mean and the median cannot be applied to the data. This is because the variable blood group cannot take numerical values. However, it can be seen that the mode can be used to describe both quantitative and qualitative data. 3.5.2 Mode of Grouped frequency distribution \\[mode = L + \\left( \\frac{f_{s}}{f_{p} + f_{s}} \\right)C\\] Locate the highest frequency the class corresponding to that frequency is called the modal class. Where \\(L\\) = lower limit of the model class; \\(f_{p}\\)= the frequency of the class preceding the model class; \\(f_{s}\\)= the frequency of the class succeeding the model class and \\(C\\) = class interval Example 3.10 For the frequency distribution of weights of sorghum ear-heads given in table below. Calculate the mode. Table 3.7: requency distribution of weights of sorghum ear heads Weights of ear heads (g) No of ear heads (f) 60-80 22 80-100 38 100-120 45 120-140 35 140-160 20 Modal class is 100-120 \\(mode = 100 + \\left( \\frac{35}{38 + 35} \\right)20 =\\) 109.589 3.5.3 Mode using Histogram Consider the figure below. The modal class is the class interval which corresponds to rectangle \\(\\text{ABCD}\\). An estimate of the mode of the distribution is the abscissa of the point of intersection of the line segments \\(\\overline{\\text{AE}}\\)and \\(\\overline{\\text{BF}}\\)in Figure 3.3: Median from a cumulative frequency curve for Example 3.10 3.6 Merits and Demerits of Mode Merits It is readily comprehensible and easy to compute. In some case it can be computed merely by inspection. It is not affected by extreme values. It can be obtained even if the extreme values are not known. Mode can be determined in distributions with open classes. Mode can be located on the graph also. Mode can be used to describe both quantitative and qualitative data. Demerits The mode is not unique. That is, there can be more than one mode for a given set of data. The mode of a set of data may not exist It is not based upon all the observation. If the statistics are boring, youve got the wrong numbers! "],["measures-of-central-tendency--ii.html", "Chapter 4 Measures of central tendency -II 4.1 Geometric mean 4.2 Merits and Demerits of Geometric mean 4.3 Harmonic mean 4.4 Merits and Demerits of Harmonic mean 4.5 Relation between AM, GM and HM 4.6 When to use AM, GM and HM? 4.7 Positional Averages 4.8 Quartiles 4.9 Percentiles 4.10 Deciles", " Chapter 4 Measures of central tendency -II 4.1 Geometric mean The geometric mean is a type of average, usually used for growth rates, like population growth or interest rates. While the arithmetic mean adds items, the geometric mean multiplies items. The geometric mean of a series containing n observations is the nth root of the product of the values. If \\(x_{1},\\ x_{2},\\ldots,\\ x_{n}\\ \\)are observations then \\[\\mathbf{\\text{Geometric mean}}\\mathbf{,\\ }\\mathbf{GM =}\\sqrt[\\mathbf{n}]{\\mathbf{x}_{\\mathbf{1}}\\mathbf{x}_{\\mathbf{2}}\\mathbf{\\ldots}\\mathbf{x}_{\\mathbf{n}}}\\] \\[\\mathbf{=}\\left( \\mathbf{x}_{\\mathbf{1}}\\mathbf{x}_{\\mathbf{2}}\\mathbf{\\ldots}\\mathbf{x}_{\\mathbf{n}} \\right)^{\\frac{\\mathbf{1}}{\\mathbf{n}}}\\] \\[\\mathbf{\\log}\\mathbf{\\text{GM}}\\mathbf{=}\\frac{\\mathbf{1}}{\\mathbf{n}}\\mathbf{\\log}\\left( \\mathbf{x}_{\\mathbf{1}}\\mathbf{x}_{\\mathbf{2}}\\mathbf{\\ldots}\\mathbf{x}_{\\mathbf{n}} \\right)\\] \\[\\mathbf{=}\\frac{\\mathbf{1}}{\\mathbf{n}}\\left( \\mathbf{\\log}\\mathbf{x}_{\\mathbf{1}}\\mathbf{+}\\mathbf{\\log}\\mathbf{x}_{\\mathbf{2}}\\mathbf{\\ldots +}\\mathbf{\\log}\\mathbf{x}_{\\mathbf{n}} \\right)\\] \\[\\mathbf{=}\\frac{\\sum_{\\mathbf{i = 1}}^{\\mathbf{n}}{\\mathbf{\\log}\\mathbf{x}_{\\mathbf{i}}}}{\\mathbf{n}}\\] \\[\\mathbf{\\ GM = Antilog}\\left( \\frac{\\sum_{\\mathbf{i = 1}}^{\\mathbf{n}}{\\mathbf{\\log}\\mathbf{x}_{\\mathbf{i}}}}{\\mathbf{n}} \\right)\\] 4.1.1 Geometric mean for grouped frequency table data \\[\\mathbf{GM = \\ Antilog}\\left( \\frac{\\sum_{\\mathbf{i = 1}}^{\\mathbf{k}}{{\\mathbf{f}_{\\mathbf{i}}\\mathbf{\\log}}\\mathbf{x}_{\\mathbf{i}}}}{\\mathbf{n}} \\right)\\] where \\(x_{i}\\) is the mid-value, \\(f_{i}\\) is the frequency , k is the number of classes Example 4.1: If the weight of sorghum ear heads are 45, 60, 48,100, 65 gms. Find the Geometric mean? Weight of ear head (x) log(x) 45 1.653 60 1.778 48 1.681 100 2.000 65 1.813 Total 8.926 Solution 4.1: Here n =5 Geometric mean= \\[\\text{Antilog}\\left( \\frac{\\sum_{i = 1}^{n}{\\log x_{i}}}{n} \\right) =\\] \\[Antilog\\left( \\frac{8.926}{5} \\right) =\\] \\[ Antilog(1.785) = 60.95\\] (note: here \\(\\text{Antilog}\\left( x \\right) = 10^{x}\\) i.e. \\[\\text{Antilog}\\left( 1.785 \\right) = \\ 10^{1.785} = 60.95\\] Example 4.2: Geometric mean of a Frequency Distribution Weight of ear head (x) Frequency(f) log(x) f[log(x)] 45 5 1.653 8.266 60 4 1.778 7.113 48 6 1.681 10.087 100 8 2.000 16.000 65 9 1.813 16.316 Total 32 57.782 Solution 4.2: Here n =32 \\[GM = \\ Antilog\\left( \\frac{\\sum_{i = 1}^{k}{{f_{i}\\log}x_{i}}}{n} \\right)\\] \\[{\\sum_{i = 1}^{k}{{f_{i}\\log}x_{i}} = 57.782 }\\] \\[{\\text{GM} = \\ Antilog\\left( \\frac{57.782}{32} \\right) }\\] \\[{= Antilog\\left( 1.8056 \\right)= 10^{1.8056} = 63.92}\\] Example 4.3: Geometric mean of a Grouped Frequency Distribution Class Mid value (x) Frequency(f) log(x) f[log(x)] 60-80 70 5 1.845 9.225 80-100 90 4 1.954 7.817 100-120 110 6 2.041 12.248 120-140 130 8 2.114 16.912 140-160 150 9 2.176 19.585 Total 32 65.787 Solution 4.4: Here n =32 \\[GM = \\ Antilog\\left( \\frac{\\sum_{i = 1}^{k}{{f_{i}\\log}x_{i}}}{n} \\right)\\] \\[{\\sum_{i = 1}^{k}{{f_{i}\\log}x_{i}} = 65.787}\\] \\[{\\text{GM} = \\ Antilog\\left( \\frac{65.787}{32} \\right)}\\] \\[{= Antilog\\left( 2.0558 \\right) = 10^{2.0558} = 113.72}\\] 4.2 Merits and Demerits of Geometric mean Merits It is rigidly defined. It is based on all the observations of the series. It is suitable for measuring the relative changes. It gives more weights to the small values and less weight to the large values. It is used in averaging the ratios, percentages and in determining the rate gradual increase and decrease. It is capable of further algebraic treatment. Demerits It is not easy to understand. It is difficult to calculate. It cannot be calculated, if the number of negative values is odd. It cannot be calculated, if any value of a series is zero. At times it gives a value which may not be found in the series or impractical. 4.3 Harmonic mean Harmonic means are often used in averaging things like rates (e.g. the average travel speed given duration of several trips). Harmonic mean (HM) of a set of observations is defined as the reciprocal of the arithmetic average of the reciprocal of the given value. If \\(x_{1},\\ x_{2},\\ldots,\\ x_{n}\\ \\)are n observations then \\[\\mathbf{\\text{H.M}} = \\frac{n}{\\sum_{i = 1}^{n}\\frac{1}{x_{i}}}\\] In case of Frequency distribution \\[\\mathbf{\\text{H.M}} = \\frac{n}{\\sum_{i = 1}^{k}{f_{i}\\frac{1}{x_{i}}}}\\] where \\(x_{i}\\) is the mid-value, \\(f_{i}\\) is the frequency , k is the number of classes 4.3.1 Steps in calculating Harmonic Mean (H.M) Calculate the reciprocal (1/value) for every value. Find the average of those reciprocals (just add them and divide by how many there are) Then do the reciprocal of that average (=1/average) Example 4.4: From the given data 5, 10, 17, 24, 30 calculate H.M Solution 4.4: Here n = 5 x 1/x 5 0.2 10 0.1 17 0.058824 24 0.041667 30 0.033333 Total 0.433824 \\[\\mathbf{\\text{H.M}} = \\frac{n}{\\sum_{i = 1}^{n}\\frac{1}{x_{i}}} = \\frac{5}{0.433824} = 11.525\\] Example 4.5: Number of tomatoes per plant are given below. Calculate the harmonic mean. No. of Tomato per plants 20 21 22 23 24 25 No. of Plants 4 2 7 1 3 1 Solution 4.5: x f 1/x f.1/x 20 4 0.05 0.2 21 2 0.047619 0.095238 22 7 0.045455 0.318182 23 1 0.043478 0.043478 24 3 0.041667 0.125 25 1 0.04 0.04 18 0.821898 Here n =18 \\[\\mathbf{\\text{H.M}} = \\frac{n}{\\sum_{i = 1}^{n}{f_{i}\\frac{1}{x_{i}}}} = \\frac{18}{0.821898} = 21.90\\] 4.4 Merits and Demerits of Harmonic mean Merits It is rigidly defined. It is defined on all observations. It is amenable to further algebraic treatment. It is the most suitable average when it is desired to give greater weight to smaller and less weight to the larger ones. Demerits It is not easily understood. It is difficult to compute. It is only a summary figure and may not be the actual item in the series It gives greater importance to small items and is therefore, useful only when small items have to be given greater weightage. It is rarely used in grouped data. 4.5 Relation between AM, GM and HM If AM stands for Arithmetic Mean, GM stands for Geometric Mean and HM stands for Harmonic Mean; then \\[\\mathbf{\\text{AM}}\\mathbf{\\times}\\mathbf{\\text{HM}}\\mathbf{=}\\mathbf{\\text{GM}}^{\\mathbf{2}}\\] also \\[\\mathbf{AM \\geq GM \\geq HM}\\] 4.6 When to use AM, GM and HM? A practical answer is that it depends on what your numbers are measuring. If you are measuring units that add up linearly in a sequence; such as lengths, distances, weights, then an arithmetic mean will give you a meaningful average. For example, the arithmetic mean of the height or weight of students in a class represents the average height or weight of students in the class. Harmonic mean will give you a meaningful average, if you are measuring units that add up as reciprocals in a sequence; such as speed or distance travelled per unit time, capacitance in series, resistance in parallel. For example, the harmonic mean of capacitors in series represents the capacitance that a single capacitor would have if only one capacitor was used instead of the set of capacitors in series. If youre measuring units that multiply in a sequence; such as growth rates or percentages, then a geometric mean will give you a meaningful average. For example, the geometric mean of a sequence of different annual interest rates over 10 years represents an interest rate that, if applied constantly for ten years, would produce the same amount growth in principal as the sequence of different annual interest rates over ten years did. 4.7 Positional Averages Positional average of a series of values refers to the averages which are taken out from the series itself which represents the whole series or may have some positional properties. In median, the middle most value of the series is taken as the representative value. Therefore, median is a positional average. Mode is also a positional average as modal values are the most frequently occurring values that are directly taken from the series itself. Other positional averages include Percentiles, Quartiles and Deciles Note that Arithmetic mean, Harmonic mean and Geometric mean are termed as mathematical averages 4.8 Quartiles The median divides a set of data into two equal parts. We can also divide a set of data into more than two parts. When an ordered set of data is divided into four equal parts, the division points are called quartiles. The first or lower quartile (\\(\\mathbf{Q}_{\\mathbf{1}}\\)) is a value that has one fourth, or 25% of the observations below its value. The second quartile (\\(\\mathbf{Q}_{\\mathbf{2}}\\)), has one-half, or 50% of the observations below its value. The second quartile is equal to the median. The third or upper quartile, (\\(\\mathbf{Q}_{\\mathbf{3}}\\)), is a value that has three-fourths, or 75% of the observations below it. \\(\\mathbf{Q}_{\\mathbf{1}}\\mathbf{=}\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)^{\\mathbf{\\text{th}}}\\)item \\(\\mathbf{Q}_{\\mathbf{3}}\\mathbf{=}\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)^{\\mathbf{\\text{th}}}\\)item Calculations of quartiles are explained using the example below. See in the example the procedure followed when a fraction appear in the calculation. Example 4.6: Compute quartiles for the data 25, 18, 30, 8, 15, 5, 10, 35, 40, 45 Solution 4.6: First arrange the data in ascending order 5, 8, 10, 15, 18, 25, 30, 35, 40, 45 here n = 10 \\(\\mathbf{Q}_{\\mathbf{1}}\\mathbf{=}\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)^{\\mathbf{\\text{th}}}\\)item i.e. \\(Q_{1} = \\left( \\frac{10 + 1}{4} \\right)^{th}\\) = 2.75th item; when such a fraction appears we use the following procedure \\(Q_{1} = \\ \\)2.75th item = 2nd item + 0.75(3rd item  2nd item) So from the given data \\(Q_{1}\\)= 8+0.75(10 8) = 9.5 \\[\\mathbf{Q}_{\\mathbf{2}}\\mathbf{= median}\\] here \\(Q_{2} = \\ \\)(18+25)/2 = 21.5 \\(\\mathbf{Q}_{\\mathbf{3}}\\mathbf{=}\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)^{\\mathbf{\\text{th}}}\\)item i.e. \\(Q_{3} = \\left( 3 \\times \\frac{(10 + 1)}{4} \\right)^{th}\\) = 8.25th item = 8th item + 0.25(9th item 8th item) = 35+0.25(40-35) =36.25 4.8.1 Quartiles of a discrete frequency data Find cumulative frequencies. Find \\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\) See in the cumulative frequencies, the value just greater than \\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\) , then the corresponding value of \\(x\\) is \\(Q_{1}\\) Find \\(\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)\\) See in the cumulative frequencies, the value just greater than \\(\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)\\) ,then the corresponding value of \\(x\\) is \\(Q_{3}\\) Example 4.7: Compute quartiles for the data given bellow \\[\\mathbf{x}\\] 5 8 12 15 19 24 30 \\[\\mathbf{f}\\] 4 3 2 4 5 2 4 Solution 4.7: x f cf 5 4 4 8 3 7 12 2 9 15 4 13 19 5 18 24 2 20 30 4 24 Here n =24 \\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\) = \\(\\left( \\frac{\\mathbf{n + 1}}{\\mathbf{4}} \\right)\\mathbf{\\ }\\)= \\(\\left( \\frac{\\mathbf{25}}{\\mathbf{4}} \\right)\\)= 6.25 The cumulative frequency value just greater than 6.25 is 7, the \\(\\mathbf{x}\\) value corresponding to cumulative frequency 7 is 8. So \\(\\mathbf{Q}_{\\mathbf{1}}\\)= 8. \\(\\left( \\frac{\\mathbf{3(n + 1)}}{\\mathbf{4}} \\right)\\) = \\(\\left( \\frac{\\mathbf{3}\\mathbf{\\times}\\mathbf{25}}{\\mathbf{4}} \\right)\\)= 18.75 The cumulative frequency value just greater than 18.75 is 20, the \\(\\mathbf{x}\\) value corresponding to cumulative frequency 20 is 24. So \\(\\mathbf{Q}_{\\mathbf{3}}\\)= 24. 4.8.2 Quartiles of a continuous frequency data Find cumulative frequencies Find \\(\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\) See in the cumulative frequencies, the value just greater than\\(\\ \\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\), and then the corresponding class interval is called first quartile class. Find \\(3\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\) See in the cumulative frequencies the value just greater than \\(3\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\mathbf{\\ }\\)then the corresponding class interval is called 3rd quartile class. Then apply the respective formulae \\[\\mathbf{Q}_{\\mathbf{1}}\\mathbf{=}\\mathbf{l}_{\\mathbf{1}}\\mathbf{+}\\frac{\\frac{\\mathbf{n}}{\\mathbf{4}}\\mathbf{-}\\mathbf{m}_{\\mathbf{1}}}{\\mathbf{f}_{\\mathbf{1}}}\\mathbf{\\times}\\mathbf{c}_{\\mathbf{1}}\\] \\[\\mathbf{Q}_{\\mathbf{3}}\\mathbf{=}\\mathbf{l}_{\\mathbf{3}}\\mathbf{+}\\frac{\\mathbf{3}\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\mathbf{-}\\mathbf{m}_{\\mathbf{3}}}{\\mathbf{f}_{\\mathbf{3}}}\\mathbf{\\times}\\mathbf{c}_{\\mathbf{3}}\\] Where \\(l_{1}\\) = lower limit of the first quartile class \\(f_{1}\\) = frequency of the first quartile class \\(c_{1}\\) = width of the first quartile class \\(m_{1}\\) = cumulative frequency preceding the first quartile class \\(l_{3}\\)= 1ower limit of the 3rd quartile class \\(f_{3}\\)= frequency of the 3rd quartile class \\(c_{3}\\)= width of the 3rd quartile class \\(m_{3}\\) = cumulative frequency preceding the 3rd quartile class Example 4.8: Find the quartiles for the grouped frequency data given Class frequency cumulative frequency 0-10 11 11 10-20 18 29 20-30 25 54 30-40 28 82 40-50 30 112 50-60 33 145 60-70 22 167 70-80 15 182 80-90 12 194 90-100 10 204 Solution 4.8: \\(\\left( \\frac{n}{4} \\right)\\) = \\(\\frac{204}{4}\\) = 51 The cumulative frequency value just greater than 51 is 54 so the class 20-30 is the 1st quartile class \\[\\mathbf{Q}_{\\mathbf{1}}\\mathbf{=}\\mathbf{l}_{\\mathbf{1}}\\mathbf{+}\\frac{\\frac{\\mathbf{n}}{\\mathbf{4}}\\mathbf{-}\\mathbf{m}_{\\mathbf{1}}}{\\mathbf{f}_{\\mathbf{1}}}\\mathbf{\\times}\\mathbf{c}_{\\mathbf{1}}\\] \\[\\mathbf{= 20 +}\\frac{\\mathbf{51 - 29}}{\\mathbf{25}}\\mathbf{\\times 10\\ = 28.8}\\] \\(3\\left( \\frac{n}{4} \\right)\\) = \\(3 \\times \\frac{204}{4}\\) = 153 The cumulative frequency value just greater than 153 is 167 so the class 60-70 is the 3rd quartile class \\[\\mathbf{Q}_{\\mathbf{3}}\\mathbf{=}\\mathbf{l}_{\\mathbf{3}}\\mathbf{+}\\frac{\\mathbf{3}\\left( \\frac{\\mathbf{n}}{\\mathbf{4}} \\right)\\mathbf{-}\\mathbf{m}_{\\mathbf{3}}}{\\mathbf{f}_{\\mathbf{3}}}\\mathbf{\\times}\\mathbf{c}_{\\mathbf{3}}\\] \\[\\mathbf{= 60 +}\\frac{\\mathbf{153 - 145}}{\\mathbf{22}}\\mathbf{\\times 10 = 63.63}\\] 4.9 Percentiles The percentile values divide an ordered set of data into 100 equal parts each containing 1 percent of the observations. The xth percentile, denoted as \\(P_{x}\\) is that value below which x percent of values in the distribution fall. It may be noted that the median is the 50th percentile, 25th percentile is first quartile \\(Q_{1}\\) and 75th percentile is\\(\\text{\\ Q}_{3}\\ \\) For raw data, first arrange the n observations in increasing order. Then the xth percentile is given by \\(\\mathbf{P}_{\\mathbf{x}}\\mathbf{=}\\left( \\frac{\\mathbf{x}\\left( \\mathbf{n + 1} \\right)}{\\mathbf{100}} \\right)^{\\mathbf{\\text{th}}}\\)item For a frequency distribution the xth percentile is given by following steps Find cumulative frequencies Find \\(\\left( \\frac{\\text{x.n}}{100} \\right)\\) See in the cumulative frequencies, the value just greater than\\(\\left( \\frac{\\text{x.n}}{100} \\right)\\)and then the corresponding class interval is called Percentile class. Use the following formula \\[\\mathbf{P}_{\\mathbf{x}}\\mathbf{= l +}\\frac{\\left( \\frac{\\mathbf{x \\times n}}{\\mathbf{100}} \\right)\\mathbf{- cf}}{\\mathbf{f}}\\mathbf{\\times c}\\] Where \\(\\mathbf{l}\\) = lower limit of the percentile class \\(\\mathbf{\\text{cf}}\\) = cumulative frequency preceding the percentile class \\(\\mathbf{f}\\) = frequency of the percentile class \\(\\mathbf{c}\\) = class interval \\(\\mathbf{n}\\) = total number of observations Example 4.9: Compute \\(\\mathbf{P}_{\\mathbf{25}}\\)and \\(\\mathbf{P}_{\\mathbf{75}}\\) for the data 25, 18, 30, 8, 15, 5, 10, 35, 40, 45 Solution 4.9: First arrange the data in ascending order 5, 8, 10, 15, 18, 25, 30, 35, 40, 45 Here n =10 \\(\\mathbf{P}_{\\mathbf{25}}\\mathbf{=}\\left( \\frac{\\mathbf{25}\\left( \\mathbf{10 + 1} \\right)}{\\mathbf{100}} \\right)^{\\mathbf{\\text{th}}}\\)= 2.75th item \\(P_{25} = \\ \\)2.75th item = 2nd item + 0.75(3rd item  2nd item) So from the given data \\(P_{25}\\)= 8+0.75(10 8) = 9.5 \\(\\mathbf{P}_{\\mathbf{75}}\\mathbf{=}\\left( \\frac{\\mathbf{75}\\left( \\mathbf{10 + 1} \\right)}{\\mathbf{100}} \\right)^{\\mathbf{\\text{th}}}\\)= 8.25th item i.e. \\(P_{75} = \\left( 75 \\times \\frac{10 + 1}{100} \\right)^{th}\\) = 8.25th item = 8th item + 0.25(9th item 8th item) = 35+0.25(40-35) =36.25 Note: Data in this example is same as Example 3.6; it can be seen that \\(P_{25} = Q_{1}\\) &amp; \\(P_{75} = Q_{3}\\) always Assignment 1: Find \\(\\text{P}_{25}\\), \\(P_{50}\\)&amp; \\(P_{75}\\)for Example 4.7 &amp; 4.8; verify that \\(P_{50} = Q_{2}\\), \\(P_{25} = Q_{1}\\) &amp; \\(P_{75} = Q_{3}\\) 4.10 Deciles Deciles are similar to quartiles. But while quartiles are three points that divide an ordered set of data into four quarters, deciles are 9 points that divide an ordered set of data into ten equal parts. The xth decile is denoted as\\(\\text{\\ d}_{x}\\). It may be noted that the median is the 5thdecile. \\(\\mathbf{d}_{\\mathbf{x}}\\mathbf{=}\\left( \\frac{\\mathbf{x}\\left( \\mathbf{n + 1} \\right)}{\\mathbf{10}} \\right)^{\\mathbf{\\text{th}}}\\)item For a frequency distribution the xth decile is given by following steps Find cumulative frequencies Find \\(\\left( \\frac{\\text{x.n}}{10} \\right)\\) See in the cumulative frequencies, the value just greater than\\(\\left( \\frac{\\text{x.n}}{10} \\right)\\)and then the corresponding class interval is called decile class. Use the following formula \\[\\mathbf{d}_{\\mathbf{x}}\\mathbf{= l +}\\frac{\\left( \\frac{\\mathbf{x \\times n}}{\\mathbf{10}} \\right)\\mathbf{- cf}}{\\mathbf{f}}\\mathbf{\\times c}\\] Where \\(\\mathbf{l}\\) = lower limit of the decile class \\(\\mathbf{\\text{cf}}\\) = cumulative frequency preceding the decile class \\(\\mathbf{f}\\) = frequency of the decile class \\(\\mathbf{c}\\) = class interval \\(\\mathbf{n}\\) = total number of observations Assignment 2: Find \\(\\text{D}_{5}\\) for Example 4.6, 4.7 &amp; 4.8; verify that \\(\\text{D}_{5} = \\text{Q}_{2} = \\text{P}_{50} = median\\) The best thing about being a statistician is that you get to play in everybody elses backyard.  John Tukey "],["measures-of-dispersion.html", "Chapter 5 Measures of Dispersion 5.1 Characteristics of a good measure of dispersion 5.2 The Range 5.3 The Inter-Quartile Range (IQR) or Midspread 5.4 Mean Absolute Deviation (MAD) 5.5 The variance and standard deviation 5.6 Coefficient of Variation (relative measure of dispersion)", " Chapter 5 Measures of Dispersion We discussed in previous lectures, how a set of data can be summarized by a single representative value which describes the central value of the data. Consider the two sets of data A &amp; B below Data sets A 1 2 3 3 4 5 B -1 0 3 3 5 8 You can see mean, median and mode for both the sets A &amp; B is 3 See the dot diagrams of data sets A and B. Figure 5.1: Scatter diagram of data sets A &amp; B It can be seen that, while values of data set A are grouped close to their mean, while the values of data set B are more spread out. We say that values of data set B are more dispersed (or scattered) than those of data set A This example shows that the mean, the mode and the median, are not enough in describing a set of data. In addition to using these measures, we need a numerical measure of dispersion (or variation) of a set of data. Statistical dispersion means the extent to which a numerical data is likely to vary about an average value. 5.1 Characteristics of a good measure of dispersion An ideal measure of dispersion is expected to possess the following properties It should be rigidly defined It should be based on all the items. It should not be unduly affected by extreme items. It should lend itself for algebraic manipulation. It should be simple to understand and easy to calculate The most important measures of dispersion are the Range, the Inter-quartile range, Mean Absolute Deviation (MAD)and the standard deviation. 5.2 The Range This is the simplest possible measure of dispersion. The range of a set of data is defined as the difference between the largest observation and the smallest observation in the set of data. Thus, Range = largest observation  smallest observation. In symbols, Range = L  S. Where L = Largest value; S = Smallest value. In individual observations and discrete series, L and S are easily identified. In continuous series, the following two methods are followed. 5.2.1 Method 1 L = Upper boundary of the highest class S = Lower boundary of the lowest class. 5.2.2 Method 2 L = Mid-value of the highest class. S = Mid-value of the lowest class. Example 5.1: The marks obtained by 8 students in Mathematics and Physics examinations are as follows: Mathematics: 35, 60, 70, 40, 85, 96, 55, 65. Physics: 50, 55, 70, 65, 89, 68, 72, 80. Find the ranges of the two sets of data. Are the Physics marks more dispersed than the Mathematics marks? Solution For Mathematics, Highest mark = 96, lowest mark = 35, range =96  35 = 61 For Physics, Highest mark = 89, lowest mark = 50, range =89  50 = 39. The mathematics marks have a wider range than the Physics marks. The Mathematics marks are therefore more dispersed than the Physics marks. Example 5.2: Calculate range from the following distribution Size 60-63 63-66 66-69 69-72 72-75 Number 5 18 42 27 8 Solution L = Upper boundary of the highest class = 75 S = Lower boundary of the lowest class = 60 Range = L  S = 75  60 = 15 5.2.3 Merits and Demerits of Range Merits It is simple to understand. It is easy to calculate. In certain types of problems like quality control, weather forecasts, share price analysis, etc. Demerits It is very much affected by the extreme items. It is based on only two extreme observations. It cannot be calculated from open-end class intervals. It is not suitable for mathematical treatment. It is a very rarely used measure. 5.3 The Inter-Quartile Range (IQR) or Midspread The range has the advantage that it is quick and easy to calculate. However, since it depends only on the maximum and the minimum values of a set of data, it does not show how the whole data is distributed between these two values. The range is therefore not a good measure of dispersion if one or both of these two values differ greatly from other values of the data. To overcome this problem, we sometimes use the inter-quartile range. A robust measure of dispersion is the inter-quartile range. The inter-quartile range of a set of data is the difference between the upper and lower quartiles of the data. Thus, Inter-Quartile Range (IQR) = Q3  Q1. The inter-quartile range of a set of data is therefore not affected by values of the data outside Q1 and Q3. The inter-quartile range is sometimes used as a measure of dispersion. Example 5.3: Consider the two sets of data below, find IQR A: 3, 4, 5, 6, 8, 9, 10, 12, 15 B: 3, 8, 8, 9, 9, 9, 10, 10, 15 For data set A, Q1 = 5, Q3 = 10; so Inter-Quartile Range =10  5 = 5 For data set B, Q1 = 8, Q3 = 10; so Inter-Quartile Range =10  8 = 2 Since the inter-quartile range of data set A is greater than that of data set B, these results confirm that data set A is more dispersed than data set B. You can also see Range is same for both the sets. 5.4 Mean Absolute Deviation (MAD) The mean absolute deviation (MAD) is a measure of variability that indicates the average distance between observations and their mean. MAD uses the original units of the data, which simplifies interpretation. Larger values signify that the data points spread out further from the average. Conversely, lower values correspond to data points bunching closer to it. The mean absolute deviation is also known as the mean deviation and average absolute deviation. Here is how to calculate the mean absolute deviation. Calculate the mean. Calculate the difference of each observation from mean and take absolute value i.e. ignore the sign. This difference is known as absolute deviation Add those deviations together. Divide the sum by the number of data points. \\[MAD = \\frac{\\sum_{i = 1}^{n}\\left| x_{i} - \\overline{x} \\right|}{n}\\] Example 5.4: find the mean absolute deviation of the following 10, 15, 15, 17, 18, 21 Sl.No. \\[x_{i}\\] \\[x_{i} - \\overline{x}\\] \\[\\left| x_{i} - \\overline{x} \\right|\\] 1 10 -6 6 2 15 -1 1 3 15 -1 1 4 17 1 1 5 18 2 2 6 21 5 5 \\(\\overline{x} =\\) 16 \\(\\sum_{i = 1}^{n}\\left| x_{i} - \\overline{x} \\right|\\) = 16 Here n = 6 and \\(\\sum_{i = 1}^{n}\\left| x_{i} - \\overline{x} \\right|\\) = 16 therefore MAD = \\(\\frac{16}{6} = 2.67\\) 5.4.1 Merits and Demerits of MAD Merits Simple And Easy Different items of observations can be easily compared with mean deviation Mean deviation is better than quartile deviation and range because it is based on all the observations of the series. Mean deviation is less affected by the extreme values in the series while comparing to standard deviation. Mean deviation is rigidly defined. So, it has fixed value. Demerits It becomes difficult to compute mean deviation in case of fractions. Mean deviation is not applicable for algebraic calculations. It cannot be calculated from open-end class intervals. Mean deviation is not a good measure as it ignores negative signs of deviations. 5.5 The variance and standard deviation The most important measures of variability are the sample variance and the sample standard deviation. If x1, x2 xn is a sample of n observations, then the sample variance is denoted by s² and is defined by the equation. \\[{\\mathbf{\\text{sample variance}},\\ \\mathbf{s}}^{\\mathbf{2}}\\mathbf{=}\\frac{\\sum_{\\mathbf{i = 1}}^{\\mathbf{n}}\\left( \\mathbf{x}_{\\mathbf{i}}\\mathbf{-}\\overline{\\mathbf{x}} \\right)^{\\mathbf{2}}}{\\mathbf{n - 1}}\\] The sample standard deviation, s, is the positive square root of the sample variance. \\[\\mathbf{variance =}\\left( \\mathbf{\\text{standard deviation}} \\right)^{\\mathbf{2}}\\] \\[\\mathbf{standard\\ deviation = \\ }\\sqrt{\\mathbf{\\text{variance}}}\\] Note: If sA, the standard deviation of data set A, is greater than sB, the standard deviation of data set B, then data set A is more dispersed than data set B. It should be noted that the standard deviation of a set of data is a non-negative number. Example 5.4: Consider the two sets of data A &amp; B below; find standard deviation? A 1 2 3 3 4 5 B -1 0 3 3 5 8 Solution: Set A \\[\\mathbf{x}_{\\mathbf{i}}\\] \\[\\left( \\mathbf{x}_{\\mathbf{i}}\\mathbf{-}\\overline{\\mathbf{x}} \\right)\\] \\[\\left( \\mathbf{x}_{\\mathbf{i}}\\mathbf{-}\\overline{\\mathbf{x}} \\right)^{\\mathbf{2}}\\] 1 -2 4 2 -1 1 3 0 0 3 0 0 4 1 1 5 2 4 Sum 18 0 10 Mean (\\(\\overline{x}\\)) =\\(\\ \\frac{18}{6} = 3\\) \\[{Sample\\ variane,\\ s}_{A}^{2} = \\frac{\\sum_{i = 1}^{n}\\left( x_{i} - \\overline{x} \\right)^{2}}{n - 1} = \\frac{10}{5} = 2\\] \\[\\text{sample standard deviation,}\\ s_{A} = \\ \\sqrt{s_{A}^{2}} = \\ \\sqrt{2} = 1.414\\] Set B \\[\\mathbf{x}_{\\mathbf{i}}\\] \\[\\left( \\mathbf{x}_{\\mathbf{i}}\\mathbf{-}\\overline{\\mathbf{x}} \\right)\\] \\[\\left( \\mathbf{x}_{\\mathbf{i}}\\mathbf{-}\\overline{\\mathbf{x}} \\right)^{\\mathbf{2}}\\] -1 -4 16 0 -3 9 3 0 0 3 0 0 5 2 4 8 5 25 Sum 18 0 54 Mean (\\(\\overline{x}\\)) =\\(\\ \\frac{18}{6} = 3\\) \\[{Sample\\ variane,\\ s}_{B}^{2} = \\frac{\\sum_{i = 1}^{n}\\left( x_{i} - \\overline{x} \\right)^{2}}{n - 1} = \\frac{54}{5} = 10.8\\] \\[sample\\ standard\\ deviation,\\ s_{B} = \\ \\sqrt{s_{B}^{2}} = \\ \\sqrt{10.8} = 3.29\\] It can be seen that \\(s_{B} &gt; s_{A}\\ \\), confirming that data set B is more dispersed than data set A (see the dot diagrams) Note: The unit of measurement of the sample variance is the square of the unit of measurement of the data. Sample standard deviation has same unit of measurement as of the data. Thus, if x is measured in centimetres (cm), then the unit of measurement of the sample variance is cm2 and that of sample standard deviation is cm. The standard deviation has the desirable property of measuring variability in the same unit as the data. An alternative formula for computing the variance The computation of s² requires calculations of \\(\\overline{x}\\), n subtractions and n squaring and adding operations. If the original observations or the deviations \\(\\left( x_{i} - \\overline{x} \\right)\\) are not integers, the deviations \\(\\left( x_{i} - \\overline{x} \\right)\\) may be difficult to work with, and several decimals may have to be carried to ensure numerical accuracy. A more efficient computational formula for s² is given by \\(s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{i = 1}^{n}{x_{i}^{2} - \\frac{1}{n}}\\left( \\sum_{i = 1}^{n}x_{i} \\right)^{2} \\right\\}\\) Example 5.5: Consider the data set below; find standard deviation? 3 4 5 6 8 9 10 12 15 Solution: \\[\\mathbf{x}_{\\mathbf{i}}\\] \\[\\mathbf{x}_{\\mathbf{i}}^{\\mathbf{2}}\\] 3 9 4 16 5 25 6 36 8 64 9 81 10 100 12 144 15 225 Sum 72 700 \\(s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{i = 1}^{n}{x_{i}^{2} - \\frac{1}{n}}\\left( \\sum_{i = 1}^{n}x_{i} \\right)^{2} \\right\\}\\) ; here n = 9 \\(s^{2} = \\frac{1}{8}\\left\\{ 700 - {\\frac{1}{9}\\left( 72 \\right)}^{2} \\right\\}\\) =15.5 \\(s = \\ \\sqrt{15.5} = 3.94\\) 5.5.1 Variance and standard deviation for grouped data 5.5.1.1 For discrete grouped data \\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{i = 1}^{n}{{f_{i}x}_{i}^{2} - \\frac{1}{n}}\\left( \\sum_{i = 1}^{n}{f_{i}x}_{i} \\right)^{2} \\right\\}\\] where \\(f_{i}\\) is the frequency of ith observation Example 5.6: The frequency distributions of seed yield of 50 sesamum plants are given below. Find the standard deviation. Seed yield in gms (x) 3 4 5 6 7 Frequency (f) 4 6 15 15 10 Solution: x f fx fx2 3 4 12 36 4 6 24 96 5 15 75 375 6 15 90 540 7 10 70 490 Total 50 271 1537 \\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{i = 1}^{n}{{f_{i}x}_{i}^{2} - \\frac{1}{n}}\\left( \\sum_{i = 1}^{n}{f_{i}x}_{i} \\right)^{2} \\right\\}\\] \\[{sample\\ variance,\\ s}^{2} = \\frac{1}{50 - 1}\\left\\{ 1537 - \\frac{271^{2}}{50} \\right\\} = 1.3914\\] \\(standard\\ deviation,\\ s = \\sqrt{1.3914}\\) = 1.179 5.5.1.2 For continuous grouped data \\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{i = 1}^{n}{{f_{i}d}_{i}^{2} - \\frac{1}{n}}\\left( \\sum_{i = 1}^{n}{f_{i}d}_{i} \\right)^{2} \\right\\}\\] where \\(f_{i}\\) is the frequency of ith class, c is the class interval, \\(d_{i} = \\frac{x_{i} - A}{c}\\), \\(x_{i}\\) is the class mark, \\(A\\) is the class mark with the highest frequency Example 5.7: The frequency distributions of seed yield of 50 sesamum plants are given below. Find the standard deviation Seed yield in gms (x) 2.5-3.5 3.5-4.5 4.5-5.5 5.5-6.5 6.5-7.5 Frequency (f) 4 6 15 15 10 Solution: Here n =50; c =1 Seed yield f x \\[d_{i} = \\frac{x_{i} - A}{c}\\] fd f d2 2.5-3.5 4 3 -2 -8 16 3.5-4.5 6 4 -1 -6 6 4.5-5.5 15 5 0 0 0 6.5-7.5 15 6 1 15 15 7.5-8.5 10 7 2 20 40 Total 50 25 0 21 77 A = 5 \\[s^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{i = 1}^{n}{{f_{i}d}_{i}^{2} - \\frac{1}{n}}\\left( \\sum_{i = 1}^{n}{f_{i}d}_{i} \\right)^{2} \\right\\}\\] \\[{sample\\ variance,\\ s}^{2} = \\frac{1}{49}\\left( 77 - \\frac{\\left( 21 \\right)^{2}}{50} \\right) = \\ 1.3914\\] \\(standard\\ deviation,\\ s = \\sqrt{1.3914}\\) = 1.179 5.5.2 Merits and Demerits of Standard Deviation Merits It is rigidly defined and its value is always definite and based on all the observations As it is based on arithmetic mean, it has all the merits of arithmetic mean. It is the most important and widely used measure of dispersion. It is possible for further algebraic treatment. It is less affected by the fluctuations of sampling and hence stable. It is the basis for measuring the coefficient of correlation and other measures. Demerits It is not easy to understand and it is difficult to calculate. It gives more weight to extreme values because the values are squared up. As it is an absolute measure of variability, it cannot be used for the purpose of comparison. 5.6 Coefficient of Variation (relative measure of dispersion) The Standard deviation is an absolute measure of dispersion. It is expressed in terms of units in which the original figures are collected and stated. The standard deviation of heights of plants cannot be compared with the standard deviation of weights of the grains, as both are expressed in different units, i.e heights in centimetre and weights in kilograms. Therefore the standard deviation must be converted into a relative measure of dispersion for the purpose of comparison. The relative measure is known as the coefficient of variation. The coefficient of variation is obtained by dividing the standard deviation by the mean and expressed in percentage. \\[\\mathbf{\\text{Coefficient of variation}}\\left( \\mathbf{C}\\mathbf{.}\\mathbf{V} \\right)\\mathbf{=}\\frac{\\mathbf{\\text{standard deviation}}}{\\mathbf{\\text{mean}}}\\mathbf{\\times 100}\\] If we want to compare the variability of two or more series, we can use C.V. The series or groups of data for which the C.V. is greater indicate that the group is more variable, less stable, less uniform, less consistent or less homogeneous. If the C.V. is less, it indicates that the group is less variable or more stable or more uniform or more consistent or more homogeneous. Example 5.8: Consider the measurement on yield and plant height of a paddy variety. The mean and standard deviation for yield are 50 kg and 10 kg respectively. The mean and standard deviation for plant height are 55 cm and 5 cm respectively. Compare the variability. Solution: Here the measurements for yield and plant height are in different units. Hence the variability can be compared only by using coefficient of variation. For yield, CV=\\(\\ \\frac{10}{50} \\times 100 =\\) 20% For plant height, CV= \\(\\frac{5}{55} \\times 100 = \\ \\)9.1% The yield is subject to more variation than the plant height. ****************************************************************** "],["skewness-and-kurtosis.html", "Chapter 6 Skewness and Kurtosis 6.1 Skewness 6.2 Measures of Skewness 6.3 Kurtosis", " Chapter 6 Skewness and Kurtosis In the previous lectures we have learned numerical measures of central tendency and dispersion, but what about measures of shape? The histogram can give you a general idea on the shape of the distribution of values in your data. But we need some numerical measures to identify the shape of the distribution. The numerical measures which deal with the shape of the distribution are Skewness and Kurtosis. 6.1 Skewness Skewness is a measure of symmetry, or more precisely, the lack of symmetry. Then you may ask, what will a symmetric distribution looks like. Histogram of a symmetric distribution is showed below: Figure 6.1: Histogram of a symmetric distribution A distribution, or data set, is symmetric if it looks the same to the left and right of the centre point. In our discussion we are including only unimodal cases. For a symmetric distribution skewness = 0; mean = median = mode Figure 6.2: symmetric distribution Example of a data set with skewness = 0 (symmetric distribution) Figure 6.3: Data set with skewness = 0 6.1.1 Left-skewed or negatively skewed For negatively skewed data set or distribution, the left tail is longer; the mass of the distribution is concentrated on the right of the figure. The distribution is said to be left-skewed, left-tailed, or skewed to the left, considering that there is a long tail in the left side. See the figure below, you can also see Mean &lt; Median &lt; Mode. Figure 6.4: Left skewed or negatively skewed distribution Example of a data set with negative skewness Figure 6.5: Negatively skewed data set 6.1.2 Right-skewed or positively skewed For positively skewed data set or distribution, the right tail is longer; the mass of the distribution is concentrated on the left of the figure. The distribution is said to be right-skewed, right-tailed, or skewed to the right, considering that there is a long tail in the right side. See the figure below, you can also see Mean &gt; Median &gt; Mode Figure 6.6: Right skewed or positively skewed distribution Example of a data set with positive skewness Figure 6.7: Data set with positive skewness (right skewed) 6.2 Measures of Skewness The direction and extent of skewness can be measured in various ways. We shall discuss four measures. 6.2.1 Karl Pearsons coefficient of Skewness (\\(S_{k}\\)) You have noticed that the mean, median and mode are not equal in a skewed distribution. The Karl Pearson's measure of skewness is based upon the divergence of mean from mode in a skewed distribution. \\[S_{k} = \\frac{mean - mode}{\\text{standard deviation}}\\] The sign of \\(S_{k}\\) gives the direction of skewness and its magnitude gives the extent of skewness. If \\(S_{k}\\) &gt; 0, the distribution is positively skewed, and if \\(S_{k}\\) &lt; 0 it is negatively skewed. In the above formula since mode is used, there is a problem that if mode is not defined for a distribution we cannot find \\(S_{k}\\). But empirical relation between mean, median and mode states that, for a moderately symmetrical distribution\\(\\ mean - mode \\approx 3(mean - median)\\). So the above formula can be written as \\[S_{k} = \\frac{3(mean - median)}{\\text{standard deviation}}\\] Example 6.1: Compute the Karl Pearson's coefficient of skewness from the following data: Height (x) frequency (f) 58 10 59 18 60 30 61 42 62 35 63 28 64 16 65 8 Solution: Height (\\(x_{i}\\)) frequency (\\(f_{i}\\)) \\[f_{i}x_{i}\\] \\[f_{i}x_{i}^{2}\\] 58 10 580 33640 59 18 1062 62658 60 30 1800 108000 61 42 2562 156282 62 35 2170 134540 63 28 1764 111132 64 16 1024 65536 65 8 520 33800 Sum 187 11482 705588 Mean, \\(\\overline{x} = \\frac{\\sum_{i = 1}^{n}{f_{i}x_{i}}}{\\sum_{i = 1}^{n}f_{i}}\\) = \\(\\frac{11482}{187} = 61.40\\) \\({sample\\ variance,\\ s}^{2} = \\frac{1}{n - 1}\\left\\{ \\sum_{i = 1}^{n}{{f_{i}x}_{i}^{2} - \\frac{1}{n}}\\left( \\sum_{i = 1}^{n}{f_{i}x}_{i} \\right)^{2} \\right\\}\\)= \\(\\frac{705588 - \\frac{\\left( 11482 \\right)^{2}}{187}}{186} = 3.123\\) \\(standard\\ deviation,\\ s = \\sqrt{3.123} = 1.179\\) Median: See in the cumulative frequencies, the value just greater than\\(\\ \\left( \\frac{n + 1}{2} \\right)\\) , then the corresponding value of \\(x\\) is \\(Q_{2}\\), median \\(\\left( \\frac{n + 1}{2} \\right) = \\frac{187 + 1}{2}\\ \\)= \\(\\frac{188}{2}\\) = 94 Height (x) frequency (f) cumulative frequency 58 10 10 59 18 28 60 30 58 61 42 100 62 35 135 63 28 163 64 16 179 65 8 187 \\[S_{k} = \\frac{3(mean - median)}{\\text{standard deviation}}\\] \\[S_{k} = \\frac{3(61.40 - 61)}{1.179} = \\frac{1.2}{1.179} = 1.017\\] Hence, the Karl Pearson's coefficient of skewness \\(S_{k}\\)=\\(1.017\\), Thus the distribution is positively skewed. 6.2.2 Bowley's measure of Skewness (SQ) Karl Pearson's coefficient of skewness is most commonly used skewness measure. However, in order to use it you must know the mean, mode (or median) and standard deviation for your data. Sometimes you might not have that information; instead you might have information about quartiles. If thats the case, you can use Bowleys measure of Skewness as an alternative to find out more about the asymmetry of your distribution. Its very useful if you have extreme data values (outliers) or if you have an open-ended distribution. \\[{Bowleys\\ measure\\ of\\ Skewness,\\ S}_{Q} = \\frac{\\left( Q_{3} - Q_{2} \\right) - \\left( Q_{2} - Q_{1} \\right)}{\\left( Q_{3} - Q_{2} \\right) + \\left( Q_{2} - Q_{1} \\right)}\\] Where \\(Q_{1}\\)= 1st quartile; \\(Q_{2}\\) = median; \\(Q_{3}\\)= 3rd quartile Equation can be further modified into \\[S_{Q} = \\frac{Q_{3} - 2Q_{2} + Q_{1}}{Q_{3} - Q_{1}}\\] \\(S_{Q}\\)= 0 means that the curve is symmetrical. \\(S_{Q}\\) &gt; 0 means the curve is positively skewed. \\(S_{Q}\\)&lt; 0 means the curve is negatively skewed. For Example 6.1 given above, Bowley's measure of Skewness can be calculated as follows Height (x) frequency (f) cumulative frequency 58 10 10 59 18 28 60 30 58 61 42 100 62 35 135 63 28 163 64 16 179 65 8 187 Calculation of\\(\\text{Q}_{1}\\), \\(Q_{2}\\), \\(Q_{3}\\) is given in Section 4.8 \\[{Q}_{1} = 60\\] \\[Q_{2} = 61\\] \\[Q_{3} = 63\\] \\[S_{Q} = \\frac{63 - (2 \\times 61) + 60}{63 - 60} = \\ \\frac{1}{3} = 0.33\\] Since \\(S_{Q}\\) &gt; 0 means the curve is positively skewed. 6.2.3 Kelly's Measure of Skewness (Sp) Bowley's measure of skewness is based on the middle 50% of the observations; it leaves 25% of the observations on each extreme of the distribution. As an improvement over Bowley's measure, Kelly has suggested a measure based on Percentiles, including P10 and P90 so that only 10% of the observations on each extreme are ignored. \\[{Kelly&#39;s\\ Measure\\ of\\ Skewness,\\ S}_{p} = \\frac{\\left( P_{90} - P_{50} \\right) - \\left( P_{50} - P_{10} \\right)}{\\left( P_{90} - P_{50} \\right) + \\left( P_{50} - P_{10} \\right)}\\] Assignment 3:Try to find Kellys Measure of Skewness for the Example 6.1 given above 6.2.4 Measure based on moments Before going into measuring skewness using moments, one should know what a moment is: 6.2.4.1 Moments The rth moment about mean of a distribution, denoted by r is given by \\[\\mu_{r} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{r}}}{N}\\] Where \\(f_{i}\\) is the frequency of ith observation or class mark\\(\\ x_{i}\\), \\(N = \\sum_{}^{}f_{i}\\), number of observations Moment about mean is also called as Central Moment If r = 0, \\(\\mu_{0} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{0}}}{N}\\) = 1 If r = 1, \\(\\mu_{1} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{1}}}{N}\\) = 0 (sum of deviation about mean is zero) If r = 2, \\(\\mu_{2} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{2}}}{N}\\) = \\(\\sigma^{2}\\), Population variance In short values of following moments about mean are Moments about mean (central moment) Value \\[\\mu_{0}\\] 1 \\[\\mu_{1}\\] 0 \\[\\mu_{2}\\] \\[\\sigma^{2}\\] For the Example 6.1 given above, calculate third central moment, \\(\\mu_{3}\\) Height (\\(x_{i}\\)) frequency (\\(f_{i}\\)) \\[\\left( x_{i} - \\overline{x} \\right)^{3}\\] \\[{f_{i}\\left( x_{i} - \\overline{x} \\right)}^{3}\\] 58 10 -39.304 -393.04 59 18 -13.824 -248.832 60 30 -2.744 -82.32 61 42 -0.064 -2.688 62 35 0.216 7.56 63 28 4.096 114.688 64 16 17.576 281.216 65 8 46.656 373.248 Sum 187 49.832 Mean = 61.40 \\[\\mu_{3} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{3}}}{N} = \\ \\frac{49.832}{187} = 0.266\\] 6.2.4.2 Moment Measure of Skewness \\(\\mathbf{(}\\beta_{1}\\text{and}\\)\\(\\gamma_{1}\\mathbf{)}\\) The moment measure of skewness is based on the property that, for a symmetrical distribution, all odd ordered central moments are equal to zero. We note that \\(\\mu_{1}\\) = 0, for every distribution, therefore, the lowest order moment that can provide an absolute measure of skewness is\\(\\text{}_{3}\\). So measures of skewness are based on\\(\\text{}_{3}\\). \\[\\beta_{1} = \\frac{\\mu_{3}^{2}}{\\mu_{2}^{3}}\\] Pronounced as beta one \\(\\beta_{1}\\)= 0 means that the curve is symmetrical. The greater the value of \\(\\beta_{1}\\)the more skewed the distribution. One serious limitation of \\(\\beta_{1}\\)is that it cannot tell the direction of skewness, i.e., whether it is positive or negative. Since \\(\\text{}_{2}\\) is always positive and \\(\\mu_{3}^{2}\\) is positive, \\(\\beta_{1}\\) will be positive always. This drawback is removed by calculating\\(\\text{}_{1}\\), called as Karl Pearsons\\(\\text{ }_{1}\\), pronounced as gamma one. \\[\\gamma_{1} = \\sqrt{\\beta_{1}} = \\frac{\\mu_{3}}{\\mu_{2}^{3}}\\] If \\(\\mu_{3}\\) is positive \\(\\gamma_{1}\\) is positive, If \\(\\mu_{3}\\) is negative \\(\\gamma_{1}\\) is negative \\(\\gamma_{1}\\)= 0 means that the curve is symmetrical. \\(\\gamma_{1}\\) &gt; 0 means the curve is positively skewed. \\(\\gamma_{1}\\)&lt; 0 means the curve is negatively skewed. For the Example 6.1 given above, skewness can be examined as below \\(\\mu_{3}\\)= 0.226 \\(\\mu_{2}\\)= 3.123 \\(\\beta_{1} = \\frac{\\mu_{3}^{2}}{\\mu_{2}^{3}}\\) = \\(\\frac{\\left( 0.226 \\right)^{2}}{\\left( 3.123 \\right)^{3}} = \\ \\frac{0.051}{30.46} = 0.0016\\) \\(\\gamma_{1} = \\sqrt{\\beta_{1}} = \\ \\sqrt{0.0016} = + 0.04\\) Since \\(\\mu_{3}\\) is positive \\(\\gamma_{1}\\)is positive. Since \\(\\gamma_{1}\\)is slightly greater than 0, distribution is a slightly skewed to right. 6.3 Kurtosis Kurtosis is another measure of the shape of a distribution. Whereas skewness measures the lack of symmetry of the frequency curve of a distribution, kurtosis is a measure of the relative peakedness of its frequency curve. Various frequency curves can be divided into three categories depending upon the shape of their peak. Figure 6.8: Three categories of frequency curves depending upon the shape of their peak Kurtosis refers to degree of flatness or peakedness of the curve. It is measured relative to the peakedness of normal curve. The normal curve is considered as mesokurtic. If a curve is more peaked than normal curve, it is called leptokurtic. If a curve is more flat-topped than normal curve, it is called platykurtic. The condition of peakedness (leptokurtic) or flatness (platykurtic) is called kurtosis of excess. Measure of kurtosis is given by beta two given by Karl Pearson \\(\\beta_{2} = \\frac{\\mu_{4}}{\\mu_{2}^{2}}\\) Where \\(\\mu_{4}\\) is the 4th central moment, \\(\\mu_{2}\\) is the 2nd central moment \\(\\beta_{2}\\)= 3 means that the curve is mesokurtic. \\(\\beta_{2}\\) &gt; 3 means the curve is leptokurtic. \\(\\beta_{2}\\)&lt; 3 means the curve is platykurtic. Another measure of kurtosis is gamma two, \\(\\gamma_{2} = \\beta_{2} - 3\\ \\) \\(\\gamma_{2}\\)= 0 means that the curve is mesokurtic. \\(\\gamma_{2}\\) &gt; 0 means the curve is leptokurtic. \\(\\gamma_{2}\\)&lt; 0 means the curve is platykurtic. For the Example 6.1 given above, kurtosis can be examined as follows Height (\\(x_{i}\\)) frequency (\\(f_{i}\\)) \\[\\left( x_{i} - \\overline{x} \\right)^{4}\\] \\[{f_{i}\\left( x_{i} - \\overline{x} \\right)}^{4}\\] 58 10 133.6336 1336.336 59 18 33.1776 597.1968 60 30 3.8416 115.248 61 42 0.0256 1.0752 62 35 0.1296 4.536 63 28 6.5536 183.5008 64 16 45.6976 731.1616 65 8 167.9616 1343.693 Sum 187 4312.747 Mean,\\(\\ \\overline{x}\\ \\)= 61.40 \\(\\mu_{2}\\) = 3.123 (calculation shown in previous example) \\(\\mu_{4} = \\frac{\\sum_{i = 1}^{N}{f_{i}\\left( x_{i} - \\overline{x} \\right)^{4}}}{N} = \\frac{4312.747}{187} = 23.062\\) \\(\\beta_{2} = \\frac{\\mu_{4}}{\\mu_{2}^{2}} = \\frac{23.062}{\\left( 3.123 \\right)^{2}} = 2.364\\) \\(\\beta_{2}\\) is 2.364, which is close to 3, distribution can be considered slightly platykurtic close to symmetric. You can verify the frequency curve of Example 6.1 below, it can be seen that it is slightly right tailed (positively skewed) Figure 6.9: frequency curve of Example 6.1 "],["measures-of-association.html", "Chapter 7 Measures of Association 7.1 Scatter Diagram 7.2 Correlation 7.3 Other types of correlation 7.4 Linear relationship 7.5 Methods of measurement of correlation", " Chapter 7 Measures of Association 7.1 Scatter Diagram Consider two variables x and y, we use scatter diagram to investigate whether there is any relation between the two variables. If the variables x and y are plotted along the X-axis and Y-axis respectively in the X-Y plane of a graph sheet the resultant diagram of dots is known as scatter diagram. From the scatter diagram we can say whether there is any association between X and Y. Example 7.1: Consider the data on Sepal length (x) and Sepal width (y) of Iris setosa. Sl. No. Sepal Length Sepal Width 1 5.1 3.5 2 4.9 3 3 4.7 3.2 4 4.6 3.1 5 5 3.6 6 7 3.2 7 6.4 3.2 8 6.9 3.1 9 5.5 2.3 10 6.5 2.8 11 6.3 3.3 12 5.8 2.7 13 7.1 3 14 6.3 2.9 15 6.5 3 Figure 7.1: Scatter diagram of data in Example 7.1 7.2 Correlation Correlation is a statistical technique used for analyzing the behaviour of two or more variables. The correlation measures the degree and closeness of the linear relationship between two variables in numerical magnitude. Correlation measure will enable us to compare the linear relationship between two variables by using a single number. If two or more quantities vary in a related manner so that the movements in one tend to be accompanied by the movements in the other, then they are said to be correlated. 7.2.1 Positive correlation Positive correlation is a relationship between two variables in which both variables move in the same direction. A positive correlation exists when one variable decreases as the other variable decreases, or one variable increases while the other increases. Examples of positive correlation: consider two variables x and y The more time you spend running on a treadmill [Running time (x)], the more calories you will burn [calories burned (y)]. Here you can see as x increases y also increases Shorter people [Height (x)] have smaller shoe sizes [shoe size (y)]. Here you can see as x decreases y also decreases. The more hours you spend in direct sunlight [Hours in sunlight (x)], the more is your tan [melanin content(y)]. Here you can see as x increases y also increases As the temperature goes up [Temperature (x)], ice cream sales [sales (y)], also go up. 7.2.2 Negative correlation Negative correlation is a relationship between two variables in which one variable increases as the other decreases, and vice versa. Examples of negative correlation: consider two variables x and y A student who has many absences [No. of days absent (x)] has a decrease in grades [grades (x)]. Here you can see as x increases y decreases. As weather gets colder [Average monthly temperature (x)], air conditioning costs decrease [Price of A.C (y)]. If a chicken increases in age [chicken age (x)], the number of eggs it produces [No. of eggs produced (y)] decreases. If a car decreases speed [average car speed(x)], travel time (y) to a destination increases. 7.3 Other types of correlation 7.3.1 Simple and Multiple In simple correlation the relationship is confined to two variables only. In multiple correlation the relationship between more than two variables is judged. 7.3.2 Partial and total There are two types of correlations in multiple correlation analysis. Under partial correlation the relationship of two or variables is examined after eliminating the linear effect of other correlated variables. The total correlation is based on all relevant variables. Correlation measures only linear relationship between variables 7.4 Linear relationship A linear relationship (or linear association) is a statistical term used to describe a straight-line relationship between variables. Linear relationships can be expressed either in a graphical format where the variable plotted on X-Y plane gives a straight line or relation between two variables (consider x and y) can be expressed with an equation of a straight line (y = a + bx) (**will be more clear when we discuss regression) Example 7.2: Consider the following example of ice cream sales The local ice cream shop keeps track of how much ice cream they sell versus the temperature on that day; here are their figures for the last 12 days: Temperature (°C) Ice Cream Sales (in $) 14.2 215 16.4 325 11.9 185 15.2 332 18.5 406 22.1 522 19.4 412 25.1 614 23.4 544 18.1 421 22.6 445 17.2 408 For the rest of our discussion we will be using this example . 7.5 Methods of measurement of correlation 7.5.1 Scatter diagram or Graphic method Figure 7.2: Scatter plot of Example 7.2 From the Figure 7.2 above you can see a linear association between the two variables i.e. between temperature and ice cream sales. It can be shown using a line as below. It is clear that as temperature increases sales increases, indicating a positive correlation. Figure 7.3: Linear relationship between variables From the example it is clear that scatter diagram gives an idea on linear association between variables, so it can also used as a graphical tool to see whether there is correlation is present or not. Perfect Correlation: If there is any change in the value of one variable, the value of the other variable is changed in a fixed proportion then the correlation between them is said to be a perfect correlation. If there is a perfect correlation, the points will lie in the straight line. In the scatter diagram of Example 7.2, you can see that there is no perfect linear relationship as the points are not exactly in the line, but the points are in some scattered form but still have a direction (positive). Direction of correlation can be identified using a scatter diagram as shown below in Figure 7.4 Figure 7.4: Scatter plot and nature of relationship 7.5.2 Karl Pearsons coefficient of Correlation (r) It is the most important and widely used measure of correlation. A measure of the intensity or degree of linear relationship between two variables is developed by Karl Pearson, a British Biometrician - known as the Pearsons Correlation coefficient denoted by r which is expressed as the ratio of the covariance to the product of the standard deviations of the two variables. 7.5.2.1 Covariance Covariance is a measure of the joint linear variability of the two variables. Consider two variables x and y with n observations each, then covariance is given by the formula Covariance of (x,y) = \\(\\frac{1}{n}\\sum_{i = 1}^{n}{\\left( x_{i} - \\overline{x} \\right)\\left( y_{i} - \\overline{y} \\right)}\\) When covariance = 0 there is no joint variability or there is no linear relationship. The unit of covariance is the product of the units of the two variables. Covariance of two variables x and y is denoted as Cov(x, y). Covariance measure is used to find correlation coefficient. The correlation coefficient between the two variables (x and y) is calculated as \\[r=\\frac{cov(x,y)}{sd(x)sd(y)}\\] Where sd. is the standard deviation. \\[r = \\frac{\\frac{1}{n}\\sum_{i = 1}^{n}{\\left( x_{i} - \\overline{x} \\right)\\left( y_{i} - \\overline{y} \\right)}}{\\sqrt{\\frac{1}{n}\\sum_{i = 1}^{n}\\left( x_{i} - \\overline{x} \\right)^{2}\\frac{1}{n}\\sum_{i = 1}^{n}\\left( y_{i} - \\overline{y} \\right)^{2}}}\\] #### Properties of the correlation coefficient (r) It is a pure number independent of both origin and scale of the units of the observations. It always lies between 1 and +1 (absolute value cannot exceed unity). 1  r  +1 r = +1, indicates perfect positive correlation. r = 1, indicates perfect negative correlation. r = 0, indicates no correlation. When the correlation is zero then there is no linear relationship between the variables. If there is no meaningful relation between the variables the value of the correlation obtained is also meaningless. (For example as fertilizer price increases, Kohilis batting average also increases, we know there no practical relationship between these variables, still we may get a correlation measure and it is called spurious correlation) A Simplified formula for computation of correlation coefficient can be derived by modifying above formula \\[r = \\frac{n\\left( \\sum_{i = 1}^{n}{x_{i}y_{i}} \\right) - \\sum_{i = 1}^{n}{x_{i}\\sum_{i = 1}^{n}y_{i}}}{\\sqrt{\\left\\lbrack n\\sum_{i = 1}^{n}{x_{i}^{2} - \\left( \\sum_{i = 1}^{n}x_{i} \\right)^{2}} \\right\\rbrack\\left\\lbrack n\\sum_{i = 1}^{n}{y_{i}^{2} - \\left( \\sum_{i = 1}^{n}y_{i} \\right)^{2}} \\right\\rbrack}}\\] Example 7.3: Consider the Example 7.2 of ice cream sales; find correlation coefficient (r) Sl. No. Temperature Sales \\(x_{i}-\\overline{x}\\)(1) \\(y_{i}-\\overline{y}\\)(2) (1).(2) \\((x_{i}-\\overline{x})^{2}\\) \\((y_{i}-\\overline{y})^{2}\\) (x) (y) 1 14.2 215 -4.475 -187.42 838.69 20.0256 35125.01 2 16.4 325 -2.275 -77.417 176.123 5.17563 5993.34 3 11.9 185 -6.775 -217.42 1473 45.9006 47270.01 4 15.2 332 -3.475 -70.417 244.698 12.0756 4958.507 5 18.5 406 -0.175 3.58333 -0.6271 0.03063 12.84028 6 22.1 522 3.425 119.583 409.573 11.7306 14300.17 7 19.4 412 0.725 9.58333 6.94792 0.52562 91.84028 8 25.1 614 6.425 211.583 1359.42 41.2806 44767.51 9 23.4 544 4.725 141.583 668.981 22.3256 20045.84 10 18.1 421 -0.575 18.5833 -10.685 0.33062 345.3403 11 22.6 445 3.925 42.5833 167.14 15.4056 1813.34 12 17.2 408 -1.475 5.58333 -8.2354 2.17563 31.17361 SUM 224.1 4829 0 0 5325.03 176.983 174754.9 n =12 \\[mean,\\overline{x} = \\ \\frac{224.1}{12} = 18.675\\] \\[mean,\\overline{y} = \\ \\frac{4829}{12} = 402.416\\] Cov (x,y) = \\(\\frac{1}{n}\\sum_{i = 1}^{n}{\\left( x_{i} - \\overline{x} \\right)\\left( y_{i} - \\overline{y} \\right)}\\) \\(\\sum_{i = 1}^{12}{\\left( x_{i} - \\overline{x} \\right)\\left( y_{i} - \\overline{y} \\right)} = 5325.03\\) Cov (x,y) = \\(\\frac{5325.03}{12} = 443.752\\) \\[Standard\\ deviation,\\ S.D\\left( x \\right) = \\ \\sqrt{\\frac{1}{n}\\sum_{i = 1}^{n}\\left( x_{i} - \\overline{x} \\right)^{2}} = \\sqrt{\\frac{176.983}{12}} = 3.840\\] \\[Standard\\ deviation,\\ S.D\\left( y \\right) = \\ \\sqrt{\\frac{1}{n}\\sum_{i = 1}^{n}\\left( y_{i} - \\overline{y} \\right)^{2}} = \\sqrt{\\frac{174754.9}{12}} = 120.676\\] \\(r = \\frac{443.752}{3.840\\ \\times 120.676} = 0.95751\\), which indicates a strong positive correlation 7.5.3 Spearmans Rank order correlation coefficient () The Spearman correlation evaluates the monotonic relationship between two continuous or ordinal variables. Note: What is a monotonic relation? In a monotonic relationship, the variables tend to move in the same relative direction, but not necessarily at a constant rate. In a linear relationship, the variables move in the same direction at a constant rate. Linear relationship is monotonic but all monotonic relations are not linear. You can see the plots below for better understanding. Figure 7.5: Linear and Monotonic relationship The Spearman correlation coefficient is based on the ranked values for each variable rather than the raw data. The spearman correlation measures the monotonic relationship between variables, where pearsons correlation coefficient measures linear relationship only. To use Spearmans correlation coefficient your data must be in ordinal, interval or ratio scale. There are two cases in calculating . One is in case of no tied rank other is when there is tied rank 7.5.3.1 No tied rank case When two or more distinct observations have the same value, thus being given the same rank, they are said to be tied The formula for the Spearman rank correlation coefficient when there are no tied ranks is: \\[\\rho = 1 - \\frac{6\\sum_{i = 1}^{n}d_{i}^{2}}{n\\left( n^{2} - 1 \\right)}\\] Where \\(d_{i}\\) is the difference between ranks of ith pair of observation Example 7.4: Calculation of Spearmans rank correlation when there is no tied rank is explained step by step by using the example below The scores for nine students in physics and math are as follows: Physics: 35, 23, 47, 17, 10, 43, 9, 6, 28 Mathematics: 30, 33, 45, 23, 8, 49, 12, 4, 31 Compute the students ranks in the two subjects and compute the Spearman rank correlation. Physics Mathematics 35 30 23 33 47 45 17 23 10 8 43 49 9 12 6 4 28 31 Step 1: Find the ranks for each individual subject. Rank the scores from greatest to smallest; assign the rank 1 to the highest score, 2 to the next highest and so on: Physics (x) Rank Mathematics (y) Rank 35 3 30 5 23 5 33 3 47 1 45 2 17 6 23 6 10 7 8 8 43 2 49 1 9 8 12 7 6 9 4 9 28 4 31 4 Step 2: Add a column d, to your data. The d is the difference between ranks. For example, the first students physics rank is 3 and math rank is 5, so the difference is -2. In the next column, square your d values. Physics (x) Rank Mathematics (y) Rank d d2 35 3 30 5 -2 4 23 5 33 3 2 4 47 1 45 2 -1 1 17 6 23 6 0 0 10 7 8 8 -1 1 43 2 49 1 1 1 9 8 12 7 1 1 6 9 4 9 0 0 28 4 31 4 0 0 SUM 12 Step 4: Sum (add up) all of your d2 values. 4 + 4 + 1 + 0 + 1 + 1 + 1 + 0 + 0 = 12. Youll need this for the formula (the \\(\\sum_{i = 1}^{n}d_{i}^{2}\\) is just the sum of d2values, here n= 9). Step 5: Insert the values into the formula. \\[\\rho = 1 - \\frac{6\\sum_{i = 1}^{n}d_{i}^{2}}{n\\left( n^{2} - 1 \\right)}\\] \\[\\rho = 1 - \\frac{6 \\times 12}{9\\left( 81 - 1 \\right)} = 0.90\\] The Spearmans Rank Correlation for this set of data is 0.9. Spearmans Rank Correlation also lies between 1 and +1 always. 1   +1 7.5.3.2 Tied rank case Calculation of Spearmans rank correlation when there is tied rank is explained step by step by using the example below Example 7.5: The scores for nine students in physics and mathematics are as follows: Physics (x) Mathematics (y) 35 30 23 33 47 45 23 23 10 8 43 49 9 12 6 33 28 33 Step 1: Consider the marks in Physics, ranked as usual Physics (x) Rank 35 3 23 5 47 1 23 6 10 7 43 2 9 8 6 9 28 4 You can see the value 23 is repeated, so may have equal ranks, so the average of two ranks 5 and 6 is given to both; \\(\\left( \\frac{5 + 6}{2} \\right)\\ \\)= 5.5 Physics (x) Rank 35 3 23 5.5 47 1 23 5.5 10 7 43 2 9 8 6 9 28 4 Similarly for marks in mathematics you can see 33 is repeated thrice. Mathematics (y) 30 33 45 23 8 49 12 33 33 Mathematics (y) Rank 30 6 33 3 45 2 23 7 8 9 49 1 12 8 33 4 33 5 You can see the value 33 is repeated thrice, so the average of three ranks 3, 4 and 5 is given \\(\\left( \\frac{3 + 4 + 5}{3} \\right)\\ \\)= 4 Mathematics (y) Rank 30 6 33 4 45 2 23 7 8 9 49 1 12 8 33 4 33 4 Step 2: Change in the formula \\[\\rho = 1 - \\frac{6\\left( \\sum_{i = 1}^{n}d_{i}^{2} + T_{x} + T_{y} \\right)}{n\\left( n^{2} - 1 \\right)}\\] If there are m individuals tied (having same rank), and s such sets of ranks are there in X- series then, \\(T_{x} = \\ \\frac{1}{12}\\sum_{i = 1}^{s}{m_{i}\\left( m_{i}^{2} - 1 \\right)}\\) In our example marks in Physics (x) there are two 23 values tied therefore m = 2; since only one such a set is there s =1 \\(T_{x} = \\ \\frac{1}{12}\\left( 2 \\times (2^{2} - 1 \\right)\\) = 0.5 If there are w individuals tied (having same rank), and s such sets of ranks are there in Y- series then, \\(T_{y} = \\ \\frac{1}{12}\\sum_{i = 1}^{s&#39;}{w_{i}\\left( w_{i}^{2} - 1 \\right)}\\) In our example marks in Mathematics (y) there are three 33 values tied therefore w = 3; since only one such a set is there s =1 \\(T_{y} = \\ \\frac{1}{12}\\left( 3 \\times (3^{2} - 1 \\right)\\) = 2 Step 2: Calculate d and then use the formula Physics (x) Rank Mathematics (y) Rank d d2 35 3 30 6 -3 9 23 5.5 33 4 1.5 2.25 47 1 45 2 -1 1 23 5.5 23 7 -1.5 2.25 10 7 8 9 -2 4 43 2 49 1 1 1 9 8 12 8 0 0 6 9 33 4 5 25 28 4 33 4 0 0 SUM 0 44.5 \\(\\rho = 1 - \\frac{6\\left( \\sum_{i = 1}^{n}d_{i}^{2} + T_{x} + T_{y} \\right)}{n\\left( n^{2} - 1 \\right)} = 1 - \\frac{6 \\times \\left( 44.5 + 0.5 + 2 \\right)}{9\\left( 9^{2} - 1 \\right)} = \\ 1 - \\frac{282}{720}\\) = 0.60834 7.5.4 Kendalls Rank Correlation Coefficient () Kendalls rank correlation coefficient also known as Kendalls Tau or coefficient of concordance. It lies between 0 and 1, 0    1. when several sets of ranks are there, it can be used to test the association. When we have k sets of rankings we may determine the association among them by using the Kendalls coefficient of Concordance (). Such a measure is useful to study the reliability in the scorings made by a number of Judges. Arrange the data into a table with each row representing the ranks assigned by (each judge), to say, n number of objects. Let there be k number of sets of rankings for each object given by k judges. Then the Kendalls coefficient of concordance  is computed as \\[\\tau = \\frac{12\\left\\lbrack \\sum_{i = 1}^{n}{R_{i}^{2} - \\frac{\\left( \\sum_{i = 1}^{n}R_{i} \\right)^{2}}{n}} \\right\\rbrack}{k^{2}n\\left( n^{2} - 1 \\right)}\\] Example 7.6: In a crop production competition, 10 entries of farmers were ranked by agricultural scientists (judges). Find the degree of agreement among the scientist for the competition result given below. Ranks given by the judges to farmers Farmers Scientist 1 Scientist 2 Scientist 3 Scientist 4 1 4 5 3 7 2 10 9 8 6 3 8 6 10 9 4 3 4 2 1 5 1 3 4 2 6 2 1 1 4 7 5 7 6 5 8 6 2 5 3 9 7 8 9 10 10 9 10 7 8 Solution: Farmers S1 S2 S3 S4 \\(R_{i}\\) (sum of ranks) \\[R_{i}^{2}\\] 1 4 5 3 7 19 361 2 10 9 8 6 33 1089 3 8 6 10 9 33 1089 4 3 4 2 1 10 100 5 1 3 4 2 10 100 6 2 1 1 4 8 64 7 5 7 6 5 23 529 8 6 2 5 3 16 256 9 7 8 9 10 34 1156 10 9 10 7 8 34 1156 SUM 220 5900 Here k = number of judges = 4 n = number of farmers =10 \\(\\left( \\sum_{i = 1}^{10}R_{i} \\right)^{2}\\ \\)= (220)2 = 48400 \\(\\sum_{i = 1}^{10}R_{i}^{2}\\) = 5900 \\[\\tau = \\frac{12\\left\\lbrack \\sum_{i = 1}^{n}{R_{i}^{2} - \\frac{\\left( \\sum_{i = 1}^{n}R_{i} \\right)^{2}}{n}} \\right\\rbrack}{k^{2}n\\left( n^{2} - 1 \\right)}\\] = \\(\\tau = \\frac{12\\left\\lbrack 5900 - \\frac{48400}{10} \\right\\rbrack}{16 \\times 10\\left( 100 - 1 \\right)}\\) = 0.803 Since \\(\\tau\\) is nearly equal to 1, the ranks given by judges were almost same ************************************************* "],["regression-analysis.html", "Chapter 8 Regression Analysis 8.1 Definition 8.2 Simple regression 8.3 Two types of variables 8.4 Detailed explanation 8.5 Error and residual 8.6 Straight lines 8.7 Method of least squares 8.8 Principle of least squares 8.9 Two lines of regression 8.10 Assumptions of Regression 8.11 Properties of Regression coefficients 8.12 Uses of Regression 8.13 Example problem", " Chapter 8 Regression Analysis Regression analysis is the method of using observations (data records) to quantify the relationship between a target variable also referred to as a dependent variable, and a set of independent variables. 8.1 Definition Regression analysis is a mathematical measure of the average relationship between two or more variables in terms of the original units of the data 8.2 Simple regression when only two variables are involved; Regression can be defined as the functional relationship between two variables, where one may represent cause and the other may represent effect. The variable representing cause is known as independent variable and is denoted by X. The variable X is also known as predictor variable, regressor or explanatory variable. The variable representing effect is known as dependent variable and is denoted by Y. For example consider yield and fertilizer dose, here yield can be considered as dependent variable (Y) and fertilizer dose can be considered as independent variable (X). 8.3 Two types of variables In regression analysis the variable whose values need to be predicted (Y) is called dependent variable and the variable which is used for prediction (X) is called independent variable. When more than two independent variables are present then the regression is called as Multiple Regression. If only two variables are present then it is called as simple regression. 8.4 Detailed explanation Correlation is a statistical measure which determines the degree of association of two variables. Regression on other hand side describes how an independent variable is numerically related to dependent variable. Regression can be simply defined as a technique of fitting best line or line of best fit to estimate value of one variable on the basis of another variable. Now what is a best line? or line of best fit? For explaining further, consider the example of Ice cream sales: Example 8.1: The local ice cream shop keeps track of how much ice cream they sell versus the temperature on that day; here are their figures for the last 12 days: Temperature (°C) Ice Cream Sales (in $) 14.2 215 16.4 325 11.9 185 15.2 332 18.5 406 22.1 522 19.4 412 25.1 614 23.4 544 18.1 421 22.6 445 17.2 408 We can use regression analysis to answer the following questions What will be the Ice cream sales when temperature is 20o Celsius? What is the functional form of relationship between Temperature and Ice cream sales? Figure 8.1: Scatter diagram of data in Example 8.1 We can draw a line to denote the functional relationship between temperature and sales Figure 8.2: lines drawn to show functional relationship You can see that as shown above we can draw any number of lines, so which is the best fit line? We can say the best fit line is the line that passes through all points such that distance of each point to the line is minimum. Using regression technique we could easily draw such a line. Before proceeding you should know the concept of error and residuals. 8.5 Error and residual An error is the difference between the observed value and the true value (true value is the unobserved population mean of the population from which sample observations are taken). A residual is the difference between the observed value and the predicted value (by the model [fitted line]). Error cannot be measured but residual can be; so residual is considered as an estimate of error. Figure 8.3: Error depicted in best fit line The distance of each observation (ei) from the fitted line can be considered as the residual (error). Best fit line can be obtained by minimizing this distance. This can be achieved using the mathematical technique principle of least squares. 8.6 Straight lines A straight line is the simplest figure in geometry. Mathematical equation of a straight line Y= a + bX. Two important features of a line slope and intercept. a is the Y-intercept, the intercept of a line is the y-value of the point where it crosses the y-axis. b is the slope of a line, which is a number that measures its \"steepness. It is the change in Y for a unit change in X along the line. In regression b is called as regression coefficient Intercept (a) Figure 8.4: Intercept of a line Slope (b) Figure 8.5: Slope of a line a and b can be considered as a finger print of a line; with these values we can easily identify the line. So now our problem is simple, to find a line of best, estimate a &amp; b, such that error ei of each observation is minimized. For that we use the method of least squares. 8.7 Method of least squares On considering the error term ei; equation of a straight line is yi=a+bxi+ei; Where ei is the ith error term corresponding to yi, i =1,2,...,n Line of best fit can be obtained by estimating a and b by minimizing error sum ei. By theorem ei =0; so a and b are estimated by minimising ei 2 8.8 Principle of least squares The statistical method used to determine a line of best fit by minimizing the sum of squares of the error term ei 2 yi=a+bxi+ei; ei = yi  (a+bxi) ei2 = {yi  (a+bxi)}2  ei2 =  {yi  (a+bxi)}2  ei2 is called as error sum of squares. As we are minimizing error sum of squares, hence the name principle of least squares. We want to minimize, E =  ei2 =  {yi  (a+bxi)}2 i.e. we need to find a and b such that E is minimum E can be minimized by taking derivative with respect to a and b and equating to zero. On doing so we will get two equations, these equations are termed as normal equations and solving those normal equations will give the formula for a and b. We are not discussing calculation part here. After taking derivatives we will get two equations (Normal equations) as below: \\[\\sum_{i = 1}^{n}{y_{i} = n\\mathbf{a} + \\mathbf{b}\\sum_{i = 1}^{n}x_{i}}\\] \\[\\sum_{i = 1}^{n}{y_{i}x_{i} = \\mathbf{a}\\sum_{i = 1}^{n}x_{i} + \\mathbf{b}\\sum_{i = 1}^{n}x_{i}^{2}}\\] On solving the above equations we will get Regression coefficient, b = \\(\\frac{\\sum_{i = 1}^{n}{y_{i}x_{i} - \\frac{\\sum_{i = 1}^{n}{y_{i}\\sum_{i = 1}^{n}x_{i}}}{n}}}{\\sum_{i = 1}^{n}x_{i}^{2} - \\frac{\\left( \\sum_{i = 1}^{n}x_{i} \\right)^{2}}{n}}\\) =\\(\\frac{cov(x,y)}{var(x)}\\) \\[\\mathbf{b =}\\frac{\\mathbf{cov(x,y)}}{\\mathbf{var(x)}} \\] \\[\\mathbf{a =}\\overline{\\mathbf{y}}\\mathbf{- b}\\overline{\\mathbf{x}}\\] where \\(\\overline{y}\\) = mean of y; \\(\\overline{x}\\) = mean of x 8.9 Two lines of regression There are two lines of regression- that of y on x and x on y. Regression of y on x Consider the two variables x and y, if you are considering y as dependent variable and x as independent variable then your equation is: y = a + bx This is used to predict the unknown value of variable y when value of variable x is known. Usually b here is denoted as byx \\[\\mathbf{b}_{\\mathbf{\\text{yx}}}\\mathbf{=}\\frac{\\mathbf{cov(x,y)}}{\\mathbf{var(x)}}\\] Consider Example 8.1; considering ice cream sales as dependent variable and temperature as independent variable Figure 8.6: Scatter diagram of data in Example 8.1 Regression of x on y Consider the two variables x and y, if you are considering x as dependent variable and y as independent variable then your equation is: x= c + my; where c is the intercept and m is the slope This is used to predict the unknown value of variable x when value of variable y is known. Usually b here is denoted as bxy \\[\\mathbf{b}_{\\mathbf{\\text{xy}}}\\mathbf{=}\\frac{\\mathbf{cov(x,y)}}{\\mathbf{var(y)}}\\] Consider Example 8.1; considering temperature as dependent variable and ice cream sales as independent variable Figure 8.7: Scatter diagram of data in Example 8.1 You can see both the regression were different. It depends on the experimenter to choose dependent and independent variable. In the above example it is evident that considering temperature as dependent variable is meaningless, i.e. what is the usefulness in predicting temperature based on ice cream sales?. So the selection of dependent and independent variable is entirely the discretion of experimenter based on the objective of his study. 8.10 Assumptions of Regression If y is the dependent variable and x is the independent variable then The xs are non-random or fixed constants At each fixed value of x the corresponding values of y have a normal distribution about a mean. For any given x, the variance of y is same. The values of y observed at different levels of x are completely independent. 8.11 Properties of Regression coefficients The correlation coefficient between x and y is the geometric mean of the two regression coefficients byx and bxy \\[r = \\sqrt{b_{\\text{yx}}b_{\\text{xy}}}\\] Regression coefficients are independent of change of origin but not of scale. If one regression coefficient is greater than unit, then the other must be less than unit but not vice versa. i.e. both the regression coefficients can be less than unity but both cannot be greater than unity, i.e. if byx &gt;1 then bxy &lt;1 and if bxy &gt;1, then byx &lt;1. Also if one regression coefficient is positive the other must be positive (in this case the correlation coefficient is positive) and if one regression coefficient is negative the other must be negative (in this case the correlation coefficient is negative). 8.12 Uses of Regression Prediction: The regression analysis is useful in predicting the value of one variable from the given value of another variable. Such predictions are useful when it is very difficult or expensive to measure the dependent variable, Y. Identify the strength of relationship: the regression might be used to identify the strength of the effect that the independent variable(s) have on a dependent variable. Like the strength of relationship between dose and effect, sales and marketing spending, or age and income. Forecast effects or impact of changes: That is, the regression analysis helps us to understand how much the dependent variable changes with a change in one or more independent variables. A typical question is, \"how much additional sales income do I get for each additional 1000 spent on marketing Predicts trends and future values: The regression analysis can be used to predict trend and future values, like what will the price of gold be in 6 months? 8.13 Example problem Now consider the example 8.1 and answer the questions Temperature (°C) Ice Cream Sales (in $) 14.2 215 16.4 325 11.9 185 15.2 332 18.5 406 22.1 522 19.4 412 25.1 614 23.4 544 18.1 421 22.6 445 17.2 408 What is the functional form of relationship between Temperature and Ice cream sales? What will be the Ice cream sales when temperature is 20o Celsius? Solution Fit a model considering Ice cream sales as dependent variable (y) and temperature as independent variable (x). Fitting a model means estimating b and a using equation. After fitting the model put 20 in the x value you will get the predicted y value Model: y = a+bx Sl. No. Temperature (x) Sales (y) \\[x_{i} - \\overline{x}\\] 1 14.2 215 -4.475 2 16.4 325 -2.275 3 11.9 185 -6.775 4 15.2 332 -3.475 5 18.5 406 -0.175 6 22.1 522 3.425 7 19.4 412 0.725 8 25.1 614 6.425 9 23.4 544 4.725 10 18.1 421 -0.575 11 22.6 445 3.925 12 17.2 408 -1.475 SUM 224.1 4829 0 \\[\\left( y_{i} - \\overline{y} \\right)\\] \\(\\left( x_{i} - \\overline{x} \\right)\\)× \\(\\left( y_{i} - \\overline{y} \\right)\\) \\[\\left( x_{i} - \\overline{x} \\right)^{2}\\] \\[\\left( y_{i} - \\overline{y} \\right)^{2}\\] -187.42 838.69 20.0256 35125.01 -77.417 176.123 5.17563 5993.34 -217.42 1473 45.9006 47270.01 -70.417 244.698 12.0756 4958.507 3.58333 -0.6271 0.03063 12.84028 119.583 409.573 11.7306 14300.17 9.58333 6.94792 0.52562 91.84028 211.583 1359.42 41.2806 44767.51 141.583 668.981 22.3256 20045.84 18.5833 -10.685 0.33062 345.3403 42.5833 167.14 15.4056 1813.34 5.58333 -8.2354 2.17563 31.17361 0 5325.03 176.983 174754.9 n =12 \\[mean,\\overline{x} = \\ \\frac{224.1}{12} = 18.675\\] \\[mean,\\overline{y} = \\ \\frac{4829}{12} = 402.416\\] Cov (x,y) = \\(\\frac{1}{n}\\sum_{i = 1}^{n}{\\left( x_{i} - \\overline{x} \\right)\\left( y_{i} - \\overline{y} \\right)}\\) \\(\\sum_{i = 1}^{12}{\\left( x_{i} - \\overline{x} \\right)\\left( y_{i} - \\overline{y} \\right)} = 5325.03\\) Cov (x,y) = \\(\\frac{5325.03}{12} = 443.752\\) \\[variance\\ of\\ x,\\ var\\left( x \\right) = \\ \\frac{1}{n}\\sum_{i = 1}^{n}\\left( x_{i} - \\overline{x} \\right)^{2} = \\frac{176.983}{12} = 14.7485\\] \\[\\mathbf{b =}\\frac{\\mathbf{cov(x,y)}}{\\mathbf{var(x)}}\\] \\[\\mathbf{b =}\\frac{443.752}{14.7485}\\mathbf{=}30.088\\] \\[\\mathbf{a =}\\overline{\\mathbf{y}}\\mathbf{- b}\\overline{\\mathbf{x}}\\] \\[\\mathbf{a =}402.416 - 30.088\\left( 18.675 \\right) = \\ - 159.477\\] So our model is \\[y = \\ - 159.477 + 30.088x\\] \\[Ice\\ cream\\ sales = \\ - 159.477 + 30.088(Temperature)\\] Ice cream sales when temperature is 20o Celsius \\[x = 20\\] \\(y = \\ - 159.477 + 30.088(20)\\) = 442.283 So the predicted ice cream sales at 20o Celsius is $442.283 ************************************************************** "],["references.html", "Chapter 9 References", " Chapter 9 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
