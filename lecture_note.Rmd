---
title: "LECTURE NOTES OF STAT 3202"
author: "Dr. Pratheesh P. Gopinath"
date: "2022-01-30"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib]
biblio-style: apalike
link-citations: yes
github-repo: https://github.com/KAUMELON/stat3202
description: "A BOOK FOR UNDERGRADUATE PROGRAMME IN AGRICULTURE"
cover-image: images/cover.PNG
---  
 

# Welcome {-} 
<p style="text-align: center;"><a href="https://coavellayani.kau.in/people/dr-pratheesh-p-gopinath"><img src="images/cover.png" alt="STAT 3202" /></a></p>  
Welcome to the book **LECTURE NOTES ON STATISTICAL METHODS AND APPLICATIONS**.

# Preface {-}  
<p style="text-align: justify;">
</p>  



<p style="text-align: justify;"> **Note**: This book is published in MeLoN (Module for e-Learning & Online Notes) . The online version of this book is free to read here.</p> 
````{=html}
<a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.
````
<p>If you have any feedback, please feel free to contact [Dr.Pratheesh P. Gopinath](https://coavellayani.kau.in/people/dr-pratheesh-p-gopinath). E-mail: `pratheesh.pg@kau.in` Thank you!</p>  

<p>This book is a collection of all lecture notes covering the syllabus of statistics course in B.Sc.(Hons.) Agriculture under Kerala Agricultural University </p>  

```{r logo, echo=FALSE,out.width="30%", fig.align='center'}
knitr::include_graphics(rep("docs/logo.png"))
```






<!--chapter:end:index.Rmd-->

---
output:
  pdf_document: default
  html_document: default
---
# Introduction  

<p style="text-align: justify;">In this lecture we will have the introduction, which includes, definition of statistics, collection and classification of data, formation of frequency distribution.[@goon] [@gupta]</p>  

## Origin of the word ‚ÄúStatistics‚Äù  

<p style="text-align: justify;">The term statistics was derived from the Neo-Latin word `statisticum collegium` meaning ‚Äúcouncil of state" and the Italian word `statista` meaning "statesman" or "politician".</p>  

<p style="text-align: justify;">A German word `Statistik`, got the meaning "collection and classification of data" generally in the early 19th century. This word was first introduced by Gottfried Achenwall (1749). `Statistik` was  originally designated as a term for analysis of data about the state (data used by government or other administrative bodies). The term `Statistik` was introduced into English in 1791 by Sir John Sinclair when he published the first of 21 volumes titled "Statistical Account of Scotland" [@ball]. The first book to have 'Statistics' in its title was "Contributions to Vital Statistics" (1845) by Francis GP Neison, actuary^[actuary: A person who compiles and analyses statistics and uses them to calculate insurance risks and premiums.] to the Medical Invalid and General Life Office.</p>
```{r scotland, echo=FALSE,fig.cap='Statistical Account of Scotland by Sir John Sinclair (1791)',fig.height=4, fig.align='center'}
knitr::include_graphics(rep("images/history1.png"))
```
## Statistics and Mathematics  

Mathematics follows a rigid theorem and proof. Mathematical theories involve well-defined and proven facts which has the minimal scope of change. However, Statistics is a discipline where real-life data is handled. This factor makes this field of study more abstract, where individuals have to develop newer solutions to problems that was new and not observed before. Statistics is an applied science; in mathematics the goal is to prove theorems. In statistics, the main goal is to develop good methods for understanding data and making decisions. Statisticians often use mathematical theorems to justify their methods, but theorems are not the main focus. Statistics is now considered as an independent field which uses mathematics to solve real life problems.  

## Definition of Statistics

<p style="text-align: justify;">Statistics is the science which deals with the

* Collection of data

* Organization of data or Classification of data

* Presentation of data

* Analysis of data

* Interpretation of data</p>

Two main branches of statistics are:

<p style="text-align: justify;">**Descriptive statistics**, which deals with summarizing data from a sample using indexes such as the mean or standard deviation etc.</p>

<p style="text-align: justify;">**Inferential statistics**, use a random sample of data taken from a population to describe and make inferences about the population parameters.</p>

## Data  

<p style="text-align: justify;">Data can be defined as individual pieces of factual information recorded and used for the purpose of analysis. It is the raw information from which inferences are drawn using the science "STATISTICS".</p>

<p style="text-align: justify;">Example for data

* No. of farmers in a block.

* The rainfall over a period of time.

* Area under paddy crop in a state.</p>

## Use and limitations of statistics

<p style="text-align: justify;">**Functions of statistics**: Statistics simplifies complexity, presents facts in a definite form, helps in formulation of suitable policies, facilitates comparison and helps in forecasting. Valid results and conclusion are obtained in research experiments using proper statistical tools.</p>

<p style="text-align: justify;">**Uses of statistics:** Statistics has pervaded almost all spheres of human activities. Statistics is useful in the administration, Industry, business, economics, research workers, banking,insurance companies etc.</p>

**Limitations of Statistics**

* Statistical theories can be applied only when there is variability in the experimental material.

* Statistics deals with only aggregates or groups and not with individual objects.

* Statistical results are not exact.

* Statistics are often misused.

## Population and Sample

<p style="text-align: justify;">Consider the following example.Suppose we wish to study the body masses of all students of College of Agriculture, Vellayani. It will take us a long time to measure the body masses of all students of the college and so we may select 20 of the students and measure their body masses (in kg). Suppose we obtain the measurements like this</p>

49 56 48 61 59 43 58 52 64 71 57 52 63 58 51 47 57 46 53 59

<p style="text-align: justify;">In this study, we are interested in the body masses of all students of College of Agriculture, Vellayani. The set of body masses of all students of College of Agriculture, Vellayani is called the **population** of this study. The set of 20 body masses, *W* = {49, 56,48, ..., 53, 59}, is a **sample** from this population.</p>

### Population 
A population is the set of all objects we wish to study  

### Sample  
A sample is part of the population we study to learn about the population.

## Variables and constants

### Variables  

<p style="text-align: justify;">Any type of observation which can take different values for different people, or different values at different times, or places, is called a variable. The following are examples of variables:  

* family size, number of hospital beds, number of schools in a country, etc.  

* height, mass, blood pressure, temperature, blood glucose level, etc.</p>  

<p style="text-align: justify;">Broadly speaking, there are two types of variables -- **quantitative** and **qualitative** (or categorical) variables</p>

### Constants

<p style="text-align: justify;">Constants are characteristics that have values that do not change. Examples of constants are: pi (ùùÖ) = the ratio of the circumference of a circle to its diameter (ùùÖ = 3.14159\...) and *e*, the base of the natural or (Napierian) logarithms (*e*=2.71828).</p>

## Types of variables

### Quantitative variables

A quantitative variable is one that can take numerical values. The variables like  family size, number of hospital beds, number of schools in a country, height, mass, blood pressure, temperature, blood glucose level, etc. are examples of quantitative variables. Quantitative variables may be characterized further as to whether they
are discrete or continuous

### Discrete variables  

The variables like family size, number of hospital beds, number of schools in a country, etc. can be counted. These are examples of discrete variables. Variables that can only take on a finite number of values are called \"discrete variables.\" Any variable phrased as "the number of ...", is discrete, because it is possible to list its possible
values {0,1, ...}. Any variable with a finite number of possible values is discrete. The following example illustrates the point. The number of daily admissions to a hospital is a discrete variable since it can be represented by a whole number, such as 0, 1, 2 or 3. The number of daily
admissions on a given day cannot be a number such as 1.8, 3.96 or 5.33.

### Continuous variables  

The variables like height, mass, blood pressure, temperature, blood glucose level, etc. can be measured. These are examples of continuous variables. A continuous variable does not possess the gaps or interruptions characteristic of a discrete variable. A continuous
variable can assume any value within a specific relevant interval of values assumed by the variable. Notice that age is continuous since an individual does not age in discrete jumps. Weight can be measured as 35.5, 35.8 kg etc so, it is a continuous variable.

### Categorical variables  

A variable is called categorical when the measurement scale is a set of categories. For example, marital status, with categories (single,married, widowed), is categorical. Whether employed (yes, no), religious affiliation (Protestant, Catholic, Jewish, Muslim, others, none),
colours etc. Categorical variables are often called qualitative. It can be seen that categorical variables can neither be measured nor counted.

## Measurement scales  

Variables can further be classified according to the following four levels of measurement: nominal, ordinal, interval and ratio.

### Nominal scale  
This scale of measure applies to qualitative variables only. On the nominal scale, no order is required. For example,gender is nominal, blood group is nominal, and marital status is also nominal. We cannot perform arithmetic operations on data measured on the nominal scale.  

### Ordinal scale  
This scale also applies to qualitative data. On the
ordinal scale, order is necessary. This means that one category is lower than the next one or vice versa. For example, Grades are ordinal, as excellent is higher than very good, which in turn is higher than good, and so on. It should be noted that, in the ordinal scale, differences between category values have no meaning.

### Interval scale  
This scale of measurement applies to quantitative
data only. In this scale, the zero point does not indicate a total absence of the quantity being measured. An example of such a scale is temperature on the Celsius or Fahrenheit scale. Suppose the minimum temperatures of 3 cities, A, B and C, on a particular day were 0^0^C, 20^0^C and 10^0^C, respectively. It is clear that we can find the differences between these temperatures. For example, city B is 20^0^C hotter than city A. However, we cannot say that city A has no temperature. Moreover, we cannot say that city B is twice as hot as city C, just because city B is 20^0^C and city C is 10^0^C. The reason is that, in the interval scale, the ratio between two numbers is not meaningful.

### Ratio scale  
This scale of measurement also applies to quantitative
data only and has all the properties of the interval scale. In addition to these properties, the ratio scale has a meaningful zero starting point and a meaningful ratio between 2 numbers. An example of variables measured on the ratio scale, is weight. A weighing scale that reads 0 kg
gives an indication that there is absolutely no weight on it. So the zero starting point is meaningful. If Ram weighs 40 kg and Laxman weighs 20 kg, then Ram weighs twice as Laxman. Another example of a variable measured on the ratio scale is temperature measured on the Kelvin scale. This has a true zero point.

```{r variables, echo=FALSE,fig.cap='Classification of variables',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image2.jpeg"))
```


## Collection of Data

The first step in any enquiry (investigation) is the collection of data. The data may be collected for the whole population or for a sample only. It is mostly collected on a sample basis. Collecting data is very difficult job. The enumerator or investigator is the well trained individual who collects the statistical data. The respondents are the persons from whom the information is collected.

### Types of Data

There are two types (sources) for the collection of data:
* Primary Data  
* Secondary Data

#### Primary Data

Primary data are the first hand information which is collected, compiled and published by organizations for some purpose. They are the most original data in character and have not undergone any sort of statistical treatment.   

Example: Population census reports are primary data because these are collected, complied and published by the population census organization.  

#### Secondary Data

The secondary data are the second hand information which is already collected by an organization for some purpose and are available for the present study. Secondary data are not pure in character and have undergone some treatment at least once.  

Example: An economic survey of England is secondary data because the data are collected by more than one organization like the Bureau of Statistics, Board of Revenue, banks, etc.

## Methods of Collecting Primary Data

Primary data are collected using the following methods:  

### Personal Investigation  
The researcher conducts the survey him/herself and collects data from it. The data collected in this way are usually accurate and reliable. This method of collecting data is
only applicable in case of small research projects.

### Through Investigation  
Trained investigators are employed to collect the data. These investigators contact the individuals and fill in
questionnaires after asking for the required information. Most organizations utilize this method.  

### Collection through Questionnaire  
Researchers get the data from local representations or agents that are based upon their own experience. This method is quick but gives only a rough estimate.  

### Through the Telephone  
Researchers get information from individuals through the telephone. This method is quick and gives accurate information.

## Methods of Collecting Secondary Data  
Secondary data are collected by the following methods:

### Official  
Publications from the Statistical Division, Ministry of Finance, the Federal Bureaus of Statistics, Ministries of Food, Agriculture, Industry, Labor, etc.  

### Semi-Official  

* Publications from State Bank, Railway Board, Central Cotton Committee, Boards of Economic Enquiry etc.  
* Publication of Trade Associations, Chambers of Commerce, etc.  
* Technical and Trade Journals and Newspapers.  
* Research Organizations such as universities and other institutions.

## Difference Between Primary and Secondary Data  
The difference between primary and secondary data is only a change of hand. Primary data are the first hand information which is directly collected form one source. They are the most original in character and have not undergone any sort of statistical treatment, while secondary data are obtained from other sources or agencies. They are not pure in character and have undergone some treatment at least once.  

## Frequency distribution  

Table shows the number of children per family for 54 families selected from a town in India. The data, presented in this form in which it was collected, is called raw data.  
```{r raw, echo=FALSE,fig.cap='raw data set of No. of children in 54 families',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image3.jpeg"))
```  
It can be seen that, the minimum and the maximum numbers of children per family are 0 and 4, respectively. Apart from these numbers, it is impossible, without further careful study, to extract any exact information from the data. But by breaking down the data into the form below  
```{r freq, echo=FALSE,fig.cap='Frequency distribution table',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image4.jpeg"))
```  
Now certain features of the data become apparent. For instance, it can easily be seen that, most of the 54 families selected have two children because number of houses having 2 children is 18. This information cannot easily be obtained from the raw data. The above table is called a frequency table or a frequency distribution. It is so called because it gives the frequency or number of times each
observation occurs. Thus, by finding the frequency of each observation, a more intelligible picture is obtained.

### Construction of frequency distribution

1.  List all values of the variable in ascending order of magnitude.  

2.  Form a tally column, that is, for each value in the data, record a stroke in the tally column next to that value. In the tally, each fifth stroke is made across the first four. This makes it easy to count the entries and enter the frequency of each observation.  

3.  Check that the frequencies sum to the total number of observations  

## Grouped frequency distribution  
Data below gives the body masses of 22 patients, measured to the nearest kilogram.  

```{r mass, echo=FALSE,fig.cap='Body masses of 22 patients',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image5.jpeg"))
```  
It can be seen that the minimum and the maximum body masses are 42 kg and 83 kg, respectively. A frequency distribution giving every body mass between 42 kg and 83 kg would be very long and would not be very informative. The problem is to overcome by grouping the data into classes.  
If we choose the classes  
41 -- 49  
50 -- 58  
59 -- 67  
68 -- 76
and 77 -- 85, we obtain the frequency distribution given below:

```{r grptable, echo=FALSE,fig.cap='Grouped Frequency distribution table',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image6.jpeg"))
```  
Above table gives the frequency of each group or class; it is therefore called a grouped frequency table or a grouped frequency distribution. Using this grouped frequency distribution, it is easier to obtain information about the data than using the raw data. For instance, it can be seen that 17 of the 22 patients have body masses between 50 kg and 76 kg (both inclusive). This information cannot easily be obtained from the raw data.  
It should be noted that, even though above table is concise, some information is lost. For example, the grouped frequency distribution does not give us the exact body masses of the patients. Thus the individual body masses of the patients are lost in our effort to obtain an overall picture.  

## Terms used in grouped frequency tables.

**Class limits**  

The intervals into which the observations are put are called [class intervals]{.ul}. The end points of the class intervals are called [class limits]{.ul}. For example, the class interval 41 -- 49, has lower class limit 41 and upper class limit 49.  

**Class boundaries**

The raw data in the above example were recorded to the nearest kilogram. Thus, a body mass of 49.5kg would have been recorded as 50 kg, a body mass of 58.4 kg would have been recorded as 58 kg, while a body mass of 58.5 kg would have been recorded as 59 kg. It can therefore be seen
that, the class interval 50 -- 58, consists of measurements greater than or equal to 49.5 kg and less than 58.5 kg. The numbers 49.5 and 58.5 are called the lower and upper boundaries of the class interval 50 -- 58. The class boundaries of the other class intervals are given below:

```{r clsslmt, echo=FALSE,fig.cap='Class boundary and class limits',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image7.jpeg"))
```   
[Note:]{.ul}  
Notice that the lower class boundary of the i^th^ class interval is the mean of the lower class limit of the class interval and the upper class limit of the (i-1)^th^ class interval (i = 2, 3, 4, ...). For example, in the table above the lower class boundaries of the second and the fourth class intervals are (50 + 49) /2 = 49.5 and (68 + 67)/2 = 67.5 respectively.  
It can also be seen that the upper class boundary of the i^th^ class interval is the mean of the upper class limit of the class interval and the lower class limit of the (i+1)^th^ class interval (i = 1, 2, 3, ...). Thus, in the above table the upper class boundary of the fourth class
interval is (76 + 77)/2 = 76.5.  

**Class mark**  
The mid-point of a class interval is called the class mark or class mid-point of the class interval. It is the average of the upper and lower class limits of the class interval. It is also the average of the upper and lower class boundaries of the class interval. For example, in the table, the class mark of the third class interval was found as
follows: class mark =(59+67) /2 = (58.5 + 67.5)/2= 63.  

**Class width**  
The difference between the upper and lower class boundaries of a class interval is called the class width of the class interval. Class widths of class intervals can also be found by subtracting two consecutive lower class limits, or by subtracting two consecutive upper class limits.

[Note:]{.ul}  

The width of the i^th^ class interval is the numerical difference between the upper class limits of the i^th^ and the ( i-1)^th^ class intervals (i = 2, 3, ...). It is also the numerical difference between the lower class limits of the i^th^ and the (i+1) ^th^ class intervals (i = 1, 2, ...).  

In grouped frequency table above the width of the first class interval is \|41-50\| = 9. This is the numerical difference between the lower class limits of the first and the second class intervals. The width of the second class interval is \|50-59\|= 9. This is the numerical difference between the lower class limits of the second and the third
class intervals. It is also equal to \|58-49\| the numerical, difference between the upper class limits of the first and the second class intervals.

## Construction of frequency distribution table

**Step 1**. Decide how many classes you wish to use.  
**Step 2**. Determine the class width  
**Step 3**. Set up the individual class limits 
**Step 4**. Tally the items into the classes  
**Step 5**. Count the number of items in each class  

Consider the example  
An agricultural student measured the lengths of leaves on an oak tree (to the nearest cm). Measurements on 38 leaves are as follows  
9,16,13,7,8,4,18,10,17,18,9,12,5,9,9,16,1,8,17,1,10,5,9,11,15,6,14,9,1,12,5,16,4,16,8,15,14,17

**Step 1.** Decide how many classes you wish to use.

H.A. Sturges provides a formula for determining the approximation number of classes. $\mathbf{k = 1 + 3.322}\mathbf{\log}\mathbf{N}$**.** Number of classes should be greater than calculated *k*  
In our example *N*=38, so *k*=1+3.322√ólog(38) = 1+3.322√ó1.5797 = 6.24 = approx 7  

So the approximated number of classes should be not less than 6.24 *i*.*e*.$\ k^{'}$ =7  

**Step 2.** Determine the class width

Generally, the class width should be the same size for all classes. *C*= \| max ‚àí min\|/ k. Class width $C^{'}$should be greater than calculated *C*. For this example, *C* = \| 18‚àí 1\|/**6.24** = 2.72, so approximately class width$C^{'} =$ 3 (Note that *k* used here is the calculated value using Struges formula not the approximated).  

**Step 3.** To set up the individual class limits, We need to find the lower limit only  

$$L = min - \frac{C^{'} \times k^{'} - (max - min)}{2}$$

where C and *k* here are final approximated class width and number of classes respectively in our example $L = 1 - \frac{3 \times 7 - (18 - 1)}{2}$=1-2=-1; since there is no negative values in data = 0.  

```{r ch1, echo=FALSE,warning=FALSE,results='asis'}
library(knitr)
library(kableExtra)
dt<-read.csv("csv/c1e1.csv")
dt %>%
  kbl(booktabs = TRUE, align = "c") %>%
   kable_classic(full_width = F, html_font = "Cambria") %>%
kable_styling(latex_options = "HOLD_position")


```

Even though the student only measured in whole numbers, the data is continuous, so \"4 cm\" means the actual value could have been anywhere from 3.5 cm to 4.5 cm.  

## Cumulative frequency

In many situations, we are not interested in the number of observations in a given class interval, but in the number of observations which are less than (or greater than) a specified value. For example, in the above table, it can be seen that 3 leaves have length less than 3.5 cm and 9
leaves (i.e. 3 + 6) have length less than 6.5 cm. These frequencies are called cumulative frequencies. A table of such cumulative frequencies is called **a cumulative frequency table** or **cumulative frequency distribution**.  

Cumulative frequency is defined as a running total of frequencies. Cumulative frequency can also defined as the sum of all previous frequencies up to the current point. Notice that the last cumulative frequency is equal to the sum of all the frequencies. Two types of cumulative frequencies are Less than cumulative frequency and Greater than cumulative frequency. Less than cumulative frequency
(LCF) is the number of values less than a specified value. Greater than cumulative frequency (GCF) is the number of observations greater than a specified value.  

The specified value for LCF in the case of grouped frequency
distribution will be upper limits and for GCF will be the lower limits of the classes. LCF's are obtained by adding frequencies in the successive classes and GCF are obtained by subtracting the successive class frequencies from the total frequency.  

## Relative frequency

It is sometimes useful to know the proportion, rather than the number, of values falling within a particular class interval. We obtain this information by dividing the frequency of the particular class interval by the total number of observations. **Relative frequency** of a class
is the frequency of class / total observation. Relative frequencies all add up to 1.  

```{r ch2, echo=FALSE,warning=FALSE,results='asis'}
library(knitr)
library(kableExtra)
dt<-read.csv("csv/c1e2.csv")
dt %>%
  kbl(booktabs = TRUE,align = "c") %>%
   kable_classic(full_width = F, html_font = "Cambria") %>%
kable_styling(latex_options = "HOLD_position")
   add_footnote("Note: A= Less than cumulative frequency; B= Greater than cumulative frequency, C = Relative frequency", notation="alphabet")
```  


&nbsp;  
&nbsp;  
&nbsp;  


::: {#hello .greeting .message style="color: #c9c6c5;"}  
<center>  

**Data is the sword of the 21st century, those who wield it well, the Samurai.‚Äù - Jonathan Rosenberg, former Google SVP**!  

</center>
:::





<!--chapter:end:01-lecture01.rmd-->

# Graphical representation of data

We found that information given in a frequency distribution is easier to interpret than raw data. Information given in a frequency distribution in a tabular form is easier to grasp if presented graphically. Many types of diagrams are used in statistics, depending on the nature of the data and the purpose for which the diagram is intended.

## Histogram

A histogram consists of rectangles with:

-   Bases on a horizontal axis, centres at the class marks, and lengths equal to the class widths.  

-   Areas proportional to class frequencies.

[Note:]{.ul}  
If the class intervals are of equal size, then the heights of the rectangles are proportional to the class frequencies and it is then customary to take the heights of the rectangles numerically equal to the class frequencies. If the class intervals are of different widths, then
the heights of the rectangles are proportional to $\frac{\text{Class Frequency}}{\text{Class Width}}$. This ratio is called **frequency density**.

Table below shows the frequency distribution of the body masses of 50 AIDS patients. Draw a Histogram.

  Mass        30 -- 39   40 -- 49   50 -- 59   60 -- 69   70 -- 79   80 -- 89
  ----------- ---------- ---------- ---------- ---------- ---------- ----------
  Frequency   3          6          17         13         8          3

```{r hist1, echo=FALSE,fig.cap='Histogram',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image8.png"))
```  


## Cumulative frequency curve (Ogive)

A graph obtained by plotting a cumulative frequency against the class boundary and joining the points by a smooth curve, is called a cumulative frequency curve. It is also called as Ogive. Two types of ogive are there, Less Than Type Cumulative Frequency Curve (Less than Ogive) and Greater Than Type Cumulative Frequency Curve (Greater than Ogive).

### Less than Ogive  
Also known as  less than type cumulative frequency curve. Here we use the upper limit of the classes and the less than cumulative frequency to plot the curve. Let us see for the example of the body masses of 50 AIDS patients.

  Upper limit                      39   49   59   69   79   89
  -------------------------------- ---- ---- ---- ---- ---- ----
  Less than Cumulative frequency   3    9    26   39   47   50

```{r lto, echo=FALSE,fig.cap='Less than ogive',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image9.jpeg"))
``` 

### Greater than Ogive
Also known as greater than type cumulative frequency curve Here we use the lower limit of the classes and the greater than cumulative frequency to plot the curve.

  Lower Limit                         30   40   50   60   70   80
  ----------------------------------- ---- ---- ---- ---- ---- ----
  Greater than Cumulative frequency   50   47   41   24   11   3

```{r gco, echo=FALSE,fig.cap='greater than ogive',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image10.jpeg"))
```   
[Note:]{.ul}  
Intersection of both ogives gives the median

### Frequency polygon

A grouped frequency table can also be represented by a frequency
polygon, which is a special kind of line graph. To construct a frequency
polygon, we plot a graph of class frequencies against the corresponding
class mid-points and join successive points with straight lines. Frequency polygon is also obtained by joining the midpoints of a histogram as shown in Fig 2.5.  

```{r ex2234, echo=FALSE,warning=FALSE,results='asis'}
library(knitr)
library(kableExtra)
dt<-read.csv("csv/c2e1.csv")
dt %>%
  kbl(col.names = NULL) %>%
   kable_classic(full_width = F, html_font = "Cambria")%>%
kable_styling(latex_options = "HOLD_position")
```    


```{r freqpol, echo=FALSE,fig.cap='Frequency polygon',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image11.jpeg"))
```  

```{r frehit, echo=FALSE,fig.cap='Frequency polygon and histogram',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image12.png"))
```


## Stem-and-leaf plot

A stem-and-leaf plot is a graphical device that is useful for representing a relatively small set of data which takes numerical values. To construct a stem-and-leaf plot, we partition each measurement into two parts. The first part is called the stem, and the second part is called the leaf. Here each numerical value is divided into two parts:
The leading digits become the stem the trailing digits become the leaf. One advantage of the stem-and-leaf display over a frequency distribution is that we retain the value of each observation. Another is the distribution of the data within each groups is clear. A stem-and-leaf plot conveys similar information as a histogram. Turned on its side, it has the same shape as the histogram. In fact, since the
stem-and-leaf plot shows each observation,it displays information that is lost in a histogram. A properly
constructed stem-and-leaf plot, like a histogram, provides information regarding the range of the data set, shows the location of the highest concentration of measurements, and reveals the presence or absence of symmetry.

Consider the example

10,15,22,25,28,23,29,31,36,45,48  

stem and leaf plot can be drawn as shown below.  


```{r ex343, echo=FALSE,warning=FALSE,results='asis'}
library(knitr)
library(kableExtra)
dt<-read.csv("csv/stem.csv")
dt %>%
  kbl(booktabs = TRUE, align = "c") %>%
   kable_classic(full_width = F, html_font = "Cambria") %>%
kable_styling(latex_options = "HOLD_position")


```  
```{r stem, echo=FALSE,fig.cap='Stem and Leaf plot',out.width="30%", fig.align='center'}
knitr::include_graphics(rep("images/image18.png"))
```

## Bar chart  
A bar chart or bar graph is a diagram consisting of a series of horizontal or vertical bars of equal width. The bars represent various categories of the data. There are three types of bar charts, and these are simple bar charts, component bar charts and grouped bar charts.

### Simple bar chart  
In a simple bar chart, the height (or length) of each bar is equal to the value of category in the y-axis it represents. For example data below shows the production of timber in five districts of Kerala in a certain year.

  District    Production
  ----------- -----------
  Alappuzha   600
  Kannur      900
  Trissur     1800
  Ernakulam   1500
  Wayanad     2400

```{r bar, echo=FALSE,fig.cap='Barchart',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image13.png"))
```

### Component bar chart

In a component bar chart, the bar for each category is subdivided into component parts; hence its name. Component bar charts are therefore used to show the division of items into components. This is illustrated in the following example.  

Example shows the distribution of sales of agricultural produce from a Farm in 1995, 1996 and 1997.  

```{r componentdata, echo=FALSE,fig.cap='Sales data of agricultural produce',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image14.jpeg"))
```

```{r componentbar, echo=FALSE,fig.cap='Component bar chart',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image15.jpeg"))
```  
The component bar chart shows the changes of each component over the years as well as the comparison of the total sales between different years.

### Grouped bar chart

For a grouped bar chart, the components are grouped together and drawn side by side. We illustrate this with the above example.  

```{r groupbar, echo=FALSE,fig.cap='Grouped bar chart',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image16.jpeg"))
```  

## Histogram and Bar chart  
| Items   | HISTOGRAM                                                                                                                  | BAR GRAPH                                                                                               |
|------------------------|----------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|
| Meaning                | Histogram refers to a graphical representation, that displays data by way of bars to show the frequency of numerical data. | Bar graph is a pictorial representation of data that uses bars to compare different categories of data. |
| Indicates              | Distribution of non-discrete variables                                                                                     | Comparison of discrete variables                                                                        |
| Presents               | Quantitative data                                                                                                          | Categorical data                                                                                        |
| Spaces                 | Bars touch each other, hence there are no spaces between bars                                                              | Bars do not touch each other, hence there are spaces between bars.                                      |
| Elements               | Elements are grouped together, so that they are considered as ranges.                                                      | Elements are taken as individual entities.                                                              |
| Can bars be reordered? | No                                                                                                                         | Yes                                                                                                     |
| Width of bars          | Need not to be same                                                                                                        | Same                                                                                                    |  

## Pie Charts

A pie chart is a circular graph divided into sectors, each sector representing a different value or category. The angle of each sector of a pie chart is proportional to the value of the part of the data it represents. The bar chart is more precise than the pie chart for visual comparison of categories with similar relative frequencies.  

### Steps for constructing a pie chart

1. Find the sum of the category values.  
2. Calculate the angle of the sector for each category, using the following formula.Angle of the sector for category A = $\frac{\text{value of category A}}{\text{sum of category values}} \times 360$  
3. Construct a circle and mark the centre.  
4. Use a protractor to divide the circle into sectors, using the angles obtained in step 2.  
5. Label each sector clearly.

See the example:  
A lady spent the following sums of money on buying ingredients for a family Christmas cake.

  Ingredients     Price     Angle
  --------------- --------- ------------------
  Flour           24        (24/240)√ó360= 36
  Margarine       96        144
  Sugar           18        27
  Eggs            60        90
  Baking powder   12        18
  Miscellaneous   30        45
  **Total**       **240**   **360**

```{r oiechart, echo=FALSE,fig.cap='Pie chart',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image17.jpeg"))
```  

&nbsp;  
&nbsp;  
&nbsp;  


::: {#hello .greeting .message style="color: #c9c6c5;"}  
<center>  

**Statistics is the grammar of science." - Karl Pearson**!  

</center>
:::




<!--chapter:end:02-lecture02.Rmd-->

# Measures of central tendency - I

In the previous lecture, you have learnt how data can be summarised in
the form of tables and presented in the form of graphs so that important
features can be illustrated easily and more effectively. In this
Lecture, we consider statistical measures which can be used to describe
the characteristics of a set of data.

We are interested in a single value that serves as a representative
value of the overall data. A¬†**measure of central tendency**¬†is a
summary statistic that represents the centre point or typical value of a
dataset.

There are five averages. Among them mean, median and mode are called
**simple averages** and the other two averages geometric mean and harmonic
mean are called **special averages**. These measures reflect numerical
values in the centre of a set of data and are therefore called measures
of central tendency.

[**Requisites of a Good Measure of Central Tendency:**]{.ui}

-   It should be rigidly defined.

-   It should be simple to understand & easy to calculate

-   It should be based upon all values of given data

-   It should be capable of further mathematical treatment.

-   It should have sampling stability.

-   It should be not be unduly affected by extreme values

[The main objectives of Measure of Central Tendency]{.ui}  

-   To condense data in a single value.

-   To facilitate comparisons between data.

## Arithmetic Mean

This is what people usually intend when they say \"average\". Arithmetic
mean or simply the mean of a variable is defined as the sum of the
observations divided by the number of observations. Mean of set of
numbers $x_{1\ },x_{2},\ldots,x_{n}$ is denoted as $\overline{x}$. It is
given by the formula

$$\overline{x} = \frac{x_{1} + x_{2} + \ldots + x_{n}}{n}$$

$= \frac{1}{n}\sum_{i = 1}^{n}x_{i}$

**Example 3.1** Find the mean of the numbers 2, 4, 7, 8, 11, 12

$$\overline{x} = \frac{2 + 4 + 7 + 8 + 11 + 12}{6} = \frac{44}{6} = 7.33$$

### The mean of a frequency distribution

#### Direct method

If the numbers $x_{1\ },x_{2},\ldots,x_{n}$ occur with frequencies
$f_{1\ },f_{2},\ldots,f_{n}$ respectively then

$$\overline{x} = \frac{x_{1}f_{1} + x_{2}f_{2\ \ } + \ldots + x_{n}f_{n}}{f_{1} + f_{2} + \ldots f_{n}}$$

$$= \frac{\sum_{i = 1}^{n}{f_{i}x_{i}}}{\sum_{i = 1}^{n}f_{i}}$$

**Example 3.2** Table below shows the body masses of 50 men. Find the
mean body mass.  

Table: (\#tab:bodymass) Body masses of 50 men.

  Mass(kg)    59   60   61   62   63
  ----------- ---- ---- ---- ---- ----
  Frequency   3    9    23   11   4

**Solution 3.2**

The calculation can be arranged as shown

  Mass(*x*)   Frequency(*f*)                *fx*
  ----------- ----------------------------- --------------------------------------
  59          3                             177
  60          9                             540
  61          23                            1403
  62          11                            682
  63          4                             252
              $\sum_{i = 1}^{n}f_{i}$= 50   $\sum_{i = 1}^{n}{f_{i}x_{i}}$= 3054

$\overline{x} = \frac{\sum_{i = 1}^{n}{f_{i}x_{i}}}{\sum_{i = 1}^{n}f_{i}} = \frac{3054}{50}$=
61.08 kg

#### Assumed mean method (Indirect method)

The amount of computation involved above can be reduced by using the
following formula:

$$\overline{x} = A + \frac{\sum_{i = 1}^{n}{f_{i}d_{i}}}{\sum_{i = 1}^{n}f_{i}}$$

Where $A$ is the assumed mean, which can be any value in *x*.
$d_{i} = x_{i} - A$, $f_{i}$ is the frequency of $x_{i}$

Consider the Example 2.2 see Table: \@ref(tab:bodymass)

let $A$ = 61; it can be any number in *x*

    Mass(*x*)   Frequency(*f*)                $$\mathbf{d}_{\mathbf{i}}\mathbf{=}\mathbf{x}_{\mathbf{i}}\mathbf{-}\mathbf{61}$$   $$\mathbf{f}_{\mathbf{i}}\mathbf{d}_{\mathbf{i}}$$
  ----------- ----------------------------- ----------------------------------------------------------------------------------- ----------------------------------------------------
  59          3                             -2                                                                                  -6
  60          9                             -1                                                                                  -9
  61          23                            0                                                                                   0
  62          11                            1                                                                                   11
  63          4                             2                                                                                   8
              $\sum_{i = 1}^{n}f_{i}$= 50                                                                                       $\sum_{i = 1}^{n}{f_{i}d_{i}}$= 4

$\overline{x} = 61 + \frac{4}{50}$ = 61.08 kg

The mean mass is 61.08 kg

### Mean of Grouped Data

#### Direct method

The mean for grouped data is obtained from the following formula:

$$\overline{x} = \frac{\sum_{i = 1}^{k}{f_{i}x_{i}}}{n}$$

Where $x_{i}$ = the mid-point of *i*^th^ class (*i*^th^ class mark);
$f_{i}$= the frequency of *i*^th^ class; $n$ = the sum of the
frequencies or total frequencies in a sample. Note that *i* =1,2\...,
*k*, *i*.*e*. there are *k* classes.

**Example 3.3** Shows the distribution of the marks scored by 60 students in a Physics examination. Find the mean mark.  

Table: (\#tab:phy) Distribution of the marks scored by 60 students  


Mark (%)             60-65   65-70   70-75   75-80   80-85
-------------------- ------- ------- ------- ------- -------
Number of students   2       15      25      14      4

**Solution 3.3**

The solution can be arranged as shown

  Marks   Class mark($\mathbf{x}_{\mathbf{i}}$)   Frequency($\mathbf{f}_{\mathbf{i}}$)   $$\mathbf{f}_{\mathbf{i}}\mathbf{x}_{\mathbf{i}}$$
  ------- --------------------------------------- -------------------------------------- ----------------------------------------------------
  60-65   62.5                                    2                                      125
  65-70   67.5                                    15                                     1012.5
  70-75   72.5                                    25                                     1812.5
  75-80   77.5                                    14                                     1085
  80-85   82.5                                    4                                      330
                                                  $\sum_{i = 1}^{n}f_{i}$= 60            $\sum_{i = 1}^{n}{f_{i}x_{i}}$= 4365

$\overline{x} = \frac{\sum_{i = 1}^{n}{f_{i}x_{i}}}{\sum_{i = 1}^{n}f_{i}} = \frac{4365}{60}$=
72.75

The mean mark is 72.75%

#### Coding method (Indirect method)

If all the class intervals of a grouped frequency distribution have equal size $C$ (class width); then the following formula can be used instead of direct method above. This formula makes calculations easier.

$$\overline{x} = A + C\frac{\sum_{i = 1}^{n}{f_{i}u_{i}}}{\sum_{i = 1}^{n}f_{i}}$$

Where $A$ is the he class mark with the highest frequency,
$u_{i} = \frac{x_{i} - A}{C}$, $f_{i}$ is the frequency of $x_{i}$, *C*
is the class width

This is called the "coding" method for computing the mean. It is a very short method and should always be used for finding the mean of a grouped frequency distribution with equal class widths.

Consider the Example 3.3 see Table:\@ref(tab:phy) 

$A$=72.5, class mark with highest frequency; $C$ =5

  Marks   Class mark($\mathbf{x}_{\mathbf{i}}$)   Frequency($\mathbf{f}_{\mathbf{i}}$)   $$\mathbf{u}_{\mathbf{i}}\mathbf{=}\frac{\mathbf{x}_{\mathbf{i}}\mathbf{- 72.5}}{\mathbf{5}}$$   $$\mathbf{f}_{\mathbf{i}}\mathbf{u}_{\mathbf{i}}$$
  ------- --------------------------------------- -------------------------------------- ------------------------------------------------------------------------------------------------ ----------------------------------------------------
  60-65   62.5                                    2                                      -2                                                                                               -4
  65-70   67.5                                    15                                     -1                                                                                               -15
  70-75   72.5                                    25                                     0                                                                                                0
  75-80   77.5                                    14                                     1                                                                                                14
  80-85   82.5                                    4                                      2                                                                                                8
                                                  $\sum_{i = 1}^{k}f_{i}$= 60                                                                                                             $\sum_{i = 1}^{k}{f_{i}u_{i}}$=3

$\overline{x} = 72.5 + 5 \times \left( \frac{3}{60} \right)$= 72.75

The mean mark is 72.75%

## Merits and demerits of Arithmetic mean Merits

[**Merits **]{.ul}

1.  It is rigidly defined.

2.  It is easy to understand and easy to calculate.

3.  If the number of items is sufficiently large, it is more accurate
    and more reliable.

4.  It is a calculated value and is not based on its position in the
    series.

5.  It is possible to calculate even if some of the details of the data
    are lacking.

6.  Of all averages, it is affected least by fluctuations of sampling.

7.  It provides a good basis for comparison.

[**Demerits**]{.ul}

1.  It cannot be obtained by inspection nor located through a frequency
    graph.

2.  It cannot be in the study of qualitative phenomena not capable of
    numerical measurement *i*.*e*. Intelligence, beauty, honesty etc.

3.  It can ignore any single item only at the risk of losing its
    accuracy.

4.  It is affected very much by extreme values.

5.  It cannot be calculated for open-end classes.

6.  It may lead to fallacious conclusions, if the details of the data
    from which it is computed are not given.  
    
## The median

**The median** of a set of data is defined as the middle value when the
data is arranged in order of magnitude. If there are no ties, half of
the observations will be smaller than the median, and half of the
observations will be larger than the median. The median can be the
middle most item that divides the group into two equal parts, one part
comprising all values greater, and the other, all values less than that
item. It is a positional measure.

### Median of ungrouped or raw data

Arrange the given *n* observations $x_{1\ },x_{2},\ldots,x_{n}$ in
ascending order. If the number of values is odd, median is the middle
value. If the number of values is even, median is the mean of middle two
values.

Arrange data in ascending then use the following formula

When *n* is odd, Median = Md
=$\left( \frac{n + 1}{2} \right)^{\text{th}}$value

When *n* is even, Median = Md
=${\text{Average\ of\ }\left( \frac{n}{2} \right)^{th}\text{and\ }\left( \frac{n}{2} + 1 \right)}^{\text{th}}$value

**Example 3.4** Find the median of each of the following sets of
numbers.

\(a\) 12, 15, 22, 17, 20, 26, 22, 26, 12

\(b\) 4, 7, 9, 10, 5, 1, 3, 4, 12, 10

**Solution 3.4**

\(a\) Arranging the data in an increasing order of magnitude, we
obtain 12, 12, 15, 17, 20, 22, 22, 26, 26. Here, N (= 9) is odd, and so,
median =$\left( \frac{9 + 1}{2} \right)^{\text{th}}$= 5^th^ ordered
observation = 20.

Note: If a number is repeated, we still count it the number of times it
appears when we calculate the median.

\(b\) Arranging the data in an increasing order of magnitude, we obtain
1, 3, 4, 4, 5, 7, 9, 10, 10, 12. Here, N(=10) is an even number and so
median = $\frac{1}{2}${5^th^ ordered observation + 6^th^ ordered
observation} = $\frac{1}{2}\left( 5 + 7 \right) = 6$.

Note: You can see in each case, the median divides the distribution into
two equal parts, with 50% of the observations greater than it and the
other 50% less than it.

### Median of ungrouped frequency distribution

The median is the middle number is an ordered set of data. In a
frequency table, the observations are already arranged in an ascending
order. We can obtain the median by looking for the value in the middle
position.

#### Median of a frequency table when the number of observations is odd

When the number of observations (n) is odd, then the median is the value
at the¬†$\left( \frac{n + 1}{2} \right)^{\text{th}}$ positional value.
For that we use less than cumulative frequency.

**Example 3.5**: The following is a frequency table of the score obtained in a mathematics quiz. Find the median score.  

Table: (\#tab:score) Score obtained in a mathematics quiz.  

  **Score**       0   1   2   3   4
  --------------- --- --- --- --- ---
  **Frequency**   3   4   7   6   3

**Solution 3.5:**

Total frequency = 3 + 4 + 7 + 6 + 3 = 23 (odd number). Since the number
of scores is odd, the median is at
$\left( \frac{23 + 1}{2} \right)^{\text{th}} =$ 12^th^¬†position. To find
out the 12^th^¬†position, we use less than cumulative frequencies as
shown:

  **Score**                            0   1   **2**    3    4
  ------------------------------------ --- --- -------- ---- ----
  **Frequency**                        3   4   **7**    6    3
  **less than cumulative frequency**   3   7   **14**   20   23

The 12^th^¬†position is after the 7^th^¬†position but before the
14^th^¬†position. So, the median is 2.

#### Median of a frequency table when the number of observations is even

When the number of observations is even, then the median is the average
of
${\left( \frac{n}{2} \right)^{th}\text{and\ }\left( \frac{n}{2} + 1 \right)}^{\text{th}}$
position values.

**Example 3.6**: The table is a frequency table of the marks obtained in a competition. Find the median score.  

Table: (\#tab:median) Distribution of marks obtained in a competition.  

  **Mark**        0    1   2   3    4
  --------------- ---- --- --- ---- ----
  **Frequency**   11   9   5   10   15

**Solution 3.6**:

Total frequency = 11 + 9 + 5 + 10 + 15 = 50 (even number). Since the
number of scores is even, the median is at the average of the¬†values in
${\left( \frac{n}{2} \right)^{th} = 25\ and\ \left( \frac{n}{2} + 1 \right)}^{\text{th}} = 26$
positions. To find out the 25^th^¬†position and 26^th^¬†position, we add up the frequencies as shown:

  **Mark**                             0    1    2    3    4
  ------------------------------------ ---- ---- ---- ---- ----
  **Frequency**                        11   9    5    10   15
  **less than cumulative frequency**   11   20   25   35   50

The mark at the 25^th^¬†position is 2 and the mark at the 26^th^¬†position
is 3. The median is the average of the scores at 25^th^¬†and
26^th^¬†positions =¬†$\frac{2 + 3}{2} = 2.5$

### Median of grouped frequency distribution  

The exact value of the median of a grouped data cannot be obtained
because the actual values of a grouped data are not known. For a grouped
frequency distribution, the median is in the class interval which
contains the $\left( \frac{N}{2} \right)^{\text{th}}$ordered
observation, where $N$ is the total number of observations. This class
interval is called the **median class**. The median of a grouped
frequency distribution can be estimated by either of the following two
methods:

#### Linear interpolation method for estimating the median

The median of a grouped frequency distribution can be estimated by
linear interpolation. We assume that the observations are evenly spread
through the median class. The median can then be computed by using the
following formula:

$$median = L + \left( \frac{\frac{1}{2}N - F}{f_{m}} \right)C$$

where $N$ = total number of observations, $L$ = lower limit of the
median class, $F$ = sum of all frequencies below *L*(cumulative
frequency), $f_{m}$ = frequency of the median class, $C$ = class width
of the median class.

#### Estimation of the median from a cumulative frequency curve

The median of a grouped frequency distribution can be estimated from a
cumulative frequency curve. A horizontal line is drawn from the point
$\frac{\text{N\ }}{2}$ on the vertical axis to meet the cumulative
frequency curve. From the point of intersection, a vertical line is
dropped to the horizontal axis. The value on the horizontal axis is
equal to the median.  
```{r mediancf, echo=FALSE,fig.cap='median from a cumulative frequency curve ',out.width="40%", fig.align='center'}
knitr::include_graphics(rep("images/mediancf.png"))
```

**Example 3.7** Table below gives the distribution of the heights of 60
students in a Senior High school. Find the median height of the students  

Table: (\#tab:medianheight)Distribution of heights of 60
students

  Height(cm)           145-150   150-155   155-160   160-165   165-170   170-175
  -------------------- --------- --------- --------- --------- --------- ---------
  Number of students   3         9         16        18        10        4

**Solution 3.7**

**(i) Linear interpolation method for estimating the median**

$N$ = 60

Median class= class interval which contains the
$\left( \frac{N}{2} \right)^{\text{th}}$ordered observation; here
$\left( \frac{60}{2} \right)^{\text{th}} =$ 30^th^ observation. Before
the class 160-165 there are 3+9+16=28 observations so 30^th^ observation
will be in the class 160-165, therefore it is the median class.

$L$ = lower limit of the median class =160

$F$ = sum of all frequencies below 160(cumulative frequency) = 16+9+3=
28

$f_{m}$ = frequency of the median class=18

$C$ = class width of the median class=5

$median = 160 + \left( \frac{\frac{1}{2}60 - 28}{18} \right)5$ = 160.56

**(ii) Estimation of the median from a cumulative frequency curve**

```{r mediancf1, echo=FALSE,fig.cap='Median from a cumulative frequency curve Example 3.7',out.width="40%", fig.align='center'}
knitr::include_graphics(rep("images/cf.png"))
```

## Merits and Demerits of Median

[**Merits**]{.ul}

1.  Median is not influenced by extreme values because it is a
    positional average.

2.  Median can be calculated in case of distribution with open-end
    intervals

3.  Median can be located even if the data are incomplete.

[**Demerits**]{.ul}

1.  A slight change in the series may bring drastic change in median
    value.

2.  In case of even number of items or continuous series, median is an
    estimated value other than any value in the series.

3.  It is not suitable for further mathematical treatment except its use
    in calculating mean deviation.

4.  It does not take into account all the observations

## The mode

The mode of a set of data is the value which occurs with the greatest
frequency. The mode is therefore the most common value. The mode is an
important measure in case of qualitative data. The mode can be used to
describe both quantitative and qualitative data.

### Mode of ungrouped or raw data

For ungrouped data or a series of individual observations, mode is often
found by mere inspection.

**Example 3.8**

\(a\) The mode of 1, 2, 2, 2, 3 is 2.

\(b\) The modes of 2, 3, 4, 4, 5, 5 are 4 and 5.

\(c\) The mode does not exist when every observation has the same frequency. For example, the following sets of data have no modes: (i) 3,
6, 8, 9; (ii) 4, 4, 4, 7, 7, 7, 9, 9, 9.

Note: It can be seen that the mode of a distribution may not exist, and
even if it exists, it may not be unique. Distributions with a single
mode are referred to as *unimodal*. Distributions with two modes are
referred to as *bimodal*. Distributions may have several modes, in which
case they are referred to as *multimodal*.

**Example 3.9** 20 patients selected at random had their blood groups
determined. The results are given in the table below  

Table: (\#tab:Blood) Blood groups of 20 patients  

  Blood group       A   AB   B   O
  ----------------- --- ---- --- ---
  No. of patients   2   4    6   8

The blood group with the highest frequency is O. The mode of the data is
therefore blood group O. We can say that most of the patients selected
have blood group O. Notice that the mean and the median cannot be
applied to the data. This is because the variable "blood group" cannot
take numerical values. However, it can be seen that the mode can be used
to describe both quantitative and qualitative data.

### Mode of Grouped frequency distribution

$$mode = L + \left( \frac{f_{s}}{f_{p} + f_{s}} \right)C$$

Locate the highest frequency the class corresponding to that frequency
is called the **modal class**.

Where $L$ = lower limit of the model class; $f_{p}$= the frequency of
the class preceding the model class; $f_{s}$= the frequency of the class
succeeding the model class and $C$ = class interval

**Example 3.10** For the frequency distribution of weights of sorghum
ear-heads given in table below. Calculate the mode.  

Table: (\#tab:earhead)requency distribution of weights of sorghum ear heads  

  Weights of ear heads (g)   No of ear heads (*f*)
  -------------------------- -----------------------
  60-80                      22
  80-100                     38
  100-120                    45
  120-140                    35
  140-160                    20

Modal class is **100-120**

$mode = 100 + \left( \frac{35}{38 + 35} \right)20 =$ 109.589

### **Mode using Histogram**

Consider the figure below. The modal class is the class interval which
corresponds to rectangle $\text{ABCD}$. An estimate of the mode of the
distribution is the abscissa of the point of intersection of the line
segments $\overline{\text{AE}}$and $\overline{\text{BF}}$in
```{r cf1, echo=FALSE,fig.cap='Median from a cumulative frequency curve for Example 3.10',out.width="40%", fig.align='center'}
knitr::include_graphics(rep("images/l2m1.jpeg"))
```

## Merits and Demerits of Mode

[*Merits*]{.ul}

1.  It is readily comprehensible and easy to compute. In some case it
    can be computed merely by inspection.

2.  It is not affected by extreme values. It can be obtained even if the
    extreme values are not known.

3.  Mode can be determined in distributions with open classes.

4.  Mode can be located on the graph also.

5.  Mode can be used to describe both quantitative and qualitative data.

[*Demerits*]{.ul}

1.  The mode is not unique. That is, there can be more than one mode for
    a given set of data.

2.  The mode of a set of data may not exist

3.  It is not based upon all the observation.


&nbsp;  
&nbsp;  
&nbsp;  


::: {#hello .greeting .message style="color: #c9c6c5;"}  
<center>  

**If the statistics are boring, you‚Äôve got the wrong numbers**!  

</center>
:::

<!--chapter:end:03-lecture03.rmd-->



# Measures of central tendency -II

## Geometric mean

The geometric mean is a type of average, usually used for growth rates,
like population growth or interest rates. While the arithmetic mean adds
items, the geometric mean multiplies items.

The geometric mean of a series containing *n* observations is the
*n*^th^ root of the product of the values. If
$x_{1},\ x_{2},\ldots,\ x_{n}\ $are observations then

$$\mathbf{\text{Geometric mean}}\mathbf{,\ }\mathbf{GM =}\sqrt[\mathbf{n}]{\mathbf{x}_{\mathbf{1}}\mathbf{x}_{\mathbf{2}}\mathbf{\ldots}\mathbf{x}_{\mathbf{n}}}$$

$$\mathbf{=}\left( \mathbf{x}_{\mathbf{1}}\mathbf{x}_{\mathbf{2}}\mathbf{\ldots}\mathbf{x}_{\mathbf{n}} \right)^{\frac{\mathbf{1}}{\mathbf{n}}}$$

$$\mathbf{\log}\mathbf{\text{GM}}\mathbf{=}\frac{\mathbf{1}}{\mathbf{n}}\mathbf{\log}\left( \mathbf{x}_{\mathbf{1}}\mathbf{x}_{\mathbf{2}}\mathbf{\ldots}\mathbf{x}_{\mathbf{n}} \right)$$

$$\mathbf{=}\frac{\mathbf{1}}{\mathbf{n}}\left( \mathbf{\log}\mathbf{x}_{\mathbf{1}}\mathbf{+}\mathbf{\log}\mathbf{x}_{\mathbf{2}}\mathbf{\ldots +}\mathbf{\log}\mathbf{x}_{\mathbf{n}} \right)$$

$$\mathbf{=}\frac{\sum_{\mathbf{i = 1}}^{\mathbf{n}}{\mathbf{\log}\mathbf{x}_{\mathbf{i}}}}{\mathbf{n}}$$

$$\mathbf{\ GM = Antilog}\left( \frac{\sum_{\mathbf{i = 1}}^{\mathbf{n}}{\mathbf{\log}\mathbf{x}_{\mathbf{i}}}}{\mathbf{n}} \right)$$

### Geometric mean for grouped frequency table data
$$\mathbf{GM = \ Antilog}\left( \frac{\sum_{\mathbf{i = 1}}^{\mathbf{k}}{{\mathbf{f}_{\mathbf{i}}\mathbf{\log}}\mathbf{x}_{\mathbf{i}}}}{\mathbf{n}} \right)$$

where $x_{i}$ is the mid-value, $f_{i}$ is the frequency , *k* is the
number of classes

**Example 4.1**: If the weight of sorghum ear heads are 45, 60, 48,100,
65 gms. Find the Geometric mean?

  Weight of ear head (x)   log(x)
  ------------------------ -----------
  45                       1.653
  60                       1.778
  48                       1.681
  100                      2.000
  65                       1.813
  Total                    **8.926**

**Solution 4.1**:

Here *n* =5

Geometric mean=  
$$\text{Antilog}\left( \frac{\sum_{i = 1}^{n}{\log x_{i}}}{n} \right) =$$  
$$Antilog\left( \frac{8.926}{5} \right) =$$  
$$ Antilog(1.785) = 60.95$$
(note: here $\text{Antilog}\left( x \right) = 10^{x}$ *i*.*e*.
$$\text{Antilog}\left( 1.785 \right) = \ 10^{1.785} = 60.95$$

**Example 4.2**: Geometric mean of a Frequency Distribution

  Weight of ear head (*x*)   Frequency(*f*)   log(*x*)   *f*\[log(*x*)\]
  -------------------------- ---------------- ---------- -----------------
  45                         5                1.653      8.266
  60                         4                1.778      7.113
  48                         6                1.681      10.087
  100                        8                2.000      16.000
  65                         9                1.813      16.316
  Total                      **32**                      **57.782**
  
**Solution 4.2**:
Here *n* =32

$$GM = \ Antilog\left( \frac{\sum_{i = 1}^{k}{{f_{i}\log}x_{i}}}{n} \right)$$

$${\sum_{i = 1}^{k}{{f_{i}\log}x_{i}} = 57.782
}$$  
$${\text{GM} = \ Antilog\left( \frac{57.782}{32} \right)  }$$  
$${= Antilog\left( 1.8056 \right)= 10^{1.8056} = 63.92}$$
**Example 4.3**: Geometric mean of a Grouped Frequency Distribution

  Class     Mid value (*x*)   Frequency(*f*)   log(*x*)   *f*\[log(*x*)\]
  --------- ----------------- ---------------- ---------- -----------------
  60-80     70                5                1.845      9.225
  80-100    90                4                1.954      7.817
  100-120   110               6                2.041      12.248
  120-140   130               8                2.114      16.912
  140-160   150               9                2.176      19.585
            **Total**         **32**                      **65.787**

   
**Solution 4.4**:  
Here *n* =32

$$GM = \ Antilog\left( \frac{\sum_{i = 1}^{k}{{f_{i}\log}x_{i}}}{n} \right)$$

$${\sum_{i = 1}^{k}{{f_{i}\log}x_{i}} = 65.787}$$
$${\text{GM} = \ Antilog\left( \frac{65.787}{32} \right)}$$
$${= Antilog\left( 2.0558 \right) = 10^{2.0558} = 113.72}$$

## Merits and Demerits of Geometric mean

[**Merits**]{.ui}

-   It is rigidly defined.

-   It is based on all the observations of the series.

-   It is suitable for measuring the relative changes.

-   It gives more weights to the small values and less weight to the
    large values.

-   It is used in averaging the ratios, percentages and in determining
    the rate gradual increase and decrease.

-   It is capable of further algebraic treatment.

[**Demerits**]{.ui}

-   It is not easy to understand.

-   It is difficult to calculate.

-   It cannot be calculated, if the number of negative values is odd.

-   It cannot be calculated, if any value of a series is zero.

-   At times it gives a value which may not be found in the series or
    impractical.

## Harmonic mean

Harmonic means are often used in averaging things like rates (e.g. the
average travel speed given duration of several trips). Harmonic mean
(HM) of a set of observations is defined as the reciprocal of the
arithmetic average of the reciprocal of the given value.

If $x_{1},\ x_{2},\ldots,\ x_{n}\ $are *n* observations then

$$\mathbf{\text{H.M}} = \frac{n}{\sum_{i = 1}^{n}\frac{1}{x_{i}}}$$

[In case of Frequency distribution]{.ul}

$$\mathbf{\text{H.M}} = \frac{n}{\sum_{i = 1}^{k}{f_{i}\frac{1}{x_{i}}}}$$

where $x_{i}$ is the mid-value, $f_{i}$ is the frequency , *k* is the
number of classes

### Steps in calculating Harmonic Mean (H.M)

1.  Calculate the reciprocal (1/value) for every value.

2.  Find the average of those reciprocals (just add them and divide by
    how many there are)

3.  Then do the reciprocal of that average (=1/average)

**Example 4.4**: From the given data 5, 10, 17, 24, 30 calculate H.M  

**Solution 4.4**:  

Here *n* = 5

  x                1/x
  ------ -----------------------
  5                0.2
  10               0.1
  17               0.058824
  24               0.041667
  30               0.033333
  Total            **0.433824**

$$\mathbf{\text{H.M}} = \frac{n}{\sum_{i = 1}^{n}\frac{1}{x_{i}}} = \frac{5}{0.433824} = 11.525$$

**Example 4.5**: Number of tomatoes per plant are given below. Calculate
the harmonic mean.

  No. of Tomato per plants   20   21   22   23   24   25
  -------------------------- ---- ---- ---- ---- ---- ----
  No. of Plants              4    2    7    1    3    1
  
**Solution 4.5**:  

  x                    f                      1/x                                f.1/x
  ---------------- ---------------- ----------------------------------- ------------------------------------------------------------
  20               4                0.05                                0.2
  21               2                0.047619                            0.095238
  22               7                0.045455                            0.318182
  23               1                0.043478                            0.043478
  24               3                0.041667                            0.125
  25               1                0.04                                0.04
                   **18**                                               **0.821898**

Here *n* =18

$$\mathbf{\text{H.M}} = \frac{n}{\sum_{i = 1}^{n}{f_{i}\frac{1}{x_{i}}}} = \frac{18}{0.821898} = 21.90$$

## Merits and Demerits of Harmonic mean

[**Merits**]{.ul}

-   It is rigidly defined.

-   It is defined on all observations.

-   It is amenable to further algebraic treatment.

-   It is the most suitable average when it is desired to give greater
    weight to smaller and less weight to the larger ones.

[**Demerits**]{.ul}

-   It is not easily understood.

-   It is difficult to compute.

-   It is only a summary figure and may not be the actual item in the
    series

-   It gives greater importance to small items and is therefore, useful
    only when small items have to be given greater weightage.

-   It is rarely used in grouped data.

## Relation between AM, GM and HM

If AM stands for Arithmetic Mean, GM stands for Geometric Mean and HM
stands for Harmonic Mean; then

$$\mathbf{\text{AM}}\mathbf{\times}\mathbf{\text{HM}}\mathbf{=}\mathbf{\text{GM}}^{\mathbf{2}}$$

also

$$\mathbf{AM \geq GM \geq HM}$$

## When to use AM, GM and HM?

A practical answer is that it depends on what your numbers are
measuring.

If you are measuring units that add up linearly in a sequence; such as
lengths, distances, weights, then an arithmetic mean will give you a
meaningful average. For example, the arithmetic mean of the height or
weight of students in a class represents the average height or weight of
students in the class.

Harmonic mean will give you a meaningful average, if you are measuring
units that add up as reciprocals in a sequence; such as speed or
distance travelled per unit time, capacitance in series, resistance in
parallel. For example, the harmonic mean of capacitors in series
represents the capacitance that a single capacitor would have if only
one capacitor was used instead of the set of capacitors in series.

If you're measuring units that multiply in a sequence; such as growth
rates or percentages, then a geometric mean will give you a meaningful
average. For example, the geometric mean of a sequence of different
annual interest rates over 10 years represents an interest rate that, if
applied constantly for ten years, would produce the same amount growth
in principal as the sequence of different annual interest rates over ten
years did.

## Positional Averages

Positional average of a series of values refers to the averages which
are taken out from the series itself which represents the whole series
or may have some positional properties.

In median, the middle most value of the series is taken as the
representative value. Therefore, median is a positional average. Mode is
also a positional average as modal values are the most frequently
occurring values that are directly taken from the series itself. Other
positional averages include **Percentiles**, **Quartiles** and
**Deciles**

Note that Arithmetic mean, Harmonic mean and Geometric mean are termed
as mathematical averages

## Quartiles {#quartile} 

The median divides a set of data into two equal parts. We can also
divide a set of data into more than two parts. When an ordered set of
data is divided into four equal parts, the division points are called
**quartiles**.

The **first or lower quartile (**$\mathbf{Q}_{\mathbf{1}}$**)** is a
value that has one fourth, or 25% of the observations below its value.

The **second quartile (**$\mathbf{Q}_{\mathbf{2}}$**)**, has one-half,
or 50% of the observations below its value. The second quartile is equal
to the **median**.

The **third or upper quartile**, **(**$\mathbf{Q}_{\mathbf{3}}$**)**, is
a value that has three-fourths, or 75% of the observations below it.

$\mathbf{Q}_{\mathbf{1}}\mathbf{=}\left( \frac{\mathbf{n + 1}}{\mathbf{4}} \right)^{\mathbf{\text{th}}}$**item**

$\mathbf{Q}_{\mathbf{3}}\mathbf{=}\left( \frac{\mathbf{3(n + 1)}}{\mathbf{4}} \right)^{\mathbf{\text{th}}}$**item**

Calculations of quartiles are explained using the example below. See in
the example the procedure followed when a fraction appear in the
calculation.

**Example 4.6**: Compute quartiles for the data 25, 18, 30, 8, 15, 5,
10, 35, 40, 45

**Solution 4.6**:

First arrange the data in ascending order

**5, 8, 10, 15, 18, 25, 30, 35, 40, 45**

here *n* = 10

$\mathbf{Q}_{\mathbf{1}}\mathbf{=}\left( \frac{\mathbf{n + 1}}{\mathbf{4}} \right)^{\mathbf{\text{th}}}$**item**

*i*.*e*. $Q_{1} = \left( \frac{10 + 1}{4} \right)^{th}$ = 2.75^th^ item;
when such a fraction appears we use the following procedure

$Q_{1} = \ $`<!-- -->`{=html}2.75^th^ item = 2^nd^ item + 0.75(3^rd^
item -- 2^nd^ item)

So from the given data $Q_{1}$= 8+0.75(10-- 8) = **9.5**

$$\mathbf{Q}_{\mathbf{2}}\mathbf{= median}$$

here $Q_{2} = \ $(18+25)/2 = **21.5**

$\mathbf{Q}_{\mathbf{3}}\mathbf{=}\left( \frac{\mathbf{3(n + 1)}}{\mathbf{4}} \right)^{\mathbf{\text{th}}}$**item**

*i*.*e*. $Q_{3} = \left( 3 \times \frac{(10 + 1)}{4} \right)^{th}$ =
8.25^th^ item = 8^th^ item + 0.25(9^th^ item --8^th^ item) =
35+0.25(40-35) =**36.25**

### Quartiles of a discrete frequency data

1.  Find cumulative frequencies.

2.  Find $\left( \frac{\mathbf{n + 1}}{\mathbf{4}} \right)$

3.  See in the cumulative frequencies, the value just greater than
    $\left( \frac{\mathbf{n + 1}}{\mathbf{4}} \right)$ , then the
    corresponding value of $x$ is $Q_{1}$

4.  Find $\left( \frac{\mathbf{3(n + 1)}}{\mathbf{4}} \right)$

5.  See in the cumulative frequencies, the value just greater than
    $\left( \frac{\mathbf{3(n + 1)}}{\mathbf{4}} \right)$ ,then the
    corresponding value of $x$ is $Q_{3}$

**Example 4.7**: Compute quartiles for the data given bellow

  $$\mathbf{x}$$   5   8   12   15   19   24   30
  ---------------- --- --- ---- ---- ---- ---- ----
  $$\mathbf{f}$$   4   3   2    4    5    2    4
  
**Solution 4.7**:  

  x       f     cf
  ----- ----- -----
  5       4     4
  8       3     7
  12      2     9
  15      4     13
  19      5     18
  24      2     20
  30      4     24
  
Here *n* =24

$\left( \frac{\mathbf{n + 1}}{\mathbf{4}} \right)$ **=**
$\left( \frac{\mathbf{n + 1}}{\mathbf{4}} \right)\mathbf{\ }$**=**
$\left( \frac{\mathbf{25}}{\mathbf{4}} \right)$**=** 6.25

The cumulative frequency value just greater than 6.25 is 7, the\
$\mathbf{x}$ value corresponding to cumulative frequency 7 is 8. So
$\mathbf{Q}_{\mathbf{1}}$**= 8.**

$\left( \frac{\mathbf{3(n + 1)}}{\mathbf{4}} \right)$ **=**
$\left( \frac{\mathbf{3}\mathbf{\times}\mathbf{25}}{\mathbf{4}} \right)$**=**
18.75

The cumulative frequency value just greater than 18.75 is 20, the\
$\mathbf{x}$ value corresponding to cumulative frequency 20 is 24. So
$\mathbf{Q}_{\mathbf{3}}$**= 24.**

### Quartiles of a continuous frequency data

1.  Find cumulative frequencies

2.  Find $\left( \frac{\mathbf{n}}{\mathbf{4}} \right)$

3.  See in the cumulative frequencies, the value just greater
    than$\ \left( \frac{\mathbf{n}}{\mathbf{4}} \right)$, and then the
    corresponding class interval is called **first quartile class**.

4.  Find $3\left( \frac{\mathbf{n}}{\mathbf{4}} \right)$

5.  See in the cumulative frequencies the value just greater than
    $3\left( \frac{\mathbf{n}}{\mathbf{4}} \right)\mathbf{\ }$then the
    corresponding class interval is called **3^rd^ quartile class**.
    Then apply the respective formulae

$$\mathbf{Q}_{\mathbf{1}}\mathbf{=}\mathbf{l}_{\mathbf{1}}\mathbf{+}\frac{\frac{\mathbf{n}}{\mathbf{4}}\mathbf{-}\mathbf{m}_{\mathbf{1}}}{\mathbf{f}_{\mathbf{1}}}\mathbf{\times}\mathbf{c}_{\mathbf{1}}$$

$$\mathbf{Q}_{\mathbf{3}}\mathbf{=}\mathbf{l}_{\mathbf{3}}\mathbf{+}\frac{\mathbf{3}\left( \frac{\mathbf{n}}{\mathbf{4}} \right)\mathbf{-}\mathbf{m}_{\mathbf{3}}}{\mathbf{f}_{\mathbf{3}}}\mathbf{\times}\mathbf{c}_{\mathbf{3}}$$

Where $l_{1}$ = lower limit of the first quartile class

$f_{1}$ = frequency of the first quartile class

$c_{1}$ = width of the first quartile class

$m_{1}$ = cumulative frequency preceding the first quartile class

$l_{3}$= 1ower limit of the 3^rd^ quartile class

$f_{3}$= frequency of the 3^rd^ quartile class

$c_{3}$= width of the 3^rd^ quartile class

$m_{3}$ = cumulative frequency preceding the 3^rd^ quartile class

**Example 4.8**: Find the quartiles for the grouped frequency data given

  **Class**   **frequency**   **cumulative frequency**
  ----------- --------------- --------------------------
  0-10        11              11
  10-20       18              29
  20-30       25              54
  30-40       28              82
  40-50       30              112
  50-60       33              145
  60-70       22              167
  70-80       15              182
  80-90       12              194
  90-100      10              204

  
**Solution 4.8**:  

$\left( \frac{n}{4} \right)$ = $\frac{204}{4}$ = 51

The cumulative frequency value just greater than 51 is 54 so the class
20-30 is the 1^st^ quartile class

$$\mathbf{Q}_{\mathbf{1}}\mathbf{=}\mathbf{l}_{\mathbf{1}}\mathbf{+}\frac{\frac{\mathbf{n}}{\mathbf{4}}\mathbf{-}\mathbf{m}_{\mathbf{1}}}{\mathbf{f}_{\mathbf{1}}}\mathbf{\times}\mathbf{c}_{\mathbf{1}}$$

$$\mathbf{= 20 +}\frac{\mathbf{51 - 29}}{\mathbf{25}}\mathbf{\times 10\  = 28.8}$$

$3\left( \frac{n}{4} \right)$ = $3 \times \frac{204}{4}$ = 153

The cumulative frequency value just greater than 153 is 167 so the class
60-70 is the 3^rd^ quartile class

$$\mathbf{Q}_{\mathbf{3}}\mathbf{=}\mathbf{l}_{\mathbf{3}}\mathbf{+}\frac{\mathbf{3}\left( \frac{\mathbf{n}}{\mathbf{4}} \right)\mathbf{-}\mathbf{m}_{\mathbf{3}}}{\mathbf{f}_{\mathbf{3}}}\mathbf{\times}\mathbf{c}_{\mathbf{3}}$$

$$\mathbf{= 60 +}\frac{\mathbf{153 - 145}}{\mathbf{22}}\mathbf{\times 10 = 63.63}$$

## Percentiles

The percentile values divide an ordered set of data into 100 equal parts
each containing 1 percent of the observations. The *x*^th^ percentile,
denoted as $P_{x}$ is that value below which *x* percent of values in
the distribution fall. It may be noted that the median is the 50^th^
percentile, 25^th^ percentile is first quartile $Q_{1}$ and 75th
percentile is$\text{\ Q}_{3}\ $

For raw data, first arrange the *n* observations in increasing order.
Then the *x*^th^ percentile is given by

$\mathbf{P}_{\mathbf{x}}\mathbf{=}\left( \frac{\mathbf{x}\left( \mathbf{n + 1} \right)}{\mathbf{100}} \right)^{\mathbf{\text{th}}}$**item**

For a frequency distribution the *x*^th^ percentile is given by
following steps

1.  Find cumulative frequencies

2.  Find $\left( \frac{\text{x.n}}{100} \right)$

3.  See in the cumulative frequencies, the value just greater
    than$\left( \frac{\text{x.n}}{100} \right)$and then the
    corresponding class interval is called **Percentile class**.

4.  Use the following formula

$$\mathbf{P}_{\mathbf{x}}\mathbf{= l +}\frac{\left( \frac{\mathbf{x \times n}}{\mathbf{100}} \right)\mathbf{- cf}}{\mathbf{f}}\mathbf{\times c}$$

Where

$\mathbf{l}$ = lower limit of the percentile class

$\mathbf{\text{cf}}$ = cumulative frequency preceding the percentile
class

$\mathbf{f}$ = frequency of the percentile class

$\mathbf{c}$ = class interval

$\mathbf{n}$ = total number of observations

**Example 4.9**: Compute $\mathbf{P}_{\mathbf{25}}$**and**
$\mathbf{P}_{\mathbf{75}}$ for the data 25, 18, 30, 8, 15, 5, 10, 35,
40, 45

**Solution 4.9**:

First arrange the data in ascending order

**5, 8, 10, 15, 18, 25, 30, 35, 40, 45**

Here *n* =10

$\mathbf{P}_{\mathbf{25}}\mathbf{=}\left( \frac{\mathbf{25}\left( \mathbf{10 + 1} \right)}{\mathbf{100}} \right)^{\mathbf{\text{th}}}$**=
2.75^th^ item**

$P_{25} = \ $`<!-- -->`{=html}2.75^th^ item = 2^nd^ item + 0.75(3^rd^
item -- 2^nd^ item)

So from the given data $P_{25}$= 8+0.75(10-- 8) = **9.5**

$\mathbf{P}_{\mathbf{75}}\mathbf{=}\left( \frac{\mathbf{75}\left( \mathbf{10 + 1} \right)}{\mathbf{100}} \right)^{\mathbf{\text{th}}}$**=
8.25^th^ item**

*i*.*e*. $P_{75} = \left( 75 \times \frac{10 + 1}{100} \right)^{th}$ =
8.25^th^ item = 8^th^ item + 0.25(9^th^ item --8^th^ item) =
35+0.25(40-35) =36.25

**Note:** Data in this example is same as Example 3.6; it can be seen
that $P_{25} = Q_{1}$ & $P_{75} = Q_{3}$ always  

```{block2 assignment-2, type='rmdnote'}
Assignment 1: Find $\text{P}_{25}$, $P_{50}$& $P_{75}$for Example
**4.7** & **4.8**; verify that $P_{50} = Q_{2}$, $P_{25} = Q_{1}$ &
$P_{75} = Q_{3}$
```

## Deciles

Deciles are similar to quartiles. But while quartiles are three points
that divide an ordered set of data into four quarters, deciles are 9
points that divide an ordered set of data into ten equal parts. The
*x*^th^ decile is denoted as$\text{\ d}_{x}$. It may be noted that the
median is the 5^th^decile.

$\mathbf{d}_{\mathbf{x}}\mathbf{=}\left( \frac{\mathbf{x}\left( \mathbf{n + 1} \right)}{\mathbf{10}} \right)^{\mathbf{\text{th}}}$**item**

For a frequency distribution the *x*^th^ decile is given by following
steps

1.  Find cumulative frequencies

2.  Find $\left( \frac{\text{x.n}}{10} \right)$

3.  See in the cumulative frequencies, the value just greater
    than$\left( \frac{\text{x.n}}{10} \right)$and then the corresponding
    class interval is called **decile class**.

4.  Use the following formula

$$\mathbf{d}_{\mathbf{x}}\mathbf{= l +}\frac{\left( \frac{\mathbf{x \times n}}{\mathbf{10}} \right)\mathbf{- cf}}{\mathbf{f}}\mathbf{\times c}$$

Where

$\mathbf{l}$ = lower limit of the decile class

$\mathbf{\text{cf}}$ = cumulative frequency preceding the decile class

$\mathbf{f}$ = frequency of the decile class

$\mathbf{c}$ = class interval

$\mathbf{n}$ = total number of observations

```{block2 assignment-1, type='rmdnote'}
Assignment 2: Find $\text{D}_{5}$ for Example **4.6**, **4.7** &
**4.8**; verify that
$\text{D}_{5} = \text{Q}_{2} = \text{P}_{50} = median$
```  

::: {#hello .greeting .message style="color: #c9c6c5;"}  
<center>  

**The best thing about being a statistician is that you get to play in everybody else's backyard.
-- John Tukey**  

</center>
:::

<!--chapter:end:04-lecture04.Rmd-->

# Measures of Dispersion

We discussed in previous lectures, how a set of data can be summarized
by a single representative value which describes the central value of
the data. Consider the two sets of data A & B below  


| Data sets |    |   |   |   |   |   |
|-----------|----|---|---|---|---|---|
| **A**         | 1  | 2 | 3 | 3 | 4 | 5 |
| **B**         | -1 | 0 | 3 | 3 | 5 | 8 |  


You can see mean, median and mode for both the sets **A** & **B** is 3

See the dot diagrams of data sets A and B.

```{r d, echo=FALSE,fig.cap='Scatter diagram of data sets A & B',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image2_d.jpeg"))
```

It can be seen that, while values of data set **A** are grouped close to
their mean, while the values of data set **B** are more spread out. We
say that values of data set **B** are more dispersed (or scattered) than
those of data set **A**

This example shows that the mean, the mode and the median, are not
enough in describing a set of data. In addition to using these measures,
we need a numerical measure of dispersion (or variation) of a set of
data.

Statistical dispersion means the extent to which a numerical data is
likely to vary about an average value.

## Characteristics of a good measure of dispersion  

An ideal measure of dispersion is expected to possess the following
properties

1.  It should be rigidly defined

2.  It should be based on all the items.

3.  It should not be unduly affected by extreme items.

4.  It should lend itself for algebraic manipulation.

5.  It should be simple to understand and easy to calculate

The most important measures of dispersion are the **Range**, the
**Inter-quartile range**, **Mean Absolute Deviation (MAD)**and the **standard deviation**.

## The Range

This is the simplest possible measure of dispersion. The range of a set
of data is defined as the difference between the largest observation and
the smallest observation in the set of data.

Thus,

**Range = largest observation -- smallest observation.**

In symbols, Range = L -- S.

Where L = Largest value; S = Smallest value.

In individual observations and discrete series, L and S are easily
identified. In continuous series, the following two methods are
followed.

### Method 1

L = Upper boundary of the highest class

S = Lower boundary of the lowest class.

### Method 2

L = Mid-value of the highest class.

S = Mid-value of the lowest class.

**Example 5.1**: The marks obtained by 8 students in Mathematics and
Physics examinations are as follows:

Mathematics: 35, 60, 70, 40, 85, 96, 55, 65.

Physics: 50, 55, 70, 65, 89, 68, 72, 80.

Find the ranges of the two sets of data. Are the Physics marks more
dispersed than the Mathematics marks?

**Solution**

For Mathematics,

Highest mark = 96, lowest mark = 35, range =96 -- 35 = 61

For Physics,

Highest mark = 89, lowest mark = 50, range =89 -- 50 = 39.

The mathematics marks have a wider range than the Physics marks. The
Mathematics marks are therefore more dispersed than the Physics marks.

**Example 5.2**: Calculate range from the following distribution

  Size     60-63   63-66   66-69   69-72   72-75
  -------- ------- ------- ------- ------- -------
  Number   5       18      42      27      8

**Solution**

L = Upper boundary of the highest class = 75

S = Lower boundary of the lowest class = 60

Range = L -- S = 75 -- 60 = 15

### Merits and Demerits of Range  

**[Merits]{.ul}**

1.  It is simple to understand.

2.  It is easy to calculate.

3.  In certain types of problems like quality control, weather
    forecasts, share price analysis, etc.

**[Demerits]{.ul}**

1.  It is very much affected by the extreme items.

2.  It is based on only two extreme observations.

3.  It cannot be calculated from open-end class intervals.

4.  It is not suitable for mathematical treatment.

5.  It is a very rarely used measure.  

## The Inter-Quartile Range (IQR) or Midspread

The range has the advantage that it is quick and easy to calculate.
However, since it depends only on the maximum and the minimum values of
a set of data, it does not show how the whole data is distributed
between these two values. The range is therefore not a good measure of
dispersion if one or both of these two values differ greatly from other
values of the data. To overcome this problem, we sometimes use the
inter-quartile range. A robust measure of dispersion is the
inter-quartile range. The inter-quartile range of a set of data is the
difference between the upper and lower quartiles of the data. Thus,

**Inter-Quartile Range (IQR)** = *Q*~3~ -- *Q*~1~.

The inter-quartile range of a set of data is therefore not affected by
values of the data outside *Q*~1~ and *Q*~3~. The inter-quartile range
is sometimes used as a measure of dispersion.

**Example 5.3**: Consider the two sets of data below, find IQR

**A**: 3, 4, 5, 6, 8, 9, 10, 12, 15

**B**: 3, 8, 8, 9, 9, 9, 10, 10, 15

For data set A, *Q*~1~ = 5, *Q*~3~ = 10; so Inter-Quartile Range =10 --
5 = 5

For data set B, *Q*~1~ = 8, *Q*~3~ = 10; so Inter-Quartile Range =10 --
8 = 2

Since the inter-quartile range of data set A is greater than that of
data set B, these results confirm that data set A is more dispersed than
data set B. You can also see Range is same for both the sets.


## Mean Absolute Deviation (MAD)

The mean absolute deviation (MAD) is a measure of variability that
indicates the average distance between observations and their mean. MAD
uses the original units of the data, which simplifies interpretation.
Larger values signify that the data points spread out further from the
average. Conversely, lower values correspond to data points bunching
closer to it. The mean absolute deviation is also known as the mean
deviation and average absolute deviation.

Here is how to calculate the mean absolute deviation.

1.  Calculate the mean.

2.  Calculate the difference of each observation from mean and take
    absolute value *i*.*e*. ignore the sign. This difference is known as
    absolute deviation

3.  Add those deviations together.

4.  Divide the sum by the number of data points.

$$MAD = \frac{\sum_{i = 1}^{n}\left| x_{i} - \overline{x} \right|}{n}$$

**Example 5.4**: find the mean absolute deviation of the following 10, 15,
15, 17, 18, 21

  Sl.No.   $$x_{i}$$             $$x_{i} - \overline{x}$$   $$\left| x_{i} - \overline{x} \right|$$
  -------- --------------------- -------------------------- ------------------------------------------------------------
  1        10                    -6                         6
  2        15                    -1                         1
  3        15                    -1                         1
  4        17                    1                          1
  5        18                    2                          2
  6        21                    5                          5
           $\overline{x} =$ 16                              $\sum_{i = 1}^{n}\left| x_{i} - \overline{x} \right|$ = 16

Here n = 6 and $\sum_{i = 1}^{n}\left| x_{i} - \overline{x} \right|$ =
16 therefore MAD = $\frac{16}{6} = 2.67$  

### Merits and Demerits of MAD 

**[Merits]{.ul}**

1.  Simple And Easy

2.  Different items of observations can be easily compared with mean deviation  

3.  Mean deviation is better than quartile deviation and range because it is based on all the observations of the series.  

4. Mean deviation is less affected by the extreme values in the series while comparing to standard deviation.  

5. Mean deviation is rigidly defined. So, it has fixed value.  


**[Demerits]{.ul}**

1. It becomes difficult to compute mean deviation in case of fractions.  

2.  Mean deviation is not applicable for algebraic calculations.  

3.  It cannot be calculated from open-end class intervals.

4.  Mean deviation is not a good measure as it ignores negative signs of deviations.  

## The variance and standard deviation

The most important measures of variability are the sample variance and
the sample standard deviation. If *x*~1~, *x*~2~... *x*~n~ is a sample
of *n* observations, then the **sample variance** is denoted by *s*¬≤ and
is defined by the equation.

$${\mathbf{\text{sample variance}},\ \mathbf{s}}^{\mathbf{2}}\mathbf{=}\frac{\sum_{\mathbf{i = 1}}^{\mathbf{n}}\left( \mathbf{x}_{\mathbf{i}}\mathbf{-}\overline{\mathbf{x}} \right)^{\mathbf{2}}}{\mathbf{n - 1}}$$

The sample **standard deviation**, *s*, is the positive square root of
the sample variance.

$$\mathbf{variance =}\left( \mathbf{\text{standard deviation}} \right)^{\mathbf{2}}$$

$$\mathbf{standard\ deviation = \ }\sqrt{\mathbf{\text{variance}}}$$

**Note**: If *s*~A~, the standard deviation of data set A, is greater
than *s*~B~, the standard deviation of data set B, then data set A is
more dispersed than data set B. It should be noted that the standard
deviation of a set of data is a non-negative number.

**Example 5.4**: Consider the two sets of data A & B below; find standard
deviation?

  **A**   1    2   3   3   4   5
  ------- ---- --- --- --- --- ---
  **B**   -1   0   3   3   5   8  
  
  **Solution**:    
  

  **Set A**                                                                                                             
  ----------- ----------------------------- --------------------------------------------------------------------------- ----------------------------------------------------------------------------------------
              $$\mathbf{x}_{\mathbf{i}}$$   $$\left( \mathbf{x}_{\mathbf{i}}\mathbf{-}\overline{\mathbf{x}} \right)$$   $$\left( \mathbf{x}_{\mathbf{i}}\mathbf{-}\overline{\mathbf{x}} \right)^{\mathbf{2}}$$
              1                             -2                                                                          4
              2                             -1                                                                          1
              3                             0                                                                           0
              3                             0                                                                           0
              4                             1                                                                           1
              5                             2                                                                           4
  **Sum**     **18**                        **0**                                                                       **10**

Mean ($\overline{x}$) =$\ \frac{18}{6} = 3$

$${Sample\ variane,\ s}_{A}^{2} = \frac{\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}}{n - 1} = \frac{10}{5} = 2$$

$$\text{sample standard deviation,}\ s_{A} = \ \sqrt{s_{A}^{2}} = \ \sqrt{2} = 1.414$$

  **Set B**                                                                                                             
  ----------- ----------------------------- --------------------------------------------------------------------------- ----------------------------------------------------------------------------------------
              $$\mathbf{x}_{\mathbf{i}}$$   $$\left( \mathbf{x}_{\mathbf{i}}\mathbf{-}\overline{\mathbf{x}} \right)$$   $$\left( \mathbf{x}_{\mathbf{i}}\mathbf{-}\overline{\mathbf{x}} \right)^{\mathbf{2}}$$
              -1                            -4                                                                          16
              0                             -3                                                                          9
              3                             0                                                                           0
              3                             0                                                                           0
              5                             2                                                                           4
              8                             5                                                                           25
  **Sum**     **18**                        **0**                                                                       **54**

Mean ($\overline{x}$) =$\ \frac{18}{6} = 3$

$${Sample\ variane,\ s}_{B}^{2} = \frac{\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}}{n - 1} = \frac{54}{5} = 10.8$$

$$sample\ standard\ deviation,\ s_{B} = \ \sqrt{s_{B}^{2}} = \ \sqrt{10.8} = 3.29$$

It can be seen that $s_{B} > s_{A}\ $, confirming that data set B is
more dispersed than data set A (see the dot diagrams)

>**Note**: The unit of measurement of the sample variance is the square
of the unit of measurement of the data. Sample standard deviation has
same unit of measurement as of the data. Thus, if *x* is measured in
centimetres (cm), then the unit of measurement of the sample variance is
cm^2^ and that of sample standard deviation is cm. The standard
deviation has the desirable property of measuring variability in the
same unit as the data.

**An alternative formula for computing the variance**

The computation of *s*¬≤ requires calculations of $\overline{x}$, *n*
subtractions and *n* squaring and adding operations. If the original
observations or the deviations $\left( x_{i} - \overline{x} \right)$ are
not integers, the deviations $\left( x_{i} - \overline{x} \right)$ may
be difficult to work with, and several decimals may have to be carried
to ensure numerical accuracy. A more efficient computational formula for
*s*¬≤ is given by

$s^{2} = \frac{1}{n - 1}\left\{ \sum_{i = 1}^{n}{x_{i}^{2} - \frac{1}{n}}\left( \sum_{i = 1}^{n}x_{i} \right)^{2} \right\}$

**Example 5.5**: Consider the data set below; find standard deviation?

  --- --- --- --- --- --- ---- ---- ----
  3   4   5   6   8   9   10   12   15
  --- --- --- --- --- --- ---- ---- ----  
  
**Solution**:  

            $$\mathbf{x}_{\mathbf{i}}$$   $$\mathbf{x}_{\mathbf{i}}^{\mathbf{2}}$$
  --------- ----------------------------- ------------------------------------------
            3                             9
            4                             16
            5                             25
            6                             36
            8                             64
            9                             81
            10                            100
            12                            144
            15                            225
  **Sum**   **72**                        **700**

$s^{2} = \frac{1}{n - 1}\left\{ \sum_{i = 1}^{n}{x_{i}^{2} - \frac{1}{n}}\left( \sum_{i = 1}^{n}x_{i} \right)^{2} \right\}$
; here *n* = 9

$s^{2} = \frac{1}{8}\left\{ 700 - {\frac{1}{9}\left( 72 \right)}^{2} \right\}$
=15.5

$s = \ \sqrt{15.5} = 3.94$

### Variance and standard deviation for grouped data  

#### For discrete grouped data

$$s^{2} = \frac{1}{n - 1}\left\{ \sum_{i = 1}^{n}{{f_{i}x}_{i}^{2} - \frac{1}{n}}\left( \sum_{i = 1}^{n}{f_{i}x}_{i} \right)^{2} \right\}$$

where $f_{i}$ is the frequency of *i*^th^ observation

**Example 5.6**: The frequency distributions of seed yield of 50 sesamum
plants are given below. Find the standard deviation.

  Seed yield in gms (*x*)   **3**   **4**   **5**    **6**    **7**
  ------------------------- ------- ------- -------- -------- --------
  Frequency (*f*)           **4**   **6**   **15**   **15**   **10**

**Solution**:  


  ***x***     ***f***   ***fx***   ***fx^2^***
  ----------- --------- ---------- -------------
  3           4         12         36
  4           6         24         96
  5           15        75         375
  6           15        90         540
  7           10        70         490
  **Total**   **50**    **271**    **1537**

$$s^{2} = \frac{1}{n - 1}\left\{ \sum_{i = 1}^{n}{{f_{i}x}_{i}^{2} - \frac{1}{n}}\left( \sum_{i = 1}^{n}{f_{i}x}_{i} \right)^{2} \right\}$$

$${sample\ variance,\ s}^{2} = \frac{1}{50 - 1}\left\{ 1537 - \frac{271^{2}}{50} \right\} = 1.3914$$

$standard\ deviation,\ s = \sqrt{1.3914}$ = 1.179

#### For continuous grouped data

$$s^{2} = \frac{1}{n - 1}\left\{ \sum_{i = 1}^{n}{{f_{i}d}_{i}^{2} - \frac{1}{n}}\left( \sum_{i = 1}^{n}{f_{i}d}_{i} \right)^{2} \right\}$$

where $f_{i}$ is the frequency of *i*^th^ class, *c* is the class
interval, $d_{i} = \frac{x_{i} - A}{c}$, $x_{i}$ is the class mark, $A$
is the class mark with the highest frequency

**Example 5.7**: The frequency distributions of seed yield of 50 sesamum
plants are given below. Find the standard deviation

  Seed yield in gms (*x*)   2.5-3.5   3.5-4.5   4.5-5.5   5.5-6.5   6.5-7.5
  ------------------------- --------- --------- --------- --------- ---------
  Frequency (*f*)           4         6         15        15        10

**Solution**:   


Here *n* =50; *c* =1

  **Seed yield**   *f*      *x*      $$d_{i} = \frac{x_{i} - A}{c}$$   *fd*     *f d^2^*
  ---------------- -------- -------- --------------------------------- -------- ----------
  2.5-3.5          4        3        -2                                -8       16
  3.5-4.5          6        4        -1                                -6       6
  4.5-5.5          15       5        0                                 0        0
  6.5-7.5          15       6        1                                 15       15
  7.5-8.5          10       7        2                                 20       40
  **Total**        **50**   **25**   **0**                             **21**   **77**

*A* = 5

$$s^{2} = \frac{1}{n - 1}\left\{ \sum_{i = 1}^{n}{{f_{i}d}_{i}^{2} - \frac{1}{n}}\left( \sum_{i = 1}^{n}{f_{i}d}_{i} \right)^{2} \right\}$$

$${sample\ variance,\ s}^{2} = \frac{1}{49}\left( 77 - \frac{\left( 21 \right)^{2}}{50} \right) = \ 1.3914$$

$standard\ deviation,\ s = \sqrt{1.3914}$ = 1.179

### Merits and Demerits of Standard Deviation  

**[Merits]{.ul}**

1.  It is rigidly defined and its value is always definite and based on
    all the observations

2.  As it is based on arithmetic mean, it has all the merits of
    arithmetic mean.

3.  It is the most important and widely used measure of dispersion.

4.  It is possible for further algebraic treatment.

5.  It is less affected by the fluctuations of sampling and hence
    stable.

6.  It is the basis for measuring the coefficient of correlation and
    other measures.

**[Demerits]{.ul}**

1.  It is not easy to understand and it is difficult to calculate.

2.  It gives more weight to extreme values because the values are
    squared up.

3.  As it is an absolute measure of variability, it cannot be used for
    the purpose of comparison.

## Coefficient of Variation (relative measure of dispersion)

The Standard deviation is an absolute measure of dispersion. It is
expressed in terms of units in which the original figures are collected
and stated. The standard deviation of heights of plants cannot be
compared with the standard deviation of weights of the grains, as both
are expressed in different units, *i*.*e* heights in centimetre and
weights in kilograms.

Therefore the standard deviation must be converted into a relative
measure of dispersion for the purpose of comparison. The relative
measure is known as the **coefficient of variation**. The coefficient of
variation is obtained by dividing the standard deviation by the mean and
expressed in percentage.

$$\mathbf{\text{Coefficient of variation}}\left( \mathbf{C}\mathbf{.}\mathbf{V} \right)\mathbf{=}\frac{\mathbf{\text{standard deviation}}}{\mathbf{\text{mean}}}\mathbf{\times 100}$$

If we want to compare the variability of two or more series, we can use
C.V. The series or groups of data for which the C.V. is greater indicate
that the group is more variable, less stable, less uniform, less
consistent or less homogeneous. If the C.V. is less, it indicates that
the group is less variable or more stable or more uniform or more
consistent or more homogeneous.

**Example 5.8**: Consider the measurement on yield and plant height of a
paddy variety. The mean and standard deviation for yield are 50 kg and
10 kg respectively. The mean and standard deviation for plant height are
55 cm and 5 cm respectively. Compare the variability.

**Solution**:

Here the measurements for yield and plant height are in different units.
Hence the variability can be compared only by using coefficient of
variation.

For yield, CV=$\ \frac{10}{50} \times 100 =$ 20%

For plant height, CV=
$\frac{5}{55} \times 100 = \ $`<!-- -->`{=html}9.1%

The yield is subject to more variation than the plant height.

**\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\***

<!--chapter:end:05_lecture05.rmd-->

# Skewness and Kurtosis  

In the previous lectures we have learned numerical measures of central
tendency and dispersion, but what about measures of shape?

The histogram can give you a general idea on the shape of the
distribution of values in your data. But we need some numerical measures
to identify the shape of the distribution. The numerical measures which
deal with the shape of the distribution are Skewness and Kurtosis.

## Skewness

Skewness is a measure of symmetry, or more precisely, the lack of
symmetry. Then you may ask, what will a symmetric distribution looks
like. Histogram of a symmetric distribution is showed below:

```{r hs, echo=FALSE,fig.cap='Histogram of a symmetric distribution',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/Hist1.png"))
```

A distribution, or data set, is symmetric if it looks the same to the
left and right of the centre point. In our discussion we are including
only unimodal cases.

For a symmetric distribution skewness = 0; mean = median = mode

```{r hs1, echo=FALSE,fig.cap='symmetric distribution',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image3_5.jpeg"))
```
Example of a data set with skewness = 0 (symmetric distribution)

```{r sk0, echo=FALSE,fig.cap='Data set with skewness = 0',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image4_5.jpeg"))
```

### Left-skewed or negatively skewed

For negatively skewed data set or distribution, the left tail is longer;
the mass of the distribution is concentrated on the right of the figure.
The distribution is said to be left-skewed, left-tailed, or skewed to
the left, considering that there is a long tail in the left side. See
the figure below, you can also see Mean \< Median \< Mode.

```{r sk1, echo=FALSE,fig.cap='Left skewed or negatively skewed distribution',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image5_5.jpeg"))
```
Example of a data set with negative skewness

```{r sk3, echo=FALSE,fig.cap='Negatively skewed data set',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image6_5.jpeg"))
```

### Right-skewed or positively skewed

For positively skewed data set or distribution, the right tail is
longer; the mass of the distribution is concentrated on the left of the
figure. The distribution is said to be right-skewed, right-tailed, or
skewed to the right, considering that there is a long tail in the right
side. See the figure below, you can also see Mean \> Median \> Mode

```{r sk4, echo=FALSE,fig.cap='Right skewed or positively skewed distribution',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image7_5.jpeg"))
```

Example of a data set with positive skewness

```{r sk5, echo=FALSE,fig.cap='Data set with positive skewness (right skewed)',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image8_5.jpeg"))
```

## Measures of Skewness 

The direction and extent of skewness can be measured in various ways. We
shall discuss four measures.

### Karl Pearson's coefficient of Skewness (**$S_{k}$**)

You have noticed that the mean, median and mode are not equal in a
skewed distribution. The Karl Pearson\'s measure of skewness is based
upon the divergence of mean from mode in a skewed distribution.

$$S_{k} = \frac{mean - mode}{\text{standard deviation}}$$

The sign of $S_{k}$ gives the direction of skewness and its magnitude
gives the extent of skewness. If $S_{k}$ \> 0, the distribution is
positively skewed, and if $S_{k}$ \< 0 it is negatively skewed.

In the above formula since mode is used, there is a problem that if mode
is not defined for a distribution we cannot find $S_{k}$. But empirical
relation between mean, median and mode states that, for a moderately
symmetrical distribution$\ mean - mode \approx 3(mean - median)$. So the
above formula can be written as

$$S_{k} = \frac{3(mean - median)}{\text{standard deviation}}$$

**Example 6.1**: Compute the Karl Pearson\'s coefficient of skewness from
the following data:

  Height (*x*)   frequency (*f*)
  -------------- -----------------
  58             10
  59             18
  60             30
  61             42
  62             35
  63             28
  64             16
  65             8

Solution:

  Height ($x_{i}$)   frequency ($f_{i}$)   $$f_{i}x_{i}$$   $$f_{i}x_{i}^{2}$$
  ------------------ --------------------- ---------------- --------------------
  58                 10                    580              33640
  59                 18                    1062             62658
  60                 30                    1800             108000
  61                 42                    2562             156282
  62                 35                    2170             134540
  63                 28                    1764             111132
  64                 16                    1024             65536
  65                 8                     520              33800
  **Sum**            **187**               **11482**        **705588**

Mean,
$\overline{x} = \frac{\sum_{i = 1}^{n}{f_{i}x_{i}}}{\sum_{i = 1}^{n}f_{i}}$
= $\frac{11482}{187} = 61.40$

${sample\ variance,\ s}^{2} = \frac{1}{n - 1}\left\{ \sum_{i = 1}^{n}{{f_{i}x}_{i}^{2} - \frac{1}{n}}\left( \sum_{i = 1}^{n}{f_{i}x}_{i} \right)^{2} \right\}$=
$\frac{705588 - \frac{\left( 11482 \right)^{2}}{187}}{186} = 3.123$

$standard\ deviation,\ s = \sqrt{3.123} = 1.179$

Median: See in the cumulative frequencies, the value just greater
than$\ \left( \frac{n + 1}{2} \right)$ , then the corresponding value of
$x$ is $Q_{2}$, median

$\left( \frac{n + 1}{2} \right) = \frac{187 + 1}{2}\ $= $\frac{188}{2}$
= 94

  Height (*x*)   frequency (*f*)   cumulative frequency
  -------------- ----------------- ----------------------
  58             10                10
  59             18                28
  60             30                58
  61             42                100
  62             35                135
  63             28                163
  64             16                179
  65             8                 187

$$S_{k} = \frac{3(mean - median)}{\text{standard deviation}}$$

$$S_{k} = \frac{3(61.40 - 61)}{1.179} = \frac{1.2}{1.179} = 1.017$$

Hence, the Karl Pearson\'s coefficient of skewness $S_{k}$=$1.017$, Thus
the distribution is positively skewed.

### Bowley\'s measure of Skewness (*S*~Q~)

Karl Pearson\'s coefficient of skewness is most commonly used skewness
measure. However, in order to use it you must know the mean, mode (or
median) and standard deviation for your data. Sometimes you might not
have that information; instead you might have information about
quartiles. If that's the case, you can use Bowley's measure of Skewness
as an alternative to find out more about the asymmetry of your
distribution. It's very useful if you have extreme data values
(outliers) or if you have an open-ended distribution.

$${Bowley‚Äôs\ measure\ of\ Skewness,\ S}_{Q} = \frac{\left( Q_{3} - Q_{2} \right) - \left( Q_{2} - Q_{1} \right)}{\left( Q_{3} - Q_{2} \right) + \left( Q_{2} - Q_{1} \right)}$$

Where $Q_{1}$= 1^st^ quartile; $Q_{2}$ = median; $Q_{3}$= 3^rd^ quartile

Equation can be further modified into

$$S_{Q} = \frac{Q_{3} - 2Q_{2} + Q_{1}}{Q_{3} - Q_{1}}$$

-   $S_{Q}$= 0 means that the curve is symmetrical.

-   $S_{Q}$ \> 0 means the curve is positively skewed.

-   $S_{Q}$\< 0 means the curve is negatively skewed.

For **Example 6.1** given above, Bowley\'s measure of Skewness can be
calculated as follows

  Height (*x*)   frequency (*f*)   cumulative frequency
  -------------- ----------------- ----------------------
  58             10                10
  59             18                28
  60             30                58
  61             42                100
  62             35                135
  63             28                163
  64             16                179
  65             8                 187

Calculation of$\text{Q}_{1}$, $Q_{2}$, $Q_{3}$ is given in Section \@ref(quartile)

$${Q}_{1} = 60$$

$$Q_{2} = 61$$

$$Q_{3} = 63$$

$$S_{Q} = \frac{63 - (2 \times 61) + 60}{63 - 60} = \ \frac{1}{3} = 0.33$$

Since $S_{Q}$ \> 0 means the curve is positively skewed.

### Kelly\'s Measure of Skewness (*S*~p~)

Bowley\'s measure of skewness is based on the middle 50% of the
observations; it leaves 25% of the observations on each extreme of the
distribution. As an improvement over Bowley\'s measure, Kelly has
suggested a measure based on Percentiles, including *P*~10~ and *P*~90~
so that only 10% of the observations on each extreme are ignored.

$${Kelly's\ Measure\ of\ Skewness,\ S}_{p} = \frac{\left( P_{90} - P_{50} \right) - \left( P_{50} - P_{10} \right)}{\left( P_{90} - P_{50} \right) + \left( P_{50} - P_{10} \right)}$$

```{block2 assignment-3, type='rmdnote'}
Assignment 3:Try to find Kelly's Measure of Skewness
for the Example 6.1 given above
``` 


### Measure based on moments

Before going into measuring skewness using moments, one should know what
a moment is:

#### Moments

The ***r*^th^ moment about mean** of a distribution, denoted by
***Œº*~r~** is given by

$$\mu_{r} = \frac{\sum_{i = 1}^{N}{f_{i}\left( x_{i} - \overline{x} \right)^{r}}}{N}$$

Where $f_{i}$ is the frequency of *i*^th^ observation or class
mark$\ x_{i}$, $N = \sum_{}^{}f_{i}$, number of observations

Moment about mean is also called as **Central Moment**

If *r* = 0,
$\mu_{0} = \frac{\sum_{i = 1}^{N}{f_{i}\left( x_{i} - \overline{x} \right)^{0}}}{N}$
= 1

If *r* = 1,
$\mu_{1} = \frac{\sum_{i = 1}^{N}{f_{i}\left( x_{i} - \overline{x} \right)^{1}}}{N}$
= 0 (sum of deviation about mean is zero)

If *r* = 2,
$\mu_{2} = \frac{\sum_{i = 1}^{N}{f_{i}\left( x_{i} - \overline{x} \right)^{2}}}{N}$
= $\sigma^{2}$, Population variance

In short values of following moments about mean are

+------------------------+----------------+
| **Moments about mean** | **Value**      |
|                        |                |
| **(central moment)**   |                |
+========================+================+
| $$\mu_{0}$$            | 1              |
+------------------------+----------------+
| $$\mu_{1}$$            | 0              |
+------------------------+----------------+
| $$\mu_{2}$$            | $$\sigma^{2}$$ |
+------------------------+----------------+

For the **Example 6.1** given above, calculate third central moment, $\mu_{3}$

  Height ($x_{i}$)   frequency ($f_{i}$)   $$\left( x_{i} - \overline{x} \right)^{3}$$   $${f_{i}\left( x_{i} - \overline{x} \right)}^{3}$$
  ------------------ --------------------- --------------------------------------------- ----------------------------------------------------
  58                 10                    -39.304                                       -393.04
  59                 18                    -13.824                                       -248.832
  60                 30                    -2.744                                        -82.32
  61                 42                    -0.064                                        -2.688
  62                 35                    0.216                                         7.56
  63                 28                    4.096                                         114.688
  64                 16                    17.576                                        281.216
  65                 8                     46.656                                        373.248
  **Sum**            **187**               **¬†**                                         **49.832**

Mean = 61.40

$$\mu_{3} = \frac{\sum_{i = 1}^{N}{f_{i}\left( x_{i} - \overline{x} \right)^{3}}}{N} = \ \frac{49.832}{187} = 0.266$$

#### Moment Measure of Skewness $\mathbf{(}\beta_{1}\text{and}$$\gamma_{1}\mathbf{)}$

The moment measure of skewness is based on the property that, for a
symmetrical distribution, all odd ordered central moments are equal to
zero. We note that $\mu_{1}$ = 0, for every distribution, therefore, the
lowest order moment that can provide an absolute measure of skewness
is$\text{Œº}_{3}$. So measures of skewness are based
on$\text{Œº}_{3}$.

$$\beta_{1} = \frac{\mu_{3}^{2}}{\mu_{2}^{3}}$$

Pronounced as 'beta one'

$\beta_{1}$= 0 means that the curve is symmetrical. The greater the
value of $\beta_{1}$the more skewed the distribution. One serious
limitation of $\beta_{1}$is that it cannot tell the direction of
skewness, *i*.*e*., whether it is positive or negative. Since
$\text{Œº}_{2}$ is always positive and $\mu_{3}^{2}$ is positive,
$\beta_{1}$ will be positive always. This drawback is removed by
calculating$\text{Œ≥}_{1}$, called as Karl Pearson's$\text{ Œ≥}_{1}$,
pronounced as 'gamma one'.

$$\gamma_{1} = \sqrt{\beta_{1}} = \frac{\mu_{3}}{\mu_{2}^{3}}$$

If $\mu_{3}$ is positive $\gamma_{1}$ is positive, If $\mu_{3}$ is
negative $\gamma_{1}$ is negative

-   $\gamma_{1}$= 0 means that the curve is symmetrical.

-   $\gamma_{1}$ \> 0 means the curve is positively skewed.

-   $\gamma_{1}$\< 0 means the curve is negatively skewed.

For the **Example 6.1** given above, skewness can be examined as below

$\mu_{3}$= 0.226

$\mu_{2}$= 3.123

$\beta_{1} = \frac{\mu_{3}^{2}}{\mu_{2}^{3}}$ =
$\frac{\left( 0.226 \right)^{2}}{\left( 3.123 \right)^{3}} = \ \frac{0.051}{30.46} = 0.0016$

$\gamma_{1} = \sqrt{\beta_{1}} = \ \sqrt{0.0016} = + 0.04$

Since $\mu_{3}$ is positive $\gamma_{1}$is positive. Since
$\gamma_{1}$is slightly greater than 0, distribution is a slightly
skewed to right.

## Kurtosis

Kurtosis is another measure of the shape of a distribution. Whereas
skewness measures the lack of symmetry of the frequency curve of a
distribution, kurtosis is a measure of the relative peakedness of its
frequency curve. Various frequency curves can be divided into three
categories depending upon the shape of their peak.

```{r k1, echo=FALSE,fig.cap='Three categories of frequency curves depending upon the shape of their peak',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image10_5.jpeg"))
```

Kurtosis refers to degree of flatness or peakedness of the curve. It is
measured relative to the peakedness of normal curve. The normal curve is considered as *mesokurtic*. If a curve is
more peaked than normal curve, it is called *leptokurtic*. If a curve is
more flat-topped than normal curve, it is called *platykurtic*.

The condition of peakedness (leptokurtic) or flatness (platykurtic) is
called **kurtosis of excess**.

Measure of kurtosis is given by 'beta two' given by Karl Pearson

$\beta_{2} = \frac{\mu_{4}}{\mu_{2}^{2}}$

Where $\mu_{4}$ is the 4^th^ central moment, $\mu_{2}$ is the 2^nd^
central moment

-   $\beta_{2}$= 3 means that the curve is mesokurtic.

-   $\beta_{2}$ \> 3 means the curve is leptokurtic.

-   $\beta_{2}$\< 3 means the curve is platykurtic.

Another measure of kurtosis is gamma two, $\gamma_{2} = \beta_{2} - 3\ $

-   $\gamma_{2}$= 0 means that the curve is mesokurtic.

-   $\gamma_{2}$ \> 0 means the curve is leptokurtic.

-   $\gamma_{2}$\< 0 means the curve is platykurtic.

For the **Example 6.1** given above, kurtosis can be examined as follows

  Height ($x_{i}$)   frequency ($f_{i}$)   $$\left( x_{i} - \overline{x} \right)^{4}$$   $${f_{i}\left( x_{i} - \overline{x} \right)}^{4}$$
  ------------------ --------------------- --------------------------------------------- ----------------------------------------------------
  58                 10                    133.6336                                      1336.336
  59                 18                    33.1776                                       597.1968
  60                 30                    3.8416                                        115.248
  61                 42                    0.0256                                        1.0752
  62                 35                    0.1296                                        4.536
  63                 28                    6.5536                                        183.5008
  64                 16                    45.6976                                       731.1616
  65                 8                     167.9616                                      1343.693
  **Sum**            **187**                                                             **4312.747**

Mean,$\ \overline{x}\ $= 61.40

$\mu_{2}$ = 3.123 (calculation shown in previous example)

$\mu_{4} = \frac{\sum_{i = 1}^{N}{f_{i}\left( x_{i} - \overline{x} \right)^{4}}}{N} = \frac{4312.747}{187} = 23.062$

$\beta_{2} = \frac{\mu_{4}}{\mu_{2}^{2}} = \frac{23.062}{\left( 3.123 \right)^{2}} = 2.364$

$\beta_{2}$ is 2.364, which is close to 3, distribution can be considered
slightly platykurtic close to symmetric.

You can verify the frequency curve of **Example 6.1** below, it can be seen
that it is slightly right tailed (positively skewed)

```{r k2, echo=FALSE,fig.cap='frequency curve of Example 6.1',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image11_5.jpeg"))
```


<!--chapter:end:06_lecture06.rmd-->

# Measures of Association

## Scatter Diagram

Consider two variables *x* and *y*, we use scatter diagram to
investigate whether there is any relation between the two variables. If
the variables *x* and *y* are plotted along the X-axis and Y-axis
respectively in the X-Y plane of a graph sheet the resultant diagram of
dots is known as **scatter diagram**. From the scatter diagram we can
say whether there is any association between X and Y.

**Example 7.1**: Consider the data on Sepal length (*x*) and Sepal width (*y*) of *Iris* *setosa.*

  Sl. No.¬†   Sepal Length   Sepal Width
  ---------- -------------- -------------
  1          5.1            3.5
  2          4.9            3
  3          4.7            3.2
  4          4.6            3.1
  5          5              3.6
  6          7              3.2
  7          6.4            3.2
  8          6.9            3.1
  9          5.5            2.3
  10         6.5            2.8
  11         6.3            3.3
  12         5.8            2.7
  13         7.1            3
  14         6.3            2.9
  15         6.5            3

```{r c1, echo=FALSE,fig.cap='Scatter diagram of data in Example 7.1',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image2c.jpeg"))
```

## Correlation

Correlation is a statistical technique used for analyzing the behaviour
of two or more variables. The correlation measures the degree and
closeness of the linear relationship between two variables in
numerical magnitude.

Correlation measure will enable us to compare the linear relationship
between two variables by using a single number. If two or more
quantities vary in a related manner so that the movements in one tend to
be accompanied by the movements in the other, then they are said to be
correlated.

### Positive correlation  
Positive correlation is a relationship between two variables in
which both variables move in the same direction. A positive correlation
exists when one variable decreases as the other variable decreases, or
one variable increases while the other increases.

Examples of positive correlation: consider two variables *x* and *y*

-   The more time you spend running on a treadmill \[Running time
    (*x*)\], the more calories you will burn \[calories burned (*y*)\].
    Here you can see as *x* increases *y* also increases

-   Shorter people \[Height (*x*)\] have smaller shoe sizes \[shoe size
    (*y*)\]. Here you can see as *x* decreases *y* also decreases.

-   The more hours you spend in direct sunlight \[Hours in sunlight
    (*x*)\], the more is your tan \[melanin content(*y*)\]. Here you can
    see as *x* increases *y* also increases

-   As the temperature goes up \[Temperature (*x*)\], ice cream sales
    \[sales (*y*)\], also go up.

### Negative correlation  
Negative correlation is a relationship between two variables in
which one variable increases as the other decreases, and vice versa.

Examples of negative correlation: consider two variables *x* and *y*

-   A student who has many absences \[No. of days absent (*x*)\] has a
    decrease in grades \[grades (*x*)\]. Here you can see as *x*
    increases *y* decreases.

-   As weather gets colder \[Average monthly temperature (*x*)\], air
    conditioning costs decrease \[Price of A.C (*y*)\].

-   If a chicken increases in age \[chicken age (*x*)\], the number of
    eggs it produces \[No. of eggs produced (*y*)\] decreases.

-   If a car decreases speed \[average car speed(*x*)\], travel time
    (*y*) to a destination increases.

## Other types of correlation

### Simple and Multiple  
In [simple correlation]{.ul} the relationship
is confined to two variables only. In [multiple correlation]{.ul} the
relationship between more than two variables is judged.

### Partial and total  
There are two types of correlations in multiple
correlation analysis.

Under [partial correlation]{.ul} the relationship of two or variables is
examined after eliminating the linear effect of other correlated
variables.

The [total correlation]{.ul} is based on all relevant variables.

>Correlation measures only linear relationship between variables

## Linear relationship  
A linear relationship (or linear association)
is a statistical term used to describe a straight-line relationship
between variables.

Linear relationships can be expressed either in a graphical format where
the variable plotted on X-Y plane gives a straight line or relation
between two variables (consider *x* and *y*) can be expressed with an
equation of a straight line (*y* = *a* + *bx*) (\*\*will be more clear
when we discuss regression)

**Example 7.2**: Consider the following example of ice cream sales

The local ice cream shop keeps track of how much ice cream they sell
versus the temperature on that day; here are their figures for the last
12 days:

  Temperature (¬∞C)   Ice Cream Sales (in \$)
  ------------------ -------------------------
  14.2               215
  16.4               325
  11.9               185
  15.2               332
  18.5               406
  22.1               522
  19.4               412
  25.1               614
  23.4               544
  18.1               421
  22.6               445
  17.2               408

For the rest of our discussion we will be using this example .

## Methods of measurement of correlation

### Scatter diagram or Graphic method

```{r c2, echo=FALSE,fig.cap='Scatter plot of Example 7.2',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image3c.jpeg"))
```

From the Figure 7.2 above you can see a linear association between the two variables *i*.*e*.
between temperature and ice cream sales. It can be shown using a line as
below. It is clear that as temperature increases sales increases,
indicating a positive correlation.

```{r c3, echo=FALSE,fig.cap='Linear relationship between variables',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/image3.5c.png"))
```

From the example it is clear that scatter diagram gives an idea on
linear association between variables, so it can also used as a graphical
tool to see whether there is correlation is present or not.

>**Perfect Correlation**: If there is any change in the value of one
variable, the value of the other variable is changed in a fixed
proportion then the correlation between them is said to be a perfect
correlation. If there is a perfect correlation, the points will lie in
the straight line. In the scatter diagram of Example 7.2, you can see that
there is no perfect linear relationship as the points are not exactly in
the line, but the points are in some scattered form but still have a
direction (positive).

Direction of correlation can be identified using a scatter diagram as shown below in Figure 7.4

```{r c4, echo=FALSE,fig.cap='Scatter plot and nature of relationship',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/image4c.jpeg"))
```

### Karl Pearson's coefficient of Correlation (*r*)

It is the most important and widely used measure of correlation. A
measure of the intensity or degree of linear relationship between two
variables is developed by Karl Pearson, a British Biometrician - known
as the **[Pearson's Correlation coefficient]{.ul}** denoted by ***r***
which is expressed as the ratio of the **covariance** to the product of the standard deviations of the two variables.  

#### Covariance  

**Covariance** is a measure of the joint linear variability of the two
variables. Consider two variables *x* and *y* with *n* observations
each, then covariance is given by the formula

Covariance of (*x*,*y*) =
$\frac{1}{n}\sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)\left( y_{i} - \overline{y} \right)}$

When covariance = 0 there is no joint variability or there is no linear
relationship. The unit of covariance is the product of the units of the
two variables.

Covariance of two variables *x* and *y* is denoted as *Cov*(*x*, *y*).
Covariance measure is used to find correlation coefficient.

The correlation coefficient between the two variables (*x* and *y*) is
calculated as  
$$r=\frac{cov(x,y)}{sd(x)sd(y)}$$

Where *sd*. is the standard deviation.  


$$r = \frac{\frac{1}{n}\sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)\left( y_{i} - \overline{y} \right)}}{\sqrt{\frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}\frac{1}{n}\sum_{i = 1}^{n}\left( y_{i} - \overline{y} \right)^{2}}}$$
#### Properties of the correlation coefficient (*r*)  

1.  It is a pure number independent of both origin and scale of the
    units of the observations.

2.  It always lies between ‚àí1 and +1 (absolute value cannot exceed
    unity). **‚àí1** ‚â§ *r* ‚â§ **+1**

3.  *r* = +1, indicates perfect positive correlation. *r* = ‚àí1,
    indicates perfect negative correlation. *r* = 0, indicates no
    correlation.

4.  When the correlation is zero then there is no linear relationship
    between the variables.

5.  If there is no meaningful relation between the variables the value
    of the correlation obtained is also meaningless. (For example as
    fertilizer price increases, Kohili's batting average also increases,
    we know there no practical relationship between these variables,
    still we may get a correlation measure and it is called *spurious
    correlation*)

6.  A Simplified formula for computation of correlation coefficient can
    be derived by modifying above formula

$$r = \frac{n\left( \sum_{i = 1}^{n}{x_{i}y_{i}} \right) - \sum_{i = 1}^{n}{x_{i}\sum_{i = 1}^{n}y_{i}}}{\sqrt{\left\lbrack n\sum_{i = 1}^{n}{x_{i}^{2} - \left( \sum_{i = 1}^{n}x_{i} \right)^{2}} \right\rbrack\left\lbrack n\sum_{i = 1}^{n}{y_{i}^{2} - \left( \sum_{i = 1}^{n}y_{i} \right)^{2}} \right\rbrack}}$$  

**Example 7.3**: Consider the Example 7.2 of ice cream sales; find
correlation coefficient (*r*)  


| Sl. No. | Temperature | Sales | $x_{i}-\overline{x}$(1)       |$y_{i}-\overline{y}$(2)       | (1).(2)|$(x_{i}-\overline{x})^{2}$         | $(y_{i}-\overline{y})^{2}$           |
|---------|-------------|-------|--------|---------|---------|---------|----------|
|         | (x)         | (y)   |        |         |         |         |          |
| 1       | 14.2        | 215   | -4.475 | -187.42 | 838.69  | 20.0256 | 35125.01 |
| 2       | 16.4        | 325   | -2.275 | -77.417 | 176.123 | 5.17563 | 5993.34  |
| 3       | 11.9        | 185   | -6.775 | -217.42 | 1473    | 45.9006 | 47270.01 |
| 4       | 15.2        | 332   | -3.475 | -70.417 | 244.698 | 12.0756 | 4958.507 |
| 5       | 18.5        | 406   | -0.175 | 3.58333 | -0.6271 | 0.03063 | 12.84028 |
| 6       | 22.1        | 522   | 3.425  | 119.583 | 409.573 | 11.7306 | 14300.17 |
| 7       | 19.4        | 412   | 0.725  | 9.58333 | 6.94792 | 0.52562 | 91.84028 |
| 8       | 25.1        | 614   | 6.425  | 211.583 | 1359.42 | 41.2806 | 44767.51 |
| 9       | 23.4        | 544   | 4.725  | 141.583 | 668.981 | 22.3256 | 20045.84 |
| 10      | 18.1        | 421   | -0.575 | 18.5833 | -10.685 | 0.33062 | 345.3403 |
| 11      | 22.6        | 445   | 3.925  | 42.5833 | 167.14  | 15.4056 | 1813.34  |
| 12      | 17.2        | 408   | -1.475 | 5.58333 | -8.2354 | 2.17563 | 31.17361 |
| **SUM**     | **224.1**       | **4829**  | 0      | 0       | **5325.03** | **176.983** | **174754.9** |  


*n* =12

$$mean,\overline{x} = \ \frac{224.1}{12} = 18.675$$

$$mean,\overline{y} = \ \frac{4829}{12} = 402.416$$

*Cov* (*x*,*y*) =
$\frac{1}{n}\sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)\left( y_{i} - \overline{y} \right)}$

$\sum_{i = 1}^{12}{\left( x_{i} - \overline{x} \right)\left( y_{i} - \overline{y} \right)} = 5325.03$

*Cov* (*x*,*y*) = $\frac{5325.03}{12} = 443.752$

$$Standard\ deviation,\ S.D\left( x \right) = \ \sqrt{\frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2}} = \sqrt{\frac{176.983}{12}} = 3.840$$

$$Standard\ deviation,\ S.D\left( y \right) = \ \sqrt{\frac{1}{n}\sum_{i = 1}^{n}\left( y_{i} - \overline{y} \right)^{2}} = \sqrt{\frac{174754.9}{12}} = 120.676$$

$r = \frac{443.752}{3.840\  \times 120.676} = 0.95751$, which indicates
a strong positive correlation

### Spearman's Rank order correlation coefficient (*œÅ*)

The Spearman correlation evaluates the monotonic relationship between
two continuous or ordinal variables.

Note: What is a monotonic relation?

In a monotonic relationship, the variables tend to move in the same
relative direction, but not necessarily at a constant rate. In a linear
relationship, the variables move in the same direction at a constant
rate.

Linear relationship is monotonic but all monotonic relations are not
linear. You can see the plots below for better understanding.  

```{r c6, echo=FALSE,fig.cap='Linear and Monotonic relationship',out.width="49%",fig.show='hold', fig.align='center'}
knitr::include_graphics(c("images/image6c.jpeg","images/image7c.jpeg","images/image8c.jpeg","images/image9c.jpeg","images/image10c.jpeg"))
```  

The Spearman correlation coefficient is based on the ranked values for
each variable rather than the raw data. The spearman correlation
measures the monotonic relationship between variables, where pearsons
correlation coefficient measures linear relationship only. To use
Spearman's correlation coefficient your data must be in ordinal,
interval or ratio scale.

There are two cases in calculating *œÅ*. One is in case of no tied rank
other is when there is tied rank

#### No tied rank case  
When two or more distinct observations have the same
value, thus being given the same rank, they are said to be tied

The formula for the Spearman rank correlation coefficient when there are
no tied ranks is:

$$\rho = 1 - \frac{6\sum_{i = 1}^{n}d_{i}^{2}}{n\left( n^{2} - 1 \right)}$$

Where $d_{i}$ is the difference between ranks of *i^t^*^h^ pair of
observation

**Example 7.4**: Calculation of Spearman's rank correlation when there is
no tied rank is explained step by step by using the example below

The scores for nine students in physics and math are as follows:

Physics: 35, 23, 47, 17, 10, 43, 9, 6, 28

Mathematics: 30, 33, 45, 23, 8, 49, 12, 4, 31

Compute the student's ranks in the two subjects and compute the Spearman
rank correlation.

  Physics   Mathematics
  --------- -------------
  35        30
  23        33
  47        45
  17        23
  10        8
  43        49
  9         12
  6         4
  28        31

**Step 1**: Find the ranks for each individual subject. Rank the scores
from greatest to smallest; assign the rank 1 to the highest score, 2 to
the next highest and so on:

+---------------+------+-------------+------+
| Physics (*x*) | Rank | Mathematics | Rank |
|               |      |             |      |
|               |      | (*y*)       |      |
+===============+======+=============+======+
| 35            | 3    | 30          | 5    |
+---------------+------+-------------+------+
| 23            | 5    | 33          | 3    |
+---------------+------+-------------+------+
| 47            | 1    | 45          | 2    |
+---------------+------+-------------+------+
| 17            | 6    | 23          | 6    |
+---------------+------+-------------+------+
| 10            | 7    | 8           | 8    |
+---------------+------+-------------+------+
| 43            | 2    | 49          | 1    |
+---------------+------+-------------+------+
| 9             | 8    | 12          | 7    |
+---------------+------+-------------+------+
| 6             | 9    | 4           | 9    |
+---------------+------+-------------+------+
| 28            | 4    | 31          | 4    |
+---------------+------+-------------+------+

**Step 2**: Add a column *d*, to your data. The *d* is the difference
between ranks. For example, the first student's physics rank is 3 and
math rank is 5, so the difference is -2. In the next column, square your
*d* values.

+---------------+--------+-------------+------+-----+--------+
| Physics (*x*) | Rank   | Mathematics | Rank | *d* | *d*^2^ |
|               |        |             |      |     |        |
|               |        | (*y*)       |      |     |        |
+===============+========+=============+======+=====+========+
| 35            | 3      | 30          | 5    | -2  | 4      |
+---------------+--------+-------------+------+-----+--------+
| 23            | 5      | 33          | 3    | 2   | 4      |
+---------------+--------+-------------+------+-----+--------+
| 47            | 1      | 45          | 2    | -1  | 1      |
+---------------+--------+-------------+------+-----+--------+
| 17            | 6      | 23          | 6    | 0   | 0      |
+---------------+--------+-------------+------+-----+--------+
| 10            | 7      | 8           | 8    | -1  | 1      |
+---------------+--------+-------------+------+-----+--------+
| 43            | 2      | 49          | 1    | 1   | 1      |
+---------------+--------+-------------+------+-----+--------+
| 9             | 8      | 12          | 7    | 1   | 1      |
+---------------+--------+-------------+------+-----+--------+
| 6             | 9      | 4           | 9    | 0   | 0      |
+---------------+--------+-------------+------+-----+--------+
| 28            | 4      | 31          | 4    | 0   | 0      |
+---------------+--------+-------------+------+-----+--------+
| **SUM**       | **12** |             |      |     |        |
+---------------+--------+-------------+------+-----+--------+

**Step 4**: Sum (add up) all of your *d*^2^ values. 4 + 4 + 1 + 0 + 1 +
1 + 1 + 0 + 0 = 12. You'll need this for the formula (the
$\sum_{i = 1}^{n}d_{i}^{2}$ is just "the sum of *d*^2^values, here *n*=
9").

**Step 5**: Insert the values into the formula.

$$\rho = 1 - \frac{6\sum_{i = 1}^{n}d_{i}^{2}}{n\left( n^{2} - 1 \right)}$$

$$\rho = 1 - \frac{6 \times 12}{9\left( 81 - 1 \right)} = 0.90$$

The Spearman's Rank Correlation for this set of data is 0.9.

Spearman's Rank Correlation also lies between ‚àí1 and +1 always. ‚àí1 ‚â§ *œÅ*
‚â§+1

#### Tied rank case

Calculation of Spearman's rank correlation when there is
tied rank is explained step by step by using the example below  

**Example 7.5**: The scores for nine students in physics and mathematics are as follows:

+---------+-------------+
| Physics | Mathematics |
|         |             |
| (*x*)   | (*y*)       |
+=========+=============+
| 35      | 30          |
+---------+-------------+
| 23      | 33          |
+---------+-------------+
| 47      | 45          |
+---------+-------------+
| 23      | 23          |
+---------+-------------+
| 10      | 8           |
+---------+-------------+
| 43      | 49          |
+---------+-------------+
| 9       | 12          |
+---------+-------------+
| 6       | 33          |
+---------+-------------+
| 28      | 33          |
+---------+-------------+

**Step 1**: Consider the marks in Physics, ranked as usual

+---------+------+
| Physics | Rank |
|         |      |
| (*x*)   |      |
+=========+======+
| 35      | 3    |
+---------+------+
| 23      | 5    |
+---------+------+
| 47      | 1    |
+---------+------+
| 23      | 6    |
+---------+------+
| 10      | 7    |
+---------+------+
| 43      | 2    |
+---------+------+
| 9       | 8    |
+---------+------+
| 6       | 9    |
+---------+------+
| 28      | 4    |
+---------+------+

You can see the value 23 is repeated, so may have equal ranks, so the
average of two ranks 5 and 6 is given to both;
$\left( \frac{5 + 6}{2} \right)\ $= 5.5

+---------+------+
| Physics | Rank |
|         |      |
| (*x*)   |      |
+=========+======+
| 35      | 3    |
+---------+------+
| 23      | 5.5  |
+---------+------+
| 47      | 1    |
+---------+------+
| 23      | 5.5  |
+---------+------+
| 10      | 7    |
+---------+------+
| 43      | 2    |
+---------+------+
| 9       | 8    |
+---------+------+
| 6       | 9    |
+---------+------+
| 28      | 4    |
+---------+------+

Similarly for marks in mathematics you can see 33 is repeated thrice.

+-------------+
| Mathematics |
|             |
| (*y*)       |
+=============+
| 30          |
+-------------+
| 33          |
+-------------+
| 45          |
+-------------+
| 23          |
+-------------+
| 8           |
+-------------+
| 49          |
+-------------+
| 12          |
+-------------+
| 33          |
+-------------+
| 33          |
+-------------+

+-------------+------+
| Mathematics | Rank |
|             |      |
| (*y*)       |      |
+=============+======+
| 30          | 6    |
+-------------+------+
| 33          | 3    |
+-------------+------+
| 45          | 2    |
+-------------+------+
| 23          | 7    |
+-------------+------+
| 8           | 9    |
+-------------+------+
| 49          | 1    |
+-------------+------+
| 12          | 8    |
+-------------+------+
| 33          | 4    |
+-------------+------+
| 33          | 5    |
+-------------+------+

You can see the value 33 is repeated thrice, so the average of three
ranks 3, 4 and 5 is given $\left( \frac{3 + 4 + 5}{3} \right)\ $= 4

+-------------+------+
| Mathematics | Rank |
|             |      |
| (*y*)       |      |
+=============+======+
| 30          | 6    |
+-------------+------+
| 33          | 4    |
+-------------+------+
| 45          | 2    |
+-------------+------+
| 23          | 7    |
+-------------+------+
| 8           | 9    |
+-------------+------+
| 49          | 1    |
+-------------+------+
| 12          | 8    |
+-------------+------+
| 33          | 4    |
+-------------+------+
| 33          | 4    |
+-------------+------+

**Step 2**: Change in the formula

$$\rho = 1 - \frac{6\left( \sum_{i = 1}^{n}d_{i}^{2} + T_{x} + T_{y} \right)}{n\left( n^{2} - 1 \right)}$$

If there are *m* individuals tied (having same rank), and *s* such sets
of ranks are there in X- series then,
$T_{x} = \ \frac{1}{12}\sum_{i = 1}^{s}{m_{i}\left( m_{i}^{2} - 1 \right)}$

In our example marks in Physics (*x*) there are two 23 values tied
therefore *m* = 2; since only one such a set is there *s* =1

$T_{x} = \ \frac{1}{12}\left( 2 \times (2^{2} - 1 \right)$ = 0.5

If there are *w* individuals tied (having same rank), and *s'* such sets
of ranks are there in Y- series then,
$T_{y} = \ \frac{1}{12}\sum_{i = 1}^{s'}{w_{i}\left( w_{i}^{2} - 1 \right)}$

In our example marks in Mathematics (*y*) there are three 33 values tied
therefore *w* = 3; since only one such a set is there *s* =1

$T_{y} = \ \frac{1}{12}\left( 3 \times (3^{2} - 1 \right)$ = 2

**Step 2**: Calculate *d* and then use the formula

+---------+------+-------------+------+------+--------+
| Physics | Rank | Mathematics | Rank | *d*  | *d*^2^ |
|         |      |             |      |      |        |
| (*x*)   |      | (*y*)       |      |      |        |
+=========+======+=============+======+======+========+
| 35      | 3    | 30          | 6    | -3   | 9      |
+---------+------+-------------+------+------+--------+
| 23      | 5.5  | 33          | 4    | 1.5  | 2.25   |
+---------+------+-------------+------+------+--------+
| 47      | 1    | 45          | 2    | -1   | 1      |
+---------+------+-------------+------+------+--------+
| 23      | 5.5  | 23          | 7    | -1.5 | 2.25   |
+---------+------+-------------+------+------+--------+
| 10      | 7    | 8           | 9    | -2   | 4      |
+---------+------+-------------+------+------+--------+
| 43      | 2    | 49          | 1    | 1    | 1      |
+---------+------+-------------+------+------+--------+
| 9       | 8    | 12          | 8    | 0    | 0      |
+---------+------+-------------+------+------+--------+
| 6       | 9    | 33          | 4    | 5    | 25     |
+---------+------+-------------+------+------+--------+
| 28      | 4    | 33          | 4    | 0    | 0      |
+---------+------+-------------+------+------+--------+
| SUM     | 0    | 44.5        |      |      |        |
+---------+------+-------------+------+------+--------+

$\rho = 1 - \frac{6\left( \sum_{i = 1}^{n}d_{i}^{2} + T_{x} + T_{y} \right)}{n\left( n^{2} - 1 \right)} = 1 - \frac{6 \times \left( 44.5 + 0.5 + 2 \right)}{9\left( 9^{2} - 1 \right)} = \ 1 - \frac{282}{720}$
= 0.60834

### Kendall's Rank Correlation Coefficient (*œÑ*)

Kendall's rank correlation coefficient also known as Kendall's Tau or
coefficient of concordance. It lies between 0 and 1, 0 ‚â§ *œÑ ‚â§* 1. when
several sets of ranks are there, it can be used to test the association.

When we have *k* sets of rankings we may determine the association among
them by using the Kendall's coefficient of Concordance (*œÑ*). Such a
measure is useful to study the reliability in the scorings made by a
number of Judges.

Arrange the data into a table with each row representing the ranks
assigned by (each judge), to say, *n* number of objects. Let there be
*k* number of sets of rankings for each object given by *k* judges. Then
the Kendall's coefficient of concordance *œÑ* is computed as

$$\tau = \frac{12\left\lbrack \sum_{i = 1}^{n}{R_{i}^{2} - \frac{\left( \sum_{i = 1}^{n}R_{i} \right)^{2}}{n}} \right\rbrack}{k^{2}n\left( n^{2} - 1 \right)}$$

**Example 7.6**: In a crop production competition, 10 entries of farmers
were ranked by agricultural scientists (judges). Find the degree of
agreement among the scientist for the competition result given below.

            Ranks given by the judges to farmers                               
  --------- -------------------------------------- ------------- ------------- -------------
  Farmers   Scientist 1                            Scientist 2   Scientist 3   Scientist 4
  1         4                                      5             3             7
  2         10                                     9             8             6
  3         8                                      6             10            9
  4         3                                      4             2             1
  5         1                                      3             4             2
  6         2                                      1             1             4
  7         5                                      7             6             5
  8         6                                      2             5             3
  9         7                                      8             9             10
  10        9                                      10            7             8

Solution:

  Farmers   S1    S2     S3   S4   $R_{i}$ (sum of ranks)   $$R_{i}^{2}$$
  --------- ----- ------ ---- ---- ------------------------ ---------------
  1         4     5      3    7    19                       361
  2         10    9      8    6    33                       1089
  3         8     6      10   9    33                       1089
  4         3     4      2    1    10                       100
  5         1     3      4    2    10                       100
  6         2     1      1    4    8                        64
  7         5     7      6    5    23                       529
  8         6     2      5    3    16                       256
  9         7     8      9    10   34                       1156
  10        9     10     7    8    34                       1156
  **SUM**   220   5900                                      

Here *k* = number of judges = 4

*n* = number of farmers =10

$\left( \sum_{i = 1}^{10}R_{i} \right)^{2}\ $= (220)^2^ = 48400

$\sum_{i = 1}^{10}R_{i}^{2}$ = 5900

$$\tau = \frac{12\left\lbrack \sum_{i = 1}^{n}{R_{i}^{2} - \frac{\left( \sum_{i = 1}^{n}R_{i} \right)^{2}}{n}} \right\rbrack}{k^{2}n\left( n^{2} - 1 \right)}$$

=\
$\tau = \frac{12\left\lbrack 5900 - \frac{48400}{10} \right\rbrack}{16 \times 10\left( 100 - 1 \right)}$
= 0.803

Since $\tau$ is nearly equal to 1, the ranks given by judges were almost
same  



\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*

<!--chapter:end:07_lecture07.rmd-->



# Regression Analysis  

Regression analysis is the method of using observations (data records)
to quantify the relationship between a target variable also referred to
as a *dependent variable*, and a set of *independent variables*.

## Definition  

Regression analysis is a mathematical measure of the
average relationship between two or more variables in terms of the
original units of the data

## Simple regression  

when only two variables are involved; Regression
can be defined as the functional relationship between two variables,
where one may represent cause and the other may represent effect. The
variable representing cause is known as independent variable and is
denoted by 'X'. The variable 'X' is also known as predictor variable,
regressor or explanatory variable. The variable representing effect is
known as dependent variable and is denoted by Y. For example consider
yield and fertilizer dose, here yield can be considered as dependent
variable (Y) and fertilizer dose can be considered as independent
variable (X).

## Two types of variables  

In regression analysis the
variable whose values need to be predicted (Y) is called **dependent variable** and the variable which is used for prediction (X) is called
**independent variable.**

When more than two independent variables are present then the regression
is called as **Multiple Regression**. If only two variables are present
then it is called as **simple regression**.

## Detailed explanation  

Correlation is a statistical measure which determines the degree of
association of two variables. Regression on other hand side describes
how an independent variable is numerically related to dependent
variable.

Regression can be simply defined as a technique of fitting best line or
line of best fit to estimate value of one variable on the basis of
another variable. Now what is a best line? or line of best fit?

For explaining further, consider the example of Ice cream sales:

**Example 8.1**: The local ice cream shop keeps track of how much ice
cream they sell versus the temperature on that day; here are their
figures for the last 12 days:

  Temperature (¬∞C)   Ice Cream Sales (in \$)
  ------------------ -------------------------
  14.2               215
  16.4               325
  11.9               185
  15.2               332
  18.5               406
  22.1               522
  19.4               412
  25.1               614
  23.4               544
  18.1               421
  22.6               445
  17.2               408

We can use regression analysis to answer the following questions

What will be the Ice cream sales when temperature is 20^o^ Celsius?

What is the functional form of relationship between Temperature and Ice
cream sales?  

```{r r1, echo=FALSE,fig.cap='Scatter diagram of data in Example 8.1',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/r2.jpeg"))
```
  
We can draw a line to denote the functional relationship between temperature and sales  

```{r r2, echo=FALSE,fig.cap='lines drawn to show functional relationship',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/r99.png"))
```

You can see that as shown above we can draw any number of lines, so
which is the best fit line?

We can say the **best fit line** is the line that passes through all
points such that distance of each point to the line is minimum. Using
regression technique we could easily draw such a line. Before proceeding
you should know the concept of error and residuals.

## Error and residual  

An error is the difference between the observed value and the true value
(true value is the unobserved population mean of the population from
which sample observations are taken). A residual is the difference
between the observed value and the predicted value (by the model
\[fitted line\]). Error cannot be measured but residual can be; so
residual is considered as an estimate of error.

```{r r3, echo=FALSE,fig.cap='Error depicted in best fit line ',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/r91.png"))
```

The distance of each observation (*e*~i~) from the fitted line can be
considered as the residual (error). Best fit line can be obtained by
minimizing this distance. This can be achieved using the mathematical
technique "**principle of least squares**".

## Straight lines

A straight line is the simplest figure in geometry.

Mathematical equation of a straight line Y= ***a*** + ***b***X.

Two important features of a line **slope** and **intercept**. ***a*** is
the Y-intercept, the intercept of a line is the y-value of the point
where it crosses the y-axis. ***b*** is the **slope of a line,** which
is a number that measures its \"steepness. It is the change in Y for a
unit change in X along the line. In regression ***b*** is called as
regression coefficient

Intercept (***a***)  

```{r r4, echo=FALSE,fig.cap='Intercept of a line ',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/r92.png"))
```  
Slope (***b***)  

```{r r5, echo=FALSE,fig.cap='Slope of a line ',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/r93.png"))
```
***a*** and ***b*** can be considered as a finger print of a line; with
these values we can easily identify the line.

So now our problem is simple, to find a line of best, estimate ***a*** &
***b***, such that error *e*~i~ of each observation is minimized. For
that we use the **method of least squares**.

## Method of least squares

On considering the error term *e*~i~; equation of a straight line is

*y*~i~=*a*+*bx*~i~+*e~i~*;

Where *e~i~* is the *i*^th^ error term corresponding to *y*~i~, *i*
=1,2,\...,*n*

Line of best fit can be obtained by estimating ***a*** and ***b*** by
minimizing error sum 'Œ£*e~i~'*. By theorem Œ£*e~i~ =*0; so ***a*** and
***b*** are estimated by minimising Œ£*e~i~* ^2^

## Principle of least squares  
The statistical method used to determine
a line of best fit by minimizing the¬†sum of squares of the error term
Œ£*e~i~* ^2^

*y~i~*=*a*+*bx*~i~+*e~i~*;

*e~i~ =* *y*~i~ -- (*a*+*bx*~i~)  

*e~i~*^2^ = {*y*~i~ -- (*a*+*bx*~i~)}^2^  

**Œ£** *e~i~*^2^ = **Œ£** {*y*~i~ -- (*a*+*bx*~i~)}^2^

**Œ£** *e~i~*^2^ is called as error sum of squares. As we are minimizing
error sum of squares, hence the name principle of least squares.

We want to minimize, **E = Œ£** *e*~i~^2^ = **Œ£** {*y*~i~ --
(*a*+*bx*~i~)}^2^

*i*.*e*. we need to find ***a*** and ***b*** such that **E** is minimum

**E** can be minimized by taking derivative with respect to ***a*** and
***b*** and equating to zero. On doing so we will get two equations,
these equations are termed as **normal equations** and solving those
normal equations will give the formula for ***a*** and ***b***.

We are not discussing calculation part here. After taking derivatives we
will get two equations (Normal equations) as below:

$$\sum_{i = 1}^{n}{y_{i} = n\mathbf{a} + \mathbf{b}\sum_{i = 1}^{n}x_{i}}$$

$$\sum_{i = 1}^{n}{y_{i}x_{i} = \mathbf{a}\sum_{i = 1}^{n}x_{i} + \mathbf{b}\sum_{i = 1}^{n}x_{i}^{2}}$$

On solving the above equations we will get

Regression coefficient, ***b*** =
$\frac{\sum_{i = 1}^{n}{y_{i}x_{i} - \frac{\sum_{i = 1}^{n}{y_{i}\sum_{i = 1}^{n}x_{i}}}{n}}}{\sum_{i = 1}^{n}x_{i}^{2} - \frac{\left( \sum_{i = 1}^{n}x_{i} \right)^{2}}{n}}$

=$\frac{cov(x,y)}{var(x)}$

$$\mathbf{b =}\frac{\mathbf{cov(x,y)}}{\mathbf{var(x)}}
$$

$$\mathbf{a =}\overline{\mathbf{y}}\mathbf{- b}\overline{\mathbf{x}}$$

where $\overline{y}$ = mean of *y*; $\overline{x}$ = mean of *x*

## Two lines of regression

There are two lines of regression- that of *y* on *x* and *x* on *y*.

[Regression of *y* on *x*]{.ul}

Consider the two variables *x* and *y*, if you are considering *y* as
dependent variable and *x* as independent variable then your equation
is:

***y* = *a* + *bx***

This is used to predict the unknown value of variable *y* when value of
variable *x* is known. Usually ***b*** here is denoted as ***b***~yx~

$$\mathbf{b}_{\mathbf{\text{yx}}}\mathbf{=}\frac{\mathbf{cov(x,y)}}{\mathbf{var(x)}}$$

Consider Example 8.1; considering ice cream sales as dependent variable
and temperature as independent variable

```{r r6, echo=FALSE,fig.cap='Scatter diagram of data in Example 8.1',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/r7.jpeg"))
```  

[Regression of *x* on *y*]{.ul}

Consider the two variables *x* and *y*, if you are considering *x* as
dependent variable and *y* as independent variable then your equation
is:

***x*= *c* + *my; ***where ***c*** is the intercept and ***m*** is the
slope

This is used to predict the unknown value of variable *x* when value of
variable *y* is known. Usually ***b*** here is denoted as ***b***~xy~

$$\mathbf{b}_{\mathbf{\text{xy}}}\mathbf{=}\frac{\mathbf{cov(x,y)}}{\mathbf{var(y)}}$$

Consider Example 8.1; considering temperature as dependent variable and
ice cream sales as independent variable

```{r r7, echo=FALSE,fig.cap='Scatter diagram of data in Example 8.1',out.width="50%", fig.align='center'}
knitr::include_graphics(rep("images/r8.jpeg"))
```

You can see both the regression were different. It depends on the
experimenter to choose dependent and independent variable. In the above
example it is evident that considering temperature as dependent variable
is meaningless, *i*.*e*. what is the usefulness in predicting
temperature based on ice cream sales?. So the selection of dependent and
independent variable is entirely the discretion of experimenter based on
the objective of his study.

## Assumptions of Regression

If *y* is the dependent variable and *x* is the independent variable
then

1.  The *x*'s are non-random or fixed constants

2.  At each fixed value of *x* the corresponding values of *y* have a
    normal distribution about a mean.

3.  For any given *x*, the variance of *y* is same.

4.  The values of *y* observed at different levels of *x* are completely
    independent.
  
## Properties of Regression coefficients  

1.  The correlation coefficient between *x* and *y* is the geometric
    mean of the two regression coefficients ***b***~yx~ and ***b***~xy~

$$r = \sqrt{b_{\text{yx}}b_{\text{xy}}}$$

2.  Regression coefficients are independent of change of origin but not
    of scale.

3.  If one regression coefficient is greater than unit, then the other
    must be less than unit but not vice versa. *i*.*e*. both the
    regression coefficients can be less than unity but both cannot be
    greater than unity, *i*.*e*. if ***b***~yx~ \>1 then ***b***~xy~ \<1
    and if ***b***~xy~ \>1, then ***b***~yx~ \<1.

4.  Also if one regression coefficient is positive the other must be
    positive (in this case the correlation coefficient is positive) and
    if one regression coefficient is negative the other must be negative
    (in this case the correlation coefficient is negative).

## Uses of Regression

**Prediction**: The regression analysis is useful in predicting the
value of one variable from the given value of another variable. Such
predictions are useful when it is very difficult or expensive to measure
the dependent variable, Y.

**Identify the strength of relationship**: the regression might be used
to identify the strength of the effect that the independent variable(s)
have on a dependent variable. Like the strength of relationship between
dose and effect, sales and marketing spending, or age and income.

**Forecast effects or impact of changes**: That is, the regression
analysis helps us to understand how much the dependent variable changes
with a change in one or more independent variables. A typical question
is, "how much additional sales income do I get for each additional 1000
spent on marketing

**Predicts trends and future values**: The regression analysis can be
used to predict trend and future values, like "what will the price of
gold be in 6 months?"

## Example problem  

Now consider the example 8.1 and answer the questions  

  Temperature (¬∞C)   Ice Cream Sales (in \$)
  ------------------ -------------------------
  14.2               215
  16.4               325
  11.9               185
  15.2               332
  18.5               406
  22.1               522
  19.4               412
  25.1               614
  23.4               544
  18.1               421
  22.6               445
  17.2               408

1.  What is the functional form of relationship between Temperature and
    Ice cream sales?

2.  What will be the Ice cream sales when temperature is 20^o^ Celsius?

**Solution**

1.  Fit a model considering Ice cream sales as dependent variable (*y*)
    and temperature as independent variable (*x*). Fitting a model means
    estimating ***b*** and ***a*** using equation.

2.  After fitting the model put 20 in the *x* value you will get the
    predicted *y* value

Model: *y* = ***a***+***b**x*

+---------+-------------+----------+------------+
| Sl. No. | Temperature | Sales    | $$x_{i} - \overline{x}$$ |
|         |             |          |                                         |
|         | (*x*)       | (*y*)    |                                         |
+=========+=============+==========+=========================================+
| 1       | 14.2        | 215      | -4.475                                  |
+---------+-------------+----------+-----------------------------------------+
| 2       | 16.4        | 325      | -2.275                                  |
+---------+-------------+----------+-----------------------------------------+
| 3       | 11.9        | 185      | -6.775                                  |
+---------+-------------+----------+-----------------------------------------+
| 4       | 15.2        | 332      | -3.475                                  |
+---------+-------------+----------+-----------------------------------------+
| 5       | 18.5        | 406      | -0.175                                  |
+---------+-------------+----------+-----------------------------------------+
| 6       | 22.1        | 522      | 3.425                                   |
+---------+-------------+----------+-----------------------------------------+
| 7       | 19.4        | 412      | 0.725                                   |
+---------+-------------+----------+-----------------------------------------+
| 8       | 25.1        | 614      | 6.425                                   |
+---------+-------------+----------+-----------------------------------------+
| 9       | 23.4        | 544      | 4.725                                   |
+---------+-------------+----------+-----------------------------------------+
| 10      | 18.1        | 421      | -0.575                                  |
+---------+-------------+----------+-----------------------------------------+
| 11      | 22.6        | 445      | 3.925                                   |
+---------+-------------+----------+-----------------------------------------+
| 12      | 17.2        | 408      | -1.475                                  |
+---------+-------------+----------+-----------------------------------------+
| **SUM** | **224.1**   | **4829** | **0**                                   |
+---------+-------------+----------+-----------------------------------------+

  $$\left( y_{i} - \overline{y} \right)$$   $\left( x_{i} - \overline{x} \right)$√ó $\left( y_{i} - \overline{y} \right)$   $$\left( x_{i} - \overline{x} \right)^{2}$$   $$\left( y_{i} - \overline{y} \right)^{2}$$
  ----------------------------------------- ------------------------------------------------------------------------------ --------------------------------------------- ---------------------------------------------
  -187.42                                   838.69                                                                         20.0256                                       35125.01
  -77.417                                   176.123                                                                        5.17563                                       5993.34
  -217.42                                   1473                                                                           45.9006                                       47270.01
  -70.417                                   244.698                                                                        12.0756                                       4958.507
  3.58333                                   -0.6271                                                                        0.03063                                       12.84028
  119.583                                   409.573                                                                        11.7306                                       14300.17
  9.58333                                   6.94792                                                                        0.52562                                       91.84028
  211.583                                   1359.42                                                                        41.2806                                       44767.51
  141.583                                   668.981                                                                        22.3256                                       20045.84
  18.5833                                   -10.685                                                                        0.33062                                       345.3403
  42.5833                                   167.14                                                                         15.4056                                       1813.34
  5.58333                                   -8.2354                                                                        2.17563                                       31.17361
  **0**                                     **5325.03**                                                                    **176.983**                                   **174754.9**

*n* =12

$$mean,\overline{x} = \ \frac{224.1}{12} = 18.675$$

$$mean,\overline{y} = \ \frac{4829}{12} = 402.416$$

*Cov* (*x*,*y*) =
$\frac{1}{n}\sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)\left( y_{i} - \overline{y} \right)}$

$\sum_{i = 1}^{12}{\left( x_{i} - \overline{x} \right)\left( y_{i} - \overline{y} \right)} = 5325.03$

*Cov* (*x*,*y*) = $\frac{5325.03}{12} = 443.752$

$$variance\ of\ x,\ var\left( x \right) = \ \frac{1}{n}\sum_{i = 1}^{n}\left( x_{i} - \overline{x} \right)^{2} = \frac{176.983}{12} = 14.7485$$

$$\mathbf{b =}\frac{\mathbf{cov(x,y)}}{\mathbf{var(x)}}$$

$$\mathbf{b =}\frac{443.752}{14.7485}\mathbf{=}30.088$$

$$\mathbf{a =}\overline{\mathbf{y}}\mathbf{- b}\overline{\mathbf{x}}$$

$$\mathbf{a =}402.416 - 30.088\left( 18.675 \right) = \  - 159.477$$

So our model is

$$y = \  - 159.477 + 30.088x$$

$$Ice\ cream\ sales = \  - 159.477 + 30.088(Temperature)$$

Ice cream sales when temperature is 20^o^ Celsius

$$x = 20$$

$y = \  - 159.477 + 30.088(20)$ = 442.283

So the predicted ice cream sales at 20^o^ Celsius is \$442.283

\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*

<!--chapter:end:08_lecture08.rmd-->

# References

<!--chapter:end:reference.rmd-->

